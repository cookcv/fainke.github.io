<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Text Summarization</title>
      <link href="/blog/5566fb07.html"/>
      <url>/blog/5566fb07.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="什么是NLP中的文本摘要"><a href="#什么是NLP中的文本摘要" class="headerlink" title="什么是NLP中的文本摘要"></a>什么是NLP中的文本摘要</h2><p>自动文本摘要是在保持关键信息内容和整体含义的同时，生成简洁流畅的摘要的任务。<br>文本摘要目前大致可以分为抽取式与生成式两种类型：</p><ol><li>Extractive Summarization：根据词语重要性、句子重要性排序，抽取出重要度高的句子，从而形成摘要。主要是对文本的选择，算法过程相对更容易，但是对于复杂的文本时，很难仅仅通过选择文本来形成摘要，如小说。</li><li>Abstractive Summarization：过程更为复杂，但生成能力更强，可认为有一定的概括能力。<a id="more"></a></li></ol><h3 id="Extractive-Summarization"><a href="#Extractive-Summarization" class="headerlink" title="Extractive Summarization"></a>Extractive Summarization</h3><p>由图可以看出，这种方法提取的内容语句来自于原文。<br><img src="images/ExtractiveSummarization.jpg" alt="Extractive Summarization"></p><h3 id="Abstractive-Summarization"><a href="#Abstractive-Summarization" class="headerlink" title="Abstractive Summarization"></a>Abstractive Summarization</h3><p>由图可以看出，这种方法提取的内容语句可能不存在于原文。<br><img src="images/AbstractiveSummarization.jpg" alt="Abstractive Summarization"></p><h2 id="Seq2Seq模型"><a href="#Seq2Seq模型" class="headerlink" title="Seq2Seq模型"></a>Seq2Seq模型</h2><p>Seq2Seq模型可以处理一切连续型信息，包括情感分类，机器翻译，命名实体识别等。<br>机器翻译任务中，输入是连续文本序列，输出也是连续文本序列。<br>命名实体识别中，输入是连续文本序列，输出是连续的标签信息。<br>所以，我们可以利用Seq2Seq模型，通过输入一段长文本，输出短的摘要，实现文本摘要功能。<br>下图是典型的Seq2Seq模型架构:<br><img src="images/Seq2Seq_EncoderDecoder.jpg" alt="Seq2Seq_EncoderDecoder"><br>通常我们可以选择RNNs网络的变体GRU或者LSTM，这是因为它们能够通过克服梯度消失的问题来捕获长期依赖性。</p><h3 id="Encoder编码器"><a href="#Encoder编码器" class="headerlink" title="Encoder编码器"></a>Encoder编码器</h3><p>LSTM中的Encoder读取整个输入序列，其中每个时间step上，都会有一个字输入编码器。然后，他在每个时间step上处理信息，并捕获输入序列中存在的上下文信息。<br><img src="images/LSTM_Encoder.jpg" alt="LSTM_Encoder"><br>最后时间step的隐藏层h4与记忆单元层c4将会用来初始化Decoder。</p><h3 id="Decoder解码器"><a href="#Decoder解码器" class="headerlink" title="Decoder解码器"></a>Decoder解码器</h3><p>Decoder是LSTM结构的另一部分。它逐字读取整个目标序列，并以一个时间步长预测相同的序列偏移量。<br>解码器可以在给定前一个单词的情况下预测序列中的下一个单词。解码器的初始输入是编码器最后一步的结果。<br><img src="images/LSTM_Decoder.jpg" alt="LSTM_Decoder"><br>在将整个目标序列放入解码器前，还需将[start] 与 [end]这两个特殊的tokens加入序列中，告知模型的开始与结束。模型通过输入的[start]开始预测第一个词,而[end]则表示整个句子的结束。</p><h4 id="Deocder的工作流程"><a href="#Deocder的工作流程" class="headerlink" title="Deocder的工作流程"></a>Deocder的工作流程</h4><p>假设输入序列为[x1,x2,x3,x4],将其编码成内部固定长度的向量。<br>下图显示了每一个time step下Decoder是如何工作的。<br><img src="images/Decoder_Timestep0.jpg" alt="Timestep"></p><h3 id="推理部分"><a href="#推理部分" class="headerlink" title="推理部分"></a>推理部分</h3><p>下图是整个Encoder-Decode的结构。通过上面的理解，我觉得这个图非常清晰。<br><img src="images/LSTM_Inference.jpg" alt="LSTM_Decoder"></p><ol><li>Encoder整个输入序列，并且用Encoder最后一个状态结果来初始化Decoder。</li><li>将[start]作为输入传递给解码器Decoder。</li><li>使用通过Encoder初始化过的Decoder运行一个time stpe。</li><li>输出将是下一个单词的概率，将选择概率最大的单词。</li><li>这个预测的单词将会在下一时间Step中作为输入。并且通过当前状态更新内部参数。</li><li>重复步骤3-5，直到生成[end]或达到目标序列的最大长度。</li></ol><h3 id="Encoder-Decoder结构的局限性"><a href="#Encoder-Decoder结构的局限性" class="headerlink" title="Encoder-Decoder结构的局限性"></a>Encoder-Decoder结构的局限性</h3><p>Encoder将整个输入序列转为固定的长度，但是当序列很长的时候，Encoder将会很难记住整个序列的内容，无法将所有必要信息准确的编码到固定长度。但是，我们需要关注序列中所有的内容么，不需要。</p><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>为了解决长句子的问题，注意力机制出现在人们的视野。注意力机制为对结果重要的部分添加高的权重，以保留主要信息。举个例子：</p><ol><li>需要编码的序列[x1,x2,x3,x4,x5,x6,x7]<br><strong>Source sequence: Which sport do you like the most?</strong></li><li>需要解码的序列[y1,y2,y3]<br><strong>Target sequence: I love cricket.</strong></li></ol><p>我们可以判断，y1[I]与x4[you]有关，而y2[love]则与x5[like]有关。所以，相比记住序列中的所有单词，不如增加对目标序列重要部分的权重，忽视低权重的部分。</p><h4 id="Global-Attention-and-Local-Attention"><a href="#Global-Attention-and-Local-Attention" class="headerlink" title="Global Attention and Local Attention"></a>Global Attention and Local Attention</h4><p>编码器的隐藏层中，所有部分都参与attention计算上下文。<br><img src="images/Sqe2Sqe_GlobalAttention.jpg" alt="全局注意力机制"><br>编码器的隐藏层中，仅有部分参与attention计算上下文。<br><img src="images/Sqe2Sqe_GlobalAttention.jpg" alt="局部注意力机制"></p><p>本文最终采用全局注意力机制。（只是添加了注意力机制，编码的固定长度依然需要固定。所以实战中需要通过数据确定一个合适的长度数值。短了无法表达文本内容，长了会造成计算资源浪费。）</p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>我们的目标是为亚马逊美食评论生成文本摘要。(这里我只提取了我觉得有用的部分)</p><h3 id="数据表述"><a href="#数据表述" class="headerlink" title="数据表述"></a>数据表述</h3><p>这些评论通常很长而且具有可描述性。数据集下载：<a href="https://www.kaggle.com/snap/amazon-fine-food-reviews" target="_blank" rel="noopener">kaggleData</a>。<br>数据涵盖了超过10年的时间，包括截至2012年10月的所有〜500,000条评论。这些评论包括产品，用户信息，评级，纯文本评论和摘要。它还包括来自所有其他亚马逊类别的评论。</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>由于评论文本和摘要中涉及的预处理步骤略有不同，因此我们需要定义两个不同的函数来预处理评论和摘要。</p><h4 id="评论文本处理"><a href="#评论文本处理" class="headerlink" title="评论文本处理"></a>评论文本处理</h4><ol><li>将所有字母小写；</li><li>移除HTML标签；</li><li>Contraction mapping；</li><li>移除(‘s)；</li><li>删除括号内的内容(觉得括号里面的内容解释说明不重要)；</li><li>消除标点符号和特殊字符；</li><li>删除停用词；</li><li>删除低频词；</li></ol><h4 id="摘要文本处理"><a href="#摘要文本处理" class="headerlink" title="摘要文本处理"></a>摘要文本处理</h4><p>为摘要文本添加[start]和[end]。</p><h3 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h3><p>通过数据统计，可以看到摘要与文本数据的长度分布。通过数据可视化，我们可以将评论文本的长度限定在80，而摘要的长度限定在10。<br><img src="images/SummayText_Length.jpg" alt="SummayText Length"></p><h3 id="建立Tokenizer"><a href="#建立Tokenizer" class="headerlink" title="建立Tokenizer"></a>建立Tokenizer</h3><p>通过分词器生成词汇表，并将单词文本序列转为数值序列，方便计算机计算。</p><h3 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h3><ol><li>我们可以选择是否让LSTM在每个时间步都会生成隐藏状态h和记忆单元状态c。</li><li>选择LSTM是否仅生成最后一个时间步的隐藏状态h和记忆单元状态c。</li><li>选择LSTM相互堆叠提高模型效果。</li><li>选择双向LSTM，可以双向处理文本数据，获取更加丰富的上下文信息。</li><li>使用beam search strategy代替贪婪方法argmax。</li><li>根据BLEU分数评估模型的性能。</li><li>可以选择指针生成网络，</li><li>因为整数序列采用独热编码的方式，所以损失函数采用了稀疏交叉熵，对内存友好。</li></ol><h2 id="数学理解注意力机制"><a href="#数学理解注意力机制" class="headerlink" title="数学理解注意力机制"></a>数学理解注意力机制</h2><ol><li>编码器为源文本序列每一个时间步j都生成了一个隐藏状态值hj。</li><li>相似的工作，解码器为目标文本每一个时间步i都生成了隐藏状态值si。</li><li><p>alignment score: $e_{ij}$。用这个分数表示源文本中的第j步单词与目标文本中第i步单词的关联度。可以用hj与si来计算这个分数值$e_{ij} = score(s_i,h_j)$<br>根据所使用的得分函数的类型，有不同类型的注意力机制。这里列举一些流行的注意力机制：<br><img src="images/LSTM_Attention_ScoreFunction.jpg" alt="ScoreFunction"></p></li><li><p>使用softmax函数对注意力参数的值进行归一化。$a_{ij}=\frac{e_{ij}}{\sum^{T}_{k=1}e_{ik}}$</p></li><li>计算注意力权重$a_{ij}$与编码器hj的隐藏状态乘积的线性总和，以产生注意力上下文向量Ci。$C_{i} = \sum^T_{j=1}a_{ij}h_{ij}$<br><img src="images/LSTM_Attention_C1.jpg" alt="Attention_C1"></li><li>将注意力上一下文向量Ci与目标隐藏层向量si级联以产生新的注意力隐藏层向量Si。$S_i=concatenate([s_{i};C_{i}])$</li><li>将注意力隐藏层向量传入密集层产生yi。$y_{i}=dense(S_{i})$</li></ol><blockquote><p><a href="https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/?utm_source=blog&amp;utm_medium=understanding-transformers-nlp-state-of-the-art-models" target="_blank" rel="noopener">英文原文</a><br>本文由公众号【深度学习视觉】整理。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Text Summarization </tag>
            
            <tag> Attention </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN如何学到图片中的位置信息</title>
      <link href="/blog/4f7ea913.html"/>
      <url>/blog/4f7ea913.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这篇文章解释了CNN是怎么学到图片内的绝对位置信息。探究了CNN到底有没有编码位置信息，这些位置信息在哪些神经元中被编码、这些位置信息又是如何被暴露给神经网络学习的。</p><a id="more"></a><p>这是一篇ICLR2020接收的文章。此前，关注位置信息编码只在NLP的任务中，因为字符位置不同，文本表达的语义不同。但是，CV一直没有这个明显的需求，大家一致认为CNN具有平移不变性。在CV的三大物体感知任务中，分类不需要位置信息，语义分割关注的是像素级别的语义分类，也不觉得需要位置信息(其实位置信息很有用)；也许你会觉得物体检测会用到位置信息，然而，物体检测模型都是通过检测Anchor中的特征做分类工作，最后得到的坐标信息来自于Anchor。</p><p><img src="images/CnnPositionHeatMap.jpg" alt="CnnPositionHeatMap"><br>上图一共有三组图片，每组由原图和剪切图构成。可以发现，显著区域将会因为图片中心位置的改变而改变。</p><h2 id="Position-Encoding-Network"><a href="#Position-Encoding-Network" class="headerlink" title="Position Encoding Network"></a>Position Encoding Network</h2><p><img src="images/CnnPositionEncoding.jpg" alt="CnnPositionEncoding"><br>作者提出了一种提取位置的模型Position Encoding Network(PosENet)。首先挑选VGG和ResNet作为特征提取网络，接着从浅层到深层提取5个leve的特征送入PosENet。其中用bi-linear插值到同一size后concat。最后PosENet的输出是一张能表示位置信息的gradient-like。PosENet模型提取出真实的位置信息，对作者添加的梯度状的图片GT进行拟合。梯度状图片GT图片如下：<br><img src="images/CnnGradientLike.jpg" alt="CnnGradientLike"><br>如果在分类任务上训练的前馈网络能够隐式的学到位置信息，那么作者设计的位置编码模块经过训练后就能对隐藏的位置信息与梯度状的图片GT之间的关系进行建模，如果特征图中没有编码的位置信息，那么输出将是随机的。</p><h2 id="具体实验"><a href="#具体实验" class="headerlink" title="具体实验"></a>具体实验</h2><h3 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h3><p>作者做了如图所示的实验：<br><img src="images/CnnPosENetResults.jpg" alt="CnnPosENetResults"><br>其中最左边一列是输入，第二列是GT，第三列是没有backbone直接接入position encoding module，第四列用VGG backbone，第五列resnet backbone。其中backbone的参数都冻结，position encoding module都不padding。</p><p>第三列表明没有backbone的pretrain权重，网络无法通过输入直接映射到gt。在没有padding的情况下，输出只会响应在输入的具体内容上，不能预测和内容无关的位置信息。第四、五列说明了pretrain的网络输出的特征中编码了位置信息，这帮助了后面接的position encoding module预测到gt。</p><h3 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h3><p>下图可以看出PosENet（VGG和ResNet）可以很容易地从经过训练的CNN模型中提取位置信息，特别是基于ResNet的PosENet模型。然而，单独训练PosENet（PosENet）直接从图像来预测的得分要低得多(并且越深的特征层效果越好)。这一结果表明，仅从输入图像中提取位置信息是非常困难的。只有与深度编码网络相耦合，PosENet才能提取出与地面真实位置图一致的位置信息。<br><img src="images/CnnPositionComparison.jpg" alt="CnnPositionComparison"></p><h3 id="padding影响"><a href="#padding影响" class="headerlink" title="padding影响"></a>padding影响</h3><p>从下图可以看出，随着pad数增加，可视化结果越接近gt。<br><img src="images/CnnPositionPadding.jpg" alt="CnnPositionPadding"></p><h2 id="文章最终得到的结论"><a href="#文章最终得到的结论" class="headerlink" title="文章最终得到的结论"></a>文章最终得到的结论</h2><p>CNN隐性的编码了位置信息，并且随着网络层数的增加和卷积核的增加，即感受野的增加，能够更好的编码位置信息。其中，这个位置信息是由zero-padding造成的，图像边缘的zero-padding提供了图像的边界信息。本来，网络是不知道每个像素点或者特征点的位置。但是，通过padding的zero，提供给模型一个相对位置信息，知道每个特征点距离zero边界的距离信息。</p><blockquote><p>论文地址：<a href="https://openreview.net/attachment?id=rJeB36NKvB&amp;name=original_pdf" target="_blank" rel="noopener">How much position information do convolutional neural networks encode?</a><br>公众号:深度学习视觉</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络能否直接判断奇偶数</title>
      <link href="/blog/c31606b1.html"/>
      <url>/blog/c31606b1.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="神经网络判断奇偶数"><a href="#神经网络判断奇偶数" class="headerlink" title="神经网络判断奇偶数"></a>神经网络判断奇偶数</h2><p>拥有神经网络的深度学习比机器学习的一大特点是，深度学习的非线性转换能够实现一定程度上的特征提取和特征组合。但是，当你传入一批自然数进入模型中训练，想要预测奇偶性的时候，你会发现，这个任务有点难。但是，如果你将这些数值转为二进制的时候，这个任务又变得可行。可以看出，深度学习也需要我们做一下数据的预处理工作。当然，也侧边看出了神经网络并非万能。<br><a id="more"></a></p><p><strong>1. 神经网络如何针对当前的任务建立模型</strong><br>比如检测，分割，分类等问题。这些问题都有一个共同点，同一个类别的目标在高维空间里也在同一个区域。这样在高维空间里，我们的神经网络将这些空间分割成多个块，每个块预测出一个类别，就能达到很高的指标。</p><p><strong>2. 神经网络为什么无法直接通过自然数数据直接构建特征预测奇偶性</strong></p><blockquote><p>作者:王赟 Maigo(Facebook 研究科学家)</p></blockquote><p>机器学习里面有一个「没有免费午餐」定理（No Free Lunch Theorem）：任意一种算法，如果对于某些类型的问题效果好，必然对于另一些类型的问题效果差。各种模型都有自己的先验假设，如果数据分布符合这个先验假设，学习效果就好，否则就差。比如很多模型都假设数据是线性可分的，对于线性不可分的数据效果就不好。</p><p><strong>不平滑的输入导致难以拟合</strong><br>机器学习适合处理的问题，一般都有这么一个特点：在特征空间中相近的输入，对应的输出一般也相近（暂且称为「平滑性」）。这是机器学习能够把从训练数据中学到的知识推广（generalize）到新数据上的前提。如果一个问题不「平滑」，也就是说，输入稍微变一点儿，输出往往都会有巨大的变化，那么机器学习一般就会表现得惨不忍睹。</p><p>比如，如果直接输入自然数0,1,2,3,…n(n很大)，这就是一个典型的「不平滑」问题：输入稍微变动一点儿(从2变成相邻数3)，输出就会有很大变动(从一个标签转为另一个标签)。还有一个例子是，输入是若干个布尔特征，输出是它们的异或。那么，输入中有一个布尔值发生了变化，就会导致输出发生翻天覆地的变化。在自然语言处理中，也会存在一个字的改变，导致整个句子的语义发生改变，所以给模型加入了先验，使用了word embedding 来刻画单词之间的距离和位置关系。</p><p><strong>激活函数的影响</strong><br>奇偶判断的核心规律是周期性，与relu是完全违背的，这些激活函数都没有太多的转折，不会像周期性函数cos/sin把特征空间切得很碎，relu可以看作只有两段区域。强行使用relu会使得神经网络需要拟合数轴上的每个数，无法完成任何泛化。当然，如果以后让激活函数具有周期性，那么也许也可以解决这类周期性的问题。但是损失函数的问题又会出现，这类崎岖的损失曲面将会很难找到全局最优解。</p><p><strong>信息论解释</strong><br>从信息论也可以理解，一个所有符号出现概率均等的系统，将无法对符号进行压缩。一个问题的解空间，可以用符号表示，如果对其中特征完全不了解，可以认为所有符号出现的概率均等，也将无法对解空间进行压缩，也就不存在一种相对高效的解法。</p><p><strong>3. 为什么转为二进制之后，神经网络就可以工作了</strong><br>这是因为通过设计合适的特征，把问题转化成一个【平滑】的问题。从信息论的角度来说，奇偶性的信息就藏在二进制的最后一位，信息就在那里，可是神经网络竟然无法捕获它。如果我们把输入数值转换成二进制，每一位作为一个布尔特征，一般的机器学习方法都会很容易地学习到个位特征就对应着答案，而其它特征与答案无关。通过最后一位是0还是1就可以直接判断label, 这是典型的data leakage.</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.zhihu.com/question/364113452" target="_blank" rel="noopener">https://www.zhihu.com/question/364113452</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>凸优化</title>
      <link href="/blog/dda9dbb9.html"/>
      <url>/blog/dda9dbb9.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><h1 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h1><h2 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h2><p><strong>1.基本概念：</strong></p><p>定义：函数$L(\cdot)$是凸函数当且仅当对定义域中的任意两点x,y和任意实数$\lambda\in[0,1]$总有$L(\lambda x+(1-\lambda) y) \leqslant \lambda L(x)+(1-\lambda) L(y)$</p><p>直观解释：凸函数曲面上任意两点的连线而成的线段，其上的任意一点都不会处于该函数曲面的下方。<br><img src="images/凸优化-01.png" alt="image.png"></p><p><strong>2.实例讲解：</strong></p><p>对于<strong>二分类</strong>问题，$Y=\{1,-1\}$,假设模型参数为$\theta$，则逻辑回归的优化问题为：</p><p>$\min _{\theta} L(\theta)=\sum_{i=1}^{n} \log \left(1+\exp \left(-y_{i} \theta^{\mathrm{T}} x_{i}\right)\right)$</p><p>可以通过计算目标函数的二阶Hessian矩阵来验证：</p><p>$L_{i}(\theta)=\log \left(1+\exp \left(-y_{i} \theta^{\top} x_{i}\right)\right)$</p><p>对该函数求一阶导，得到：</p><p>$\begin{aligned} \nabla L_{i}(\theta) &amp;=\frac{1}{1+\exp \left(-y_{i} \theta^{\mathrm{T}} x_{i}\right)} \exp \left(-y_{i} \theta^{\mathrm{T}} x_{i}\right) \cdot\left(-y_{i} x_{i}\right) \\ &amp;=\frac{-y_{i} x_{i}}{1+\exp \left(y_{i} \theta^{\mathrm{T}} x_{i}\right)} \end{aligned}$ </p><p>继续求导，得到函数的Hessian矩阵：<br>$\begin{aligned} \nabla^{2} L_{i}(\theta) &amp;=\frac{y_{i} x_{i} \cdot \exp \left(y_{i} \theta^{\mathrm{T}} x_{i}\right) \cdot y_{i} x_{i}^{\mathrm{T}}}{\left(1+\exp \left(y_{i} \theta^{\mathrm{T}} x_{i}\right)\right)^{2}} \\ &amp;=\frac{\exp \left(y_{i} \theta^{\mathrm{T}} x_{i}\right)}{\left(1+\exp \left(y_{i} \theta^{\mathrm{T}} x_{i}\right)\right)^{2}} x_{i} x_{i}^{\mathrm{T}} \end{aligned}$</p><p>该矩阵满足半正定的性质$\nabla^{2} L_{i}(\theta) \succeq 0$，因此$\nabla^{2} L(\theta)=\sum_{i=1}^{n} \nabla^{2} L_{i}(\theta) \geq 0$，函数$L(\cdot)$为凸函数。对于凸优化问题，所有的局部极小值都是全局极小值。</p><p><strong>主成分分析</strong>对应的优化问题是非凸优化问题。令$X=\left[x_{1}, \ldots, x_{n}\right]$为数据中心后构成的矩阵，则主成分分析的优化问题为$\min_{V V^{T}=I_{k}} L(V)=\left|X-V^{T} V X\right|_{F}^{2}$，通过凸函数的定义可以验证该优化问题的目标函数为非凸函数。令 $V^*$为优化问题的全局极小值，</p><p>则 $ -V^* $也是该问题的全局极小值，且有：</p><script type="math/tex; mode=display">\begin{aligned} L\left(\frac{1}{2} V^{*}+\frac{1}{2}\left(-V^{*}\right)\right)=L(0) &=\|X\|_{\mathrm{F}}^{2}>\left\|X-V^{* \mathrm{T}} V^{*} X\right\|_{\mathrm{F}}^{2} \\ &=\frac{1}{2} L\left(V^{*}\right)+\frac{1}{2} L\left(-V^{*}\right) \end{aligned}</script><p>这不满足凸函数的定义，因此主成分分析的优化问题为非凸优化问题。</p><p><strong>3.知识补充：</strong></p><p>定义：设$A$是实对称矩阵。如果对任意的实非零列向量$x$有$x^TAx≥0$，就称A为半正定矩阵。如果$x^TAx&gt;0$,则为正定矩阵。<br>几何解释：正定/半正定矩阵$A$指的是一个向量经过$A$的变化后的向量与其本身的夹角小于/小于等于90度。</p><p>实数矩阵与其转置矩阵相乘为半正定矩阵，如果可逆，则为正定矩阵。</p><p><strong>一些明显的凸函数：</strong></p><ol><li>指数函数是凸函数；</li><li>对数函数是凹函数，然后负对数函数就是凸函数；</li><li>对于一个凸函数进行仿射变换，可以理解为线性变换，结果还是凸函数；</li><li>二次函数是凸函数（二次项系数为正）；</li><li>高斯分布函数是凹函数；</li><li>多个凸函数的线性加权，如果权值是大于等于零的，那么整个加权结果函数是凸函数。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 凸优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CBNet组合主干网络</title>
      <link href="/blog/3477354.html"/>
      <url>/blog/3477354.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><h2 id="论文目标"><a href="#论文目标" class="headerlink" title="论文目标"></a>论文目标</h2><ol><li>每次一个新的网络出现都需要经过高代价的ImageNet预训练处理。</li><li>现存主干网络都是为分类场景设计，直接拿来用，效果并不能做到最优。</li></ol><p>综上在现有主干网络的基础上建立一个更有强大的主干网络，称为复合主干网络。</p><hr><a id="more"></a><h2 id="论文主要做法"><a href="#论文主要做法" class="headerlink" title="论文主要做法"></a>论文主要做法</h2><p><img src="images/CBNet_1.png" alt=""></p><p>组合连接邻近独立优秀主干网络，CBNet 将前一个主干网络的输出特征（即高层抽象特征）输入到下一个主干网络的对应层级中，一直到最后一个主干网络（Lead Backbone），然后使用 Lead Backbone 的特征图进行目标检测。通过这样做，将多个高级和低级特性融合在一起，以生成更丰富的特征表示。本网络结构的预训练模型参数来自于每个独立的网络。</p><p><img src="images/CBNet_2.png" alt=""></p><p>四种主干组合的形式：</p><ol><li><p><strong>邻近高级组合：</strong>（Adjacent Higher-Level Composition，AHLC）来自辅助主干网的每个输出特征使用复合连接块输入到相邻的主干网中。</p></li><li><p><strong>同层组合：</strong>（Same Level Composition，SLC）是另一种简单的合成样式，它将前一个主干的相邻低层阶段的输出提供给后一个主干。如图所示，此样式不使用复合连接块。来自低层主干网的特征被直接添加到相邻的主干网中。</p></li><li><p><strong>邻近低层组合：</strong>（Adjacent Lower-Level Composition，ALLC）非常类似于AHLC。唯一不同的是，来自前一个主干网底层的特征被传递给后续的主干网。</p></li><li><p><strong>密集高层组合：</strong>（Dense Higher-Level Composition，DHLC）的灵感来自DenseNet，每一层都连接到所有后续的层，在一个阶段建立一个稠密的连接。</p></li></ol><p>这四种组合方式，AHLC效果较好：</p><p><img src="images/CBNet_3.png" alt=""></p><hr><h2 id="论文效果"><a href="#论文效果" class="headerlink" title="论文效果"></a>论文效果</h2><ol><li>它将 FPN、Mask R-CNN 和 Cascade R-CNN 在 COCO 数据集上的 mAP 提升了 1.5%-3.0%。</li><li>简单地将 CBNet 集成到基线检测器 Cascade Mask R-CNN，即可实现单个模型在 COCO 数据集上的mAP达到 53.3。</li></ol><p><img src="images/CBNet_4.png" alt=""></p><p><img src="images/CBNet_5.png" alt=""></p><hr><h2 id="特征提取效果"><a href="#特征提取效果" class="headerlink" title="特征提取效果"></a>特征提取效果</h2><p>研究者认为 CBNet 性能优于单个目标检测主干网络的根本原因是：相比于后者，CBNet 提取出的基础特征更具表示性。</p><p><img src="images/CBNet_6.png" alt="CBNet (Dual-ResNet101) 和原始主干网络 (ResNet101) 提取特征的视觉对比，基线检测器为 FPN-ResNet101"></p><p>　对于每一个主干网络，上图根据前景物体的大小，对 Res2 和 Res5 进行可视化。我们可以看到 CBNet 的特征图更具表示性，它的前景物体激活值更大，背景的激活值更小。</p><h2 id="论文代码"><a href="#论文代码" class="headerlink" title="论文代码"></a>论文代码</h2><blockquote><p><a href="https://arxiv.org/pdf/1909.03625.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1909.03625.pdf</a><br><a href="https://github.com/PKUbahuangliuhe/CBNet" target="_blank" rel="noopener">https://github.com/PKUbahuangliuhe/CBNet</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 物体检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习问答</title>
      <link href="/blog/ee15081e.html"/>
      <url>/blog/ee15081e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="感知器与逻辑回归的区别"><a href="#感知器与逻辑回归的区别" class="headerlink" title="感知器与逻辑回归的区别"></a>感知器与逻辑回归的区别</h3><p>多层感知器是我们用于分类的最基本的神经网络之一。在二分类问题上，线性分类器的目的就是找一个超平面把正负两类分开，感知器相当于一个阶跃函数，直接区分是0还是1，而逻辑回归则是给予0到1之间的概率。当然，如果我们调节逻辑回归的阈值，使得输出非0即1，则就成了感知器。<br><a id="more"></a></p><p><img src="images/DeepLearningQuestion21_1.jpg" alt="DeepLearningQuestion21_1"></p><p>感知器的损失函数为误分类点的函数间隔之和，函数间隔可以理解为样本与分类超平面的距离。误分类点距离分类超平面越远，则损失函数值越大。只有误分类的点会影响损失函数的值。</p><p>$L=-y(w^Tx+b)$ </p><p>$w^Tx+b$是分割的超平面</p><ol><li><p>当正类数据分类到-1结果中，y=1，但超平面对应的值为-1，此时损失值大于0。</p></li><li><p>当负类数据分类到1结果中，y=-1，但超平面对应的值为1，此时损失值大于0。</p></li></ol><p>Logistic回归的损失函数为logistic损失函数，当分类错误时，函数间隔越大，则损失函数值越大。当分类正确时，样本点距离超平面越远，则损失函数值越小。所有的样本点分布情况都会影响损失函数最后的值。模型更加平滑。</p><p>$log(1+exp(-y(w^Tx+b)))$</p><h3 id="权重和偏差在神经网络中起什么作用"><a href="#权重和偏差在神经网络中起什么作用" class="headerlink" title="权重和偏差在神经网络中起什么作用"></a>权重和偏差在神经网络中起什么作用</h3><p>$w_1x_1 + w_2x_2 + w_3x_3 + … + w_nx_n &gt;= b$</p><p>简单来说，权重就是某个因素的重要程度，bias值其实就是一个阈值，只有当左边部分不小于这个bias的时候，神经元的输出才会为正。</p><p>也有理解，这里的bias是所选模型自带的固有的误差，因为选的模型必不可能是完美的，bias与数据无关，是模型自带的。</p><p>并且，在有些场合里，bias的使用也没有意义，比如在batch normalization层之前的层就没必要加，因为会被归一化抵消掉。</p><h3 id="可否令隐藏层所有神经元具有相同的bias"><a href="#可否令隐藏层所有神经元具有相同的bias" class="headerlink" title="可否令隐藏层所有神经元具有相同的bias"></a>可否令隐藏层所有神经元具有相同的bias</h3><p>本质上，在每个层或每个神经元处也可以具有不同的偏差值。但是，最好对隐藏层中的所有神经元都只有一个偏差矩阵。</p><h3 id="激活函数的作用"><a href="#激活函数的作用" class="headerlink" title="激活函数的作用"></a>激活函数的作用</h3><p>由于非线性的激活函数的存在，使得模型可以捕获非线性关系。如果没有激活函数，那么无论多深的网络都只是简单的线性模型，无法捕获数据中的复杂模式。</p><h3 id="神经网络中权重初始化的值都一样会怎么样"><a href="#神经网络中权重初始化的值都一样会怎么样" class="headerlink" title="神经网络中权重初始化的值都一样会怎么样"></a>神经网络中权重初始化的值都一样会怎么样</h3><p>如果所有神经元具有相同的权重值，则每个隐藏单元将获得完全相同的信号。尽管这可能在正向传播过程中起作用，但反向传播期间损失函数的导数每次都将会相同。最终模型将会欠拟合。</p><h3 id="前向传播与反向传播的工作原理"><a href="#前向传播与反向传播的工作原理" class="headerlink" title="前向传播与反向传播的工作原理"></a>前向传播与反向传播的工作原理</h3><p><strong>前向传播：</strong>在每个隐藏层，我们计算每个节点上激活的输出，然后进一步传播到下一层，直到到达最终输出层。由于我们从输入端开始到最终输出层，因此我们向前移动，这称为前向传播。</p><p><strong>反向传播：</strong>为了最小化损失函数，我们从最终损失函数开始，并通过链式法则计算每个隐藏层的梯度，返回到每个隐藏层，这时我们向后移动，因此称为反向传播。</p><p><img src="images/bp_fp_1.jpeg" alt="bp_fp_1"></p><p><strong>前向传播:</strong></p><p><img src="images/fp.jpg" alt="fp"></p><p><strong>反向传播:</strong></p><p><img src="images/bp_l2.jpg" alt="bp_l2"></p><p><img src="images/bp_l1.png" alt="bp_l1"></p><h3 id="深度学习常用的数据类型"><a href="#深度学习常用的数据类型" class="headerlink" title="深度学习常用的数据类型"></a>深度学习常用的数据类型</h3><p>深度学习含有从最简单的数据结构（如列表）到复杂的数据结构（如计算图）的数据类型。</p><p><strong>List：</strong>元素的有序序列。</p><p><strong>Matrix：</strong>具有行和列的元素的有序序列。</p><p><strong>Dataframe：</strong>数据框就像矩阵一样，但是它包含实际数据，其中列名和行表示数据集中的每个数据点。</p><p><strong>Tensors：</strong>张量在PyTorch和TensorFlow中都使用，就像深度学习的基本编程单元一样。就像多维数组一样，我们可以对它们执行许多数学运算。</p><p><strong>Computation Graphs：</strong>计算图为我们提供了执行操作的顺序，每个节点表示神经网络中的操作或组件。</p><h3 id="为什么要使用Batch-Normalization"><a href="#为什么要使用Batch-Normalization" class="headerlink" title="为什么要使用Batch Normalization"></a>为什么要使用Batch Normalization</h3><p>关于一些其他归一化方法，可以看这篇文章<a href="https://fainke.com/blog/7d202220.html">深度学习归一化</a></p><p>模型将归一化后的输入传入激活函数。</p><ol><li><p>加快模型收敛的速度的技术。</p></li><li><p>解决了梯度消失的问题。</p></li><li><p>增加了模型泛化能力，使得dropout技术可以去掉。</p></li></ol><h3 id="例举一些激活函数"><a href="#例举一些激活函数" class="headerlink" title="例举一些激活函数"></a>例举一些激活函数</h3><p><a href="https://fainke.com/blog/6a3ffb6e.html">ReLu系列激活函数</a></p><p><img src="images/activationFunction.jpg" alt="activationFunction"></p><h3 id="为什么CNN在图像上表现很好"><a href="#为什么CNN在图像上表现很好" class="headerlink" title="为什么CNN在图像上表现很好"></a>为什么CNN在图像上表现很好</h3><p>CNN本质是在识别曲线和边缘信息。直接将图像数据作为输入，不仅无需人工对图像进行预处理和额外的特征抽取等复杂操作，而且以其特有的细粒度特征提取方式，使得对图像的处理达到了几近人力的水平。</p><h3 id="为什么RNNs在文本上表现很好"><a href="#为什么RNNs在文本上表现很好" class="headerlink" title="为什么RNNs在文本上表现很好"></a>为什么RNNs在文本上表现很好</h3><p>RNNs的循环特性为下一节点保留前一节点的信息。</p><h3 id="CNN中的填充方式Valid与Same之间的区别"><a href="#CNN中的填充方式Valid与Same之间的区别" class="headerlink" title="CNN中的填充方式Valid与Same之间的区别"></a>CNN中的填充方式Valid与Same之间的区别</h3><p><strong>valid padding</strong>：不进行任何处理，只使用原始图像，不允许卷积核超出原始图像边界。当余下部分不够卷积核大小时，直接舍去。</p><p><strong>same padding</strong>：进行填充，允许卷积核超出原始图像边界，并使得卷积后结果的大小与原来的一致。使得余下部分能够参与卷积，所以padding一些数据。</p><h3 id="梯度消失与梯度爆炸"><a href="#梯度消失与梯度爆炸" class="headerlink" title="梯度消失与梯度爆炸"></a>梯度消失与梯度爆炸</h3><p><a href="https://fainke.com/blog/c1d77713.html">梯度消失与梯度爆炸</a></p><h3 id="LSTM是如何解决梯度消失与梯度爆炸"><a href="#LSTM是如何解决梯度消失与梯度爆炸" class="headerlink" title="LSTM是如何解决梯度消失与梯度爆炸"></a>LSTM是如何解决梯度消失与梯度爆炸</h3><p>LSTM是一种RNNs模型，由于添加了门控结构，所以可以记住关键信息，梯度不会随着时间步长的增加而消失。</p><h3 id="为什么GRU比LSTM更快"><a href="#为什么GRU比LSTM更快" class="headerlink" title="为什么GRU比LSTM更快"></a>为什么GRU比LSTM更快</h3><p>GRU取消了遗忘门，将输入和“忘记”门组合到一个更新门中。元素的减少使得模型复杂度降低，所以更快。</p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FasterRCNN结构梳理</title>
      <link href="/blog/8e69a262.html"/>
      <url>/blog/8e69a262.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Faster R-CNN最突出的贡献就在于提出了Region Proposal Network（RPN）代替了Selective Search，从而将候选区域提取的时间开销几乎降为0（2s -&gt; 0.01s）<br><a id="more"></a></p><h2 id="结构梳理"><a href="#结构梳理" class="headerlink" title="结构梳理"></a>结构梳理</h2><p>一切都要从一张图的特征开始说起：features。<br><img src="images/RPN_ROIHead.png" alt="RPN_Roi Head.png"></p><p><strong>RPN</strong>接到features后，先做了一次3x3的卷积，再由两个1x1卷积操作分别得到分类score:2x9与位置偏移loc:4x9结构，这两个结构都会被ProposalCreator与rpn_loss所使用。</p><p><strong>AnchorTargetCreator</strong>用box与anchor联合得到拟合目标：loc与label。这里前景与背景的label总数为256，loc图外的标记为-1。</p><p><strong>RPN_LOSS</strong>将会利用上述预测信息与标签信息计算loss，以此来调整使得RPN网络预测的score与loc更好。只对前景计算回归损失。</p><p><strong>ProposalCreator</strong>的任务是拿到score与loc后，将loc转为roi，按照分数筛选先取12000，再通过极大值抑制去除重叠后再按照score选取前2000个roi。</p><p><strong>ProposalTargetCreator</strong>将ProposalCreator中得到的2000个roi与标签box利用ROU再进行筛选，留下正负样本共128个。</p><p><strong>ROI Pooling</strong>层得到这128个rois后，对其坐标对应到特征图，size缩小为1/stride（1/16）。这里在对应的时候，会存在无法整除的现象，所以后来又提出了ROI Align。对应好之后，还要对roi 实施Pooling操作，使得对应好的roi特征图池化到后面层能处理的大小（7x7），在这里还是有量化损失。<br><img src="images/ROI_Pooling.gif" alt="ROI_Pooling.gif"></p><p><strong>FC 21与FC 84</strong>分别得到20+1（背景）类的分类与目标的位置。得到的数据将会与<strong>ProposalTargetCreator</strong>中的真实标签计算<strong>roi_loss</strong>。</p><p><strong>名词解释：</strong><br>roi =  [y_min,x_min,y_max,x_max]，实际原图坐标。<br>loc = [dy, dx, dh, dw]各个位置的偏移。</p><h2 id="关于box的回归讲解："><a href="#关于box的回归讲解：" class="headerlink" title="关于box的回归讲解："></a>关于box的回归讲解：</h2><p>$t_* $包含真实框与预测框的平移量($t_x,t_y$)和尺度缩放($t_w,t_h$)</p><script type="math/tex; mode=display">\begin{array}{c}{t_{x}=\left(G_{x}-P_{x}\right) / P_{w},(6)} \\ {t_{y}=\left(G_{y}-P_{y}\right) / P_{h},(7)} \\ {t_{w}=\log \left(G_{w} / P_{w}\right),(8)} \\ {t_{h}=\log \left(G_{h} / P_{h}\right),(9)}\end{array}</script><p>目标函数为：</p><script type="math/tex; mode=display">d_{* }(P)=w_{* }^{T}\Phi_{5}(P)</script><p>其中$\Phi_{5}(P)$是输入Proposal的特征向量，w_* 是要学习的参数( * 表示x,y,w,h)， d_*(P)是得到的预测值。 计算目的是让t_*与d_*(P)之间的差距最小，得损失函数为：</p><script type="math/tex; mode=display">Loss=\sum_{i}^{N}\left(t_{*}^{i}-\hat{w}_{*}^{T}\phi_{5}\left(P^{i}\right)\right)^{2}</script><p>函数优化目标：</p><script type="math/tex; mode=display">W_{*}=\operatorname{argmin}_{w_{*}}\sum_{i}^{N}\left(t_{*}^{i}-\hat{w}_{*}^{T}\phi_{5}\left(P^{i}\right)\right)^{2}+\lambda\left\|\hat{w}_{*}\right\|^{2}</script><p><strong>为什么$t_x,t_y$要除以宽高：</strong><br>因为，特征图具有尺度不变性，无论之前图像的大小，最终形成的特征图的都是一样的，所以移动的比例都是一样的，所以要除以宽高。</p><p><strong>为什么$t_w,t_h$要取对数：</strong><br>因为缩放尺度必须是正数，刚好exp函数满足要求，反函数即为log。</p><p><strong>线性函数拟合非线性函数：</strong><br>特征图与参数的运算是线性运算，而对数运算是非线性运算，这是很显然无法拟合的。但是，在IOU较大的时候对数运算可以近似为线性运算。<br>高数中的基本公式：$\lim _{x=0} \log (1+x)=x$<br>所以可以得到：</p><script type="math/tex; mode=display">t_{w}=\log \left(G_{w} / P_{w}\right)=\log \left(\frac{G_{w}+P_{w}-P_{w}}{P_{w}}\right)=\log \left(1+\frac{G_{w}-P_{w}}{P_{w}}\right)</script><p>可以看到，当$G_w-P_w=0$的时候，才会是线性函数，也就是预测值与真实值要足够近，只有满足该条件才可以很好的回归Box，否则，就算FasterRcnn有两次回归运算都无法处理一些相差很大的box,更别说其它one stage算法。为了处理这类问题，一般需要统计数据中的边框类型，设置合适的Anchor长宽比与大小。除此之外，用Cascade RCNN提高前景roi的质量也是一种方法。</p><h2 id="IOU-两个框的交并比"><a href="#IOU-两个框的交并比" class="headerlink" title="IOU:两个框的交并比"></a>IOU:两个框的交并比</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def compute_iou(box1, box2, wh&#x3D;False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    compute the iou of two boxes.</span><br><span class="line">    Args:</span><br><span class="line">        box1, box2: [xmin, ymin, xmax, ymax] (wh&#x3D;False) or [xcenter, ycenter, w, h] (wh&#x3D;True)</span><br><span class="line">        wh: the format of coordinate.</span><br><span class="line">    Return:</span><br><span class="line">        iou: iou of box1 and box2.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if wh &#x3D;&#x3D; False:</span><br><span class="line">        xmin1, ymin1, xmax1, ymax1 &#x3D; box1</span><br><span class="line">        xmin2, ymin2, xmax2, ymax2 &#x3D; box2</span><br><span class="line">    else:</span><br><span class="line">        xmin1, ymin1 &#x3D; int(box1[0]-box1[2]&#x2F;2.0), int(box1[1]-box1[3]&#x2F;2.0)</span><br><span class="line">        xmax1, ymax1 &#x3D; int(box1[0]+box1[2]&#x2F;2.0), int(box1[1]+box1[3]&#x2F;2.0)</span><br><span class="line">        xmin2, ymin2 &#x3D; int(box2[0]-box2[2]&#x2F;2.0), int(box2[1]-box2[3]&#x2F;2.0)</span><br><span class="line">        xmax2, ymax2 &#x3D; int(box2[0]+box2[2]&#x2F;2.0), int(box2[1]+box2[3]&#x2F;2.0)</span><br><span class="line"></span><br><span class="line">    ## 获取矩形框交集对应的左上角和右下角的坐标（intersection）</span><br><span class="line">    xx1 &#x3D; np.max([xmin1, xmin2])</span><br><span class="line">    yy1 &#x3D; np.max([ymin1, ymin2])</span><br><span class="line">    xx2 &#x3D; np.min([xmax1, xmax2])</span><br><span class="line">    yy2 &#x3D; np.min([ymax1, ymax2])</span><br><span class="line"></span><br><span class="line">    ## 计算两个矩形框面积</span><br><span class="line">    area1 &#x3D; (xmax1-xmin1) * (ymax1-ymin1) </span><br><span class="line">    area2 &#x3D; (xmax2-xmin2) * (ymax2-ymin2)</span><br><span class="line"></span><br><span class="line">    inter_area &#x3D; (np.max([0, xx2-xx1])) * (np.max([0, yy2-yy1]))　#计算交集面积</span><br><span class="line">    iou &#x3D; inter_area &#x2F; (area1+area2-inter_area+1e-6)　＃计算交并比</span><br><span class="line"></span><br><span class="line">    return iou</span><br></pre></td></tr></table></figure><h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for object in all objects:</span><br><span class="line">    (1) 获取当前目标类别下所有bbx的信息</span><br><span class="line">    (2) 将bbx按照confidence从高到低排序,并记录当前confidence最大的bbx</span><br><span class="line">    (3) 计算最大confidence对应的bbx与剩下所有的bbx的IOU,移除所有大于IOU阈值的bbx</span><br><span class="line">    (4) 对剩下的bbx，循环执行(2)和(3)直到所有的bbx均满足要求（即不能再移除bbx）</span><br></pre></td></tr></table></figure><p>NMS是对所有的类别分别执行的。举个栗子，假设最后预测出的矩形框有2类（分别为cup, pen）,在NMS之前，每个类别可能都会有不只一个bbx被预测出来，这个时候我们需要对这两个类别分别执行一次NMS过程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">class Bounding_box:</span><br><span class="line">    def __init__(self, x1, y1, x2, y2, score):</span><br><span class="line">        self.x1 &#x3D; x1</span><br><span class="line">        self.y1 &#x3D; y1</span><br><span class="line">        self.x2 &#x3D; x2</span><br><span class="line">        self.y2 &#x3D; y2</span><br><span class="line">        self.score &#x3D; score</span><br><span class="line"></span><br><span class="line">def get_iou(boxa, boxb):</span><br><span class="line">    max_x &#x3D; max(boxa.x1, boxb.x1)</span><br><span class="line">    max_y &#x3D; max(boxa.y1, boxb.y1)</span><br><span class="line">    min_x &#x3D; min(boxa.x2, boxb.x2)</span><br><span class="line">    min_y &#x3D; min(boxa.y2, boxb.y2)</span><br><span class="line">    if min_x &lt;&#x3D; max_x or min_y &lt;&#x3D; max_y:</span><br><span class="line">        return 0</span><br><span class="line">    area_i &#x3D; (min_x - max_x) * (min_y - max_y)</span><br><span class="line">    area_a &#x3D; (boxa.x2 - boxa.x1) * (boxa.y2 - boxa.y1)</span><br><span class="line">    area_b &#x3D; (boxb.x2 - boxb.x1) * (boxb.y2 - boxb.y1)</span><br><span class="line">    area_u &#x3D; area_a + area_b - area_i</span><br><span class="line">    return float(area_i) &#x2F; float(area_u)</span><br><span class="line"></span><br><span class="line">def NMS(box_lists, k):</span><br><span class="line">    box_lists &#x3D; sorted(box_lists, key&#x3D;lambda x: x.score, reverse&#x3D;True)</span><br><span class="line">    NMS_lists &#x3D; [box_lists[0]]</span><br><span class="line">    temp_lists &#x3D; []</span><br><span class="line">    for i in range(k):</span><br><span class="line">        for j in range(1, len(box_lists)):</span><br><span class="line">            iou &#x3D; get_iou(NMS_lists[i], box_lists[j])</span><br><span class="line">            if iou &lt; 0.7:</span><br><span class="line">                temp_lists.append(box_lists[j])</span><br><span class="line">        if len(temp_lists) &#x3D;&#x3D; 0:</span><br><span class="line">            return NMS_lists</span><br><span class="line">        box_lists &#x3D; temp_lists</span><br><span class="line">        temp_lists &#x3D; []</span><br><span class="line">        NMS_lists.append(box_lists[0])</span><br><span class="line">    return NMS_lists</span><br><span class="line"></span><br><span class="line">box1 &#x3D; Bounding_box(13, 22, 268, 367, 0.124648176)</span><br><span class="line">box2 &#x3D; Bounding_box(18, 27, 294, 400, 0.35818103)</span><br><span class="line">box3 &#x3D; Bounding_box(234, 123, 466, 678, 0.13638769)</span><br><span class="line">box_lists &#x3D; [box1, box2, box3]</span><br><span class="line">NMS_list &#x3D; NMS(box_lists, 2)</span><br><span class="line">print (NMS_list)</span><br><span class="line">print (NMS_list[0].x1)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FasterRCNN </tag>
            
            <tag> 图像检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Haar特征</title>
      <link href="/blog/da5401e0.html"/>
      <url>/blog/da5401e0.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>当下的人脸检测主要为以下两种方法：</p><ol><li>基于<strong>知识</strong>的检测方法：检测器官特征和器官之间的几何关系</li><li>基于<strong>统计</strong>的检测方法：像素相似性度量</li></ol><p>基于知识的方法主要利用先验知识将人脸看作器官特征的组合，根据眼睛、眉毛、嘴巴、鼻子等器官的特征以及相互之间的几何位置关系来检测人脸。</p><p>基于统计的方法则将人脸看作一个整体的模式——二维像素矩阵，从统计的观点通过大量人脸图像样本构造人脸模式空间，根据相似度量来判断人脸是否存在。</p><p>本文主要介绍的是基于统计的检测方法Haar，Haar特征值反映了图像的灰度变化情况。通过改变特征模板的大小和位置，可在图像子窗口中穷举出大量的特征。<br><a id="more"></a></p><p><strong>Haar分类器=Haar-like特征+AdaBoost算法+级联+积分图</strong><br>要理解Haar分类器，那么就需要理解构成它的每一部分。<br>Haar-like特征：检测提供基础特征；<br>积分图：为了加速特征的计算而使用的算法；<br>AdaBoost：训练区分人脸与非人脸强分类器；<br>级联：把强分类器级联在一起，提高准确率。</p><h3 id="Haar特征其数目计算"><a href="#Haar特征其数目计算" class="headerlink" title="Haar特征其数目计算"></a>Haar特征其数目计算</h3><p>w=白色区域像素之和-黑色区域像素之和<br>得到的就是这个区域的一个特征值，这个特征值可以用来区分人脸与非人脸。当然，一个特征的区分度是很有限的。为了增加区分度，可以对多个矩形特征计算得到一个区分度更大的特征值，然而在一个窗口中怎样排列能够更好的体现人脸的特征，这是未知的所以需要AdaBoost算法去训练找到，在训练前需要将每种组合穷举出来，为了增加计算特征值的速度，使用了积分图（单独写一篇文章）。</p><p><img src="images/Haar_1.png" alt="Haar_1"></p><p><strong>特征数计算</strong><br>比如上图中的1(a)特征，特征大小为2x1，在24x24的图像上，水平可滑动23步，垂直可滑动24步。当特征水平放大为4*1后，水平滑动步数为24-4+1=21步数。其步数随特征放大递减，python代码可表示为range(1,23+1,2)，总共个数为sum(range(1,23+1,2))=144。同理垂直方向计算得到的特征总个数为sum(range(1,24+1,1))=300。整个1(a)的特征个数为144*300 = 43200。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def getHaar(W,H,w,h):</span><br><span class="line">    X &#x3D; int(W&#x2F;w)</span><br><span class="line">    Y &#x3D; int(H&#x2F;h)</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    for i in range(1,X+1):</span><br><span class="line">        for j in range(1,Y+1):</span><br><span class="line">            for x in range(1,W-i*w+1+1):</span><br><span class="line">                for y in range(1,H-j*h+1+1):</span><br><span class="line">                    count+&#x3D;1     </span><br><span class="line">    return count</span><br></pre></td></tr></table></figure></p><p>同理其它类型的特征数目也可以计算得到。但是，对于45rotated的特征，其矩形框的宽，高（w,h）表示如图所示。W,H为图片大小。</p><p><img src="images/Haar_2.png" alt="Haar_2"></p><hr><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>下图是我们用三个Haar-like特征f1，f2，f3来判断输入数据是否为人脸。</p><p><img src="images/Haar_3.png" alt="Haar_3"></p><p>一个弱分类器就是一个基本和上图类似的决策树，最基本的弱分类器只包含一个Haar-like特征，也就是它的决策树只有一层，被称为树桩（stump）。</p><hr><p><strong>弱分类器</strong>的训练即是找到一个分类阈值使其成为最优弱分类器。<br>寻找的步骤：<br>1.对于每个特征f，计算所有训练样本的特征值，并按特征值大小排序。<br>2.扫描排序好的特征值，对排序好的<strong>每个元素</strong>，计算四个值。<br>3.全部人脸样本的权重之和t1;<br>4.全部非人脸样本的权重之和t0;<br>5.在此元素之前的非人脸样本的权重之和s0；<br>6.最终得到每个元素的分类误差r=min((s1+(t0-s0)),(s0+(t1-s1)))<br>7.寻找r值最小的元素作为最优阈值。<br><strong>补充</strong><br>这最优的weak classifier是这么得来的，比如说对于特征A 我们用特征A对所有样本取特征值，然后根据特征值排序所有样本，可以想象，具有明显人脸特征的样本和具有明显非人脸特征的样本应该分别处于这个排序的两端，但肯定有一些样本 不是那么明显就能被A特征区分开，我们要做的是在其中取一个阈值。想象一个点在排好序的直线上滑动 滑动到某一个位置，使得我们能够最好的用特征A区分人脸和非人脸，也就是说，错误率最低，若得到这个阈值，则此时我们找到一个相对特征A的最优weak classifier。由此类推，对所有的特征都如法炮制。我们会得到对应于n个特征的n个最优weak classifier，从里面选一个最最优的，最后得出你想要的那个最优weak classifier。</p><hr><p><strong>强分类器</strong>的诞生需要T轮的迭代，具体操作如下：</p><ol><li>给定训练样本集S，共N个样本，其中X和Y分别对应于正样本和负样本； T为训练的最大循环次数；　　</li><li>初始化样本权重为1/N ，即为训练样本的初始概率分布；　</li><li>第一次迭代训练N个样本，得到第一个最优弱分类器。</li><li>提高上一轮中被误判的样本的权重；</li><li>将新的样本和上次本分错的样本放在一起进行新一轮的训练。</li><li>循环执行4-5步骤，T轮后得到T个最优弱分类器。</li><li>组合T个最优弱分类器得到强分类器。</li></ol><hr><h3 id="论文列表："><a href="#论文列表：" class="headerlink" title="论文列表："></a>论文列表：</h3><blockquote><p>【1】《Rapid Object Detection using a Boosted Cascade of Simple Features》</p><p>【2】《Robust Real-Time Face Detection》</p><p>【3】《An Extended Set of Haar-like Features for &gt;Rapid Object Detection》</p><p>【4】《Crytographic Limitations on Learning Boolean Formulae and Finite Automata》</p><p>【5】《A Theory of the Learnable》</p><p>【6】《The Computational Complexity of Machine Learning》</p><p>【7】《The Strength of Weak Learnability》</p><p>【8】《Boosting a weak learning algorithm》</p><p>【9】《A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting》</p><p><a href="https://www.cnblogs.com/ello/archive/2012/04/28/2475419.html" target="_blank" rel="noopener">https://www.cnblogs.com/ello/archive/2012/04/28/2475419.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Haar </tag>
            
            <tag> 人脸检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ImageNet图像分类对抗攻击-方案整理</title>
      <link href="/blog/9c9393d0.html"/>
      <url>/blog/9c9393d0.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p> -<br><a id="more"></a></p><p><img src="images/imageNet_1.png" alt="imageNet_1"></p><hr><p>赛题地址：<a href="https://tianchi.aliyun.com/competition/entrance/231761/forum" target="_blank" rel="noopener">https://tianchi.aliyun.com/competition/entrance/231761/forum</a><br>赛题介绍：按照最大浮动32干扰的话，最高分为5。</p><p>方案关键词：<br>模型ensemble；多尺度ensemble；数据增强。</p><hr><h3 id="第一名-Score-4-4"><a href="#第一名-Score-4-4" class="headerlink" title="第一名(Score:4.4)"></a>第一名(Score:4.4)</h3><ol><li>在最初开始，从 ImageNet 数据集中挑选出 1000张可以被线下防御模型正确分类的图片，每一张图片分别属于一个类别。在攻击的时候，直接用 TargetLabel 类别对应的图片作为初始化。</li><li>使用前一次提交的对抗图片作为本次训练的初始化。</li></ol><p>Code：<a href="https://drive.google.com/open?id=1Up1fV-PaiHin3xSqXicsP9yyc1dWUD47" target="_blank" rel="noopener">https://drive.google.com/open?id=1Up1fV-PaiHin3xSqXicsP9yyc1dWUD47</a></p><h3 id="第二名-Score-4-1"><a href="#第二名-Score-4-1" class="headerlink" title="第二名(Score:4.1)"></a>第二名(Score:4.1)</h3><p>本组的方案类似 M-DI2-FGSM，差别在于噪声添加方式:</p><ol><li><p>在梯度下降时添加动量，并把当前梯度依无穷范数$L_{\infty}$作为归一化处理；<a href="https://arxiv.org/pdf/1710.06081.pdf" target="_blank" rel="noopener">文献：Boosting adversarial attacks with momentum</a></p></li><li><p>对三个防御模型的 logits 进行加权求和得到融合的 logits，使用融合 logits 对应的交叉熵损失来进行梯度的求解 <a href="https://arxiv.org/pdf/1710.06081.pdf" target="_blank" rel="noopener">文献：Boosting adversarial attacks with momentum</a>；</p></li><li><p>一定概率对输入图像进行随机的 resize 和 padding 操作 ；<br><a href="https://arxiv.org/pdf/1803.06978.pdf" target="_blank" rel="noopener">文献：1. Improving transferability of adversarial examples with input diversity</a><br><a href="https://arxiv.org/pdf/1711.01991.pdf" target="_blank" rel="noopener">文献：2. Mitigating adversarial effects through randomization</a></p></li><li><p>最终的 loss 融合了不同权重的无目标攻击的 loss 和有目标攻击的 loss；</p></li><li>去除了 FGSM 等攻击方法中用于引导噪声的 sign()，求解梯度时对添加的扰动 $\delta$ 求梯度（与对输入图像 x 求梯度等价）。</li></ol><p>原作者结论：动量、输入变换和融合 logits 对攻击效果的提升非常明显。</p><ol><li>添加动量可以使攻击跳出局部最优，大幅提升对线下模型的攻击成功率和对线上模型的迁移效果；</li><li>对 logits 进行融合比对 loss 进行融合的效果要好，因为 logits 保留了所有类别的分类信息，可以更好地引导攻击的方向；</li><li>对输入进行变换可以使攻击算法无法直接观察到原始输入，减少过拟合，提升样本迁移能力。</li></ol><p>本组融合了无目标攻击的 loss 和有目标攻击的 loss，这样可以引导图像远离原始分类，保证在无法成功进行有目标攻击时也可以有很大概率成功进行无目标攻击。除此之外，因为有目标攻击的得分更高，所以对其 loss 赋予了更高的权重。本组的生成对抗样本的使用的 loss 为：</p><script type="math/tex; mode=display">L\left(X, y^{true}, y^{\text {target}} ; \theta\right)=\mathbf{1}_{y^{true}} \cdot \log (\operatorname{softmax}(l(X ; \theta)))-\beta \cdot \mathbf{1}_{y^{target}} \cdot \log (\operatorname{softmax}(l(X ; \theta)))</script><p>本组使用无穷范数归一化代替 sign()sign() 噪声，一定程度上可以避免产生局部过大的梯度以及随后引入的高频噪声。本组使用的梯度更新过程为：</p><script type="math/tex; mode=display">g_{n+1}=\mu \cdot g_{n}+\frac{\nabla_{\delta} L\left(T(X+\delta ; p), y^{\text {true }}, y^{\text {target }} ; \theta\right)}{\left\|\nabla_{\delta} L\left(T(X+\delta ; p), y^{\text {true }}, y^{\text {target }} ; \theta\right)\right\|_{\infty}}</script><p>最后，本组添加噪声的过程为：<br>$\delta_{n+1} = Clip_{\delta}^{\epsilon} \{ \delta_n + \alpha \cdot g_{n+1} \}$<br>Code：<a href="https://github.com/IDKiro/Attack-ImageNet?spm=5176.12282029.0.0.42813946ZiOCID" target="_blank" rel="noopener">https://github.com/IDKiro/Attack-ImageNet?spm=5176.12282029.0.0.42813946ZiOCID</a></p><h3 id="第三名-Score-3-98"><a href="#第三名-Score-3-98" class="headerlink" title="第三名(Score:3.98)"></a>第三名(Score:3.98)</h3><h4 id="Multi-Scale-Attack"><a href="#Multi-Scale-Attack" class="headerlink" title="Multi-Scale Attack"></a>Multi-Scale Attack</h4><ol><li>实验发现集成图片不同尺寸（Multi-Scale）、水平翻转的损失可以提高性能，损失函数调整为：<br>$L(x,y,target) = \sum_{s \in S}(l(x^s,y,target) + l(x^s_{flip},y,target))$<br>①取S=(0.8, 1, 1.25),Score = 2.49<br>②取S=(0.74,0.8,1,1.20),Score = 2.8<br>③取S=(0.5, 0.74, 0.8, 1, 1.25, 1.5),Score = 3.29</li></ol><h4 id="Ensemble-Attack"><a href="#Ensemble-Attack" class="headerlink" title="Ensemble Attack"></a>Ensemble Attack</h4><ol><li>以 Multi-Scale 得到的结果作为初始值，集成三个预训练模型再次攻击。集成方式为平均三个模型的输出（logits），即$f(x) = \frac{1}{3} \sum_{i=1}^3f_i(x)$</li><li>取S=(0.74,1,1.25),Score=3.89。以此为初始值，再取S=(0.8,1,1.36)，Score=3.95</li><li>融合（同名图片两两比较，选取对 target 类预测概率最高的图片）上述两组图片，得到最终最优成绩：\mathrm{Score} = 3.98Score=3.98。</li></ol><p>Code：<a href="https://github.com/Equationliu/Attack-ImageNet" target="_blank" rel="noopener">https://github.com/Equationliu/Attack-ImageNet</a></p><h3 id="第四名-Score-2-7"><a href="#第四名-Score-2-7" class="headerlink" title="第四名(Score:2.7)"></a>第四名(Score:2.7)</h3><p>将预训练模型和输入图片放到相应目录后，运行python main.py即可得到两种攻击下的对抗样本，分别耗时五分钟、十分钟左右（GTX 1080Ti）<br>Code:<a href="https://github.com/the-butterfly/simple_attack_for_imagenet" target="_blank" rel="noopener">https://github.com/the-butterfly/simple_attack_for_imagenet</a></p><h3 id="第五名-Score"><a href="#第五名-Score" class="headerlink" title="第五名(Score:)"></a>第五名(Score:)</h3><p>本组的攻击方案来自于论文：<a href="https://arxiv.org/pdf/1812.03411.pdf" target="_blank" rel="noopener">Feature Denoising for Improving Adversarial Robustness</a>中的两个模型进行融合，这两个模型是论文中的Resnet152Denoised模型和ResneXt101Denoised模型。此外，本组复现了论文：<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Raff_Barrage_of_Random_Transforms_for_Adversarially_Robust_Defense_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Barrage of Random Transforms for Adversarially Robust Defense</a><br>在算法迭代中本组使用了6个策略：</p><h4 id="1-Input-Diversity"><a href="#1-Input-Diversity" class="headerlink" title="1.Input Diversity"></a>1.Input Diversity</h4><p>来自论文<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Improving_Transferability_of_Adversarial_Examples_With_Input_Diversity_CVPR_2019_paper.html" target="_blank" rel="noopener">《Improving Transferability of Adversarial Examples With Input Diversity》</a>。<br>算法的基本思路是在每次迭代时对图片进行一些小变换。我们在原文变换基础上加多了几种变换（如旋转，翻转）。</p><h4 id="2-Momentum"><a href="#2-Momentum" class="headerlink" title="2.Momentum"></a>2.Momentum</h4><p>来自论文<a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.html" target="_blank" rel="noopener">《Boosting Adversarial Attacks With Momentum》</a>。<br>算法的基本思路是将动量梯度下降的优化方法引入到生成对抗样本的迭代中。</p><h4 id="3-对噪声进行高斯模糊"><a href="#3-对噪声进行高斯模糊" class="headerlink" title="3.对噪声进行高斯模糊"></a>3.对噪声进行高斯模糊</h4><p>来自论文<a href="https://arxiv.org/abs/1904.02884" target="_blank" rel="noopener">《Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks》</a>。<br>对这几个鲁棒模型进行定向攻击的难度非常大。分析原因，是因为其中两个采取了去噪方法，另一个采取了巨量随机变换堆叠的方法，都产生了类似（但不是）梯度掩码的现象，导致在对他们进行梯度型攻击时，梯度包含的信息很少，也就是噪声很干净。为了克服这一点，我们使用了一些策略来挖掘更多的噪声。</p><h4 id="4-可变步长搜索"><a href="#4-可变步长搜索" class="headerlink" title="4.可变步长搜索"></a>4.可变步长搜索</h4><p>在迭代时，计算当前像素点与L无穷范数限制的边界之差，若差越小，则迭代步长越大。实验证明这对增强迁移性和白盒攻击都有效。</p><h4 id="5-目标类图像融合"><a href="#5-目标类图像融合" class="headerlink" title="5.目标类图像融合"></a>5.目标类图像融合</h4><p>在迭代之前按一定比例融合属于目标类的图片。专门为了增强定向攻击使用。实验证明这对增强迁移性有效。</p><h4 id="6-放宽搜索区域"><a href="#6-放宽搜索区域" class="headerlink" title="6.放宽搜索区域"></a>6.放宽搜索区域</h4><p>对于定向攻击，我们使用34的eps作为最大扰动限制，对于非定向攻击，我们使用64的eps作为最大扰动限制。实验证明这对白盒攻击有效。</p><ul><li><p>模型：<br>本次比赛中主要使用的模型是Facebook所提供的三个Tensorflow框架下的模型以及一个复现论文的模型，四个模型下载链接如下：</p><ul><li><a href="https://github.com/facebookresearch/ImageNet-Adversarial-Training/releases/download/v0.1/R152-Denoise.npz?spm=5176.12282029.0.0.22c81c84nkBEjW&amp;file=R152-Denoise.npz" target="_blank" rel="noopener">R152-Denoise.npz</a></li><li><a href="https://github.com/facebookresearch/ImageNet-Adversarial-Training/releases/download/v0.2/X101-DenoiseAll.npz" target="_blank" rel="noopener">X101-DenoiseAll.npz</a></li><li><a href="https://github.com/XttyCTL9/BaRTDefense?spm=5176.12282029.0.0.22c81c84nkBEjW" target="_blank" rel="noopener">复现模型（定向）</a></li><li><a href="https://github.com/facebookresearch/ImageNet-Adversarial-Training/releases/download/v0/R152.npz" target="_blank" rel="noopener">R152.npz（非定向）</a></li></ul></li><li><p>代码：</p><ul><li><a href="https://github.com/XttyCTL9/BaRTDefense" target="_blank" rel="noopener">复现模型代码链接</a></li><li><a href="https://github.com/XttyCTL9/TianchiAdversarial" target="_blank" rel="noopener">攻击算法代码链接</a></li></ul></li><li><p>文件处理方式：</p><ul><li>因为Facebook提供的原模型联合起来有命名问题，所以需要重新压缩重命名。</li><li>解决方案：下载完毕后，使用压缩软件打开，然后解压缩<br>新建一个R152文件夹，将R152.npz解压出的所有文件放入这个文件夹中，重新压缩为zip文件，重命名为R152_rename.npz，但是我们的最终方案中不利用此模型。<br>新建一个R152_Denoise文件夹，将R152-Denoise.npz解压出的所有文件放入这个文件夹中，重新压缩为zip文件，重命名为R152-Denoise_rename.npz<br>新建一个X101_Denoise文件夹，将X101-DenoiseAll解压出的所有文件放入这个文件夹中，重新压缩为zip文件，重命名为X101-DenoiseAll_rename.npz<br>在代码中加载以上npz文件，搜索并修改default=’’中单引号内的内容即可。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像分类 </tag>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA最大方差</title>
      <link href="/blog/8161fe9d.html"/>
      <url>/blog/8161fe9d.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简述：</strong></p><p>PCA是一种线性、非监督、全局的降维算法。在高维的特征数据空间中有可能会包含冗余与噪声，因此需要寻找数据内部的主成分来表征原始数据，从而达到降维与降低训练复杂的目的。<br><a id="more"></a></p><p><strong>求解步骤：</strong></p><p>1.对样本数据进行中心化处理；(使数据分布更具方向性，使得特征向量更具原数据表达性。)</p><p>2.求样本协方差矩阵；</p><p>3.对协方差矩阵进行特征值分解，将特征值从大到小排序；</p><p>4.取特征值前m大对应的特征向量W1,W2,…,Wm,将原n维数据通过这些特征向量映射到m维空间中；</p><p>通过以上步骤即可将方差较小的特征（噪声）抛弃。降维后的信息占比为：m维向量特征值的平方和比上n维向量特征值的平方和。$\sqrt{\frac{\sum_{i=1}^{m} \lambda i^{2}}{\sum_{i=1}^{n} \lambda i^{2}}}$</p><p><strong>原理：</strong></p><p>在信号处理领域，我们认为信号具有较大的方差，噪声有较小的方差。信号与噪声之比称之为信噪比，信噪比越大意味着数据质量越好。因此，PCA的目标即最大化数据投影方差，使得降维导致的信息损失最小化。由公式可得协方差对称矩阵，此时，协方差矩阵的第一特征值大小可表示数据降维后在第一主成分上的方差大小。所以，PCA降维的目的可以说是找到这个协方差矩阵的最大特征值和其所对应的特征向量。</p><p><strong>结语：</strong></p><p>由于PCA是线性降维，具有一定的局限性，所以对于效果不好的复杂数据需要一些非线性降维手段。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 主成分分析 </tag>
            
            <tag> PCA </tag>
            
            <tag> 数据降维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>P_NP_NPC</title>
      <link href="/blog/54dce366.html"/>
      <url>/blog/54dce366.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h1><p><strong>P问题：</strong>一类可以通过<strong>确定性</strong>图灵机在多项式时间内解决的问题集合。<br><strong>NP问题：</strong>一类可以通过<strong>非确定性</strong>图灵机在多项式时间内解决的决策问题集合。<br><strong>P与NP：</strong>任何可以被图灵机在多项式时间内解决的问题都可以被非确定性的图灵机解决，不确定是否是真子集。<br><strong>NPC问题：</strong>一个NPC问题需要同时满足两个条件。①该问题是NP问题；②NP里所有问题可以在多项式时间内转为该问题。<br><strong>NPH问题：</strong>只需要满足NPC中的第二个性质，所以，NPC是NPH的子集。<br><strong>上述元素的近似关系图：</strong><br><img src="images/NP-01.png" alt="image.png"><br><strong>$\mathbf{P} \subseteq \mathbf{co}-\mathbf{N} \mathbf{P}$：</strong><br>①因为P在运算下封闭，如果一个语言在P中，这时他的补语言co-P也在P中。综上得P与co-P都在NP中。<br>②一个语言在co-NP当且仅当他的补语言在NP。综上得P与co-P都在co-NP中。<br><img src="images/NP-02.png" alt="image.png">)<br><strong>补语(复杂性类)：</strong>记为co-C。一个决策问题 X是反C的成员，当且仅当它的互补 X是在复杂类C【维基百科】。补的例子：一个重要问题是数字是否是素数，它的补充是确定一个数字是否是一个复合数，这里补语的域是超过1的所有整数的集合。这个补也许还是一个NP问题，也许不是一个NP问题。</p><h1 id="2-结语"><a href="#2-结语" class="headerlink" title="2.结语"></a>2.结语</h1><p>才疏学浅，如有不正确的言语，还请指出。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NP问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python四大排序算法</title>
      <link href="/blog/61b26bf3.html"/>
      <url>/blog/61b26bf3.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>冒泡排序,选择排序,插入排序,快速排序<br><a id="more"></a></p><h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">alist &#x3D; list(range(10))</span><br><span class="line">random.shuffle(alist)</span><br><span class="line">print(&quot;排序前:&quot;,alist)</span><br><span class="line"></span><br><span class="line">def bubble(alist):</span><br><span class="line">    &quot;&quot;&quot;冒泡排序&quot;&quot;&quot;</span><br><span class="line">    for j in range(0,len(alist)-1):</span><br><span class="line">        count &#x3D; 0</span><br><span class="line">        for i in range(0,len(alist)-1-j):</span><br><span class="line">            if alist[i]&gt;alist[i+1]:</span><br><span class="line">                alist[i],alist[i+1] &#x3D; alist[i+1],alist[i]</span><br><span class="line">                count +&#x3D; 1</span><br><span class="line">        if 0 &#x3D;&#x3D; count :</span><br><span class="line">            break</span><br><span class="line">    return alist</span><br><span class="line"></span><br><span class="line">alist &#x3D; bubble(alist)</span><br><span class="line">print(&quot;排序后:&quot;,alist)</span><br></pre></td></tr></table></figure><h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">alist &#x3D; list(range(10))</span><br><span class="line">random.shuffle(alist)</span><br><span class="line">print(&quot;排序前:&quot;,alist)</span><br><span class="line"></span><br><span class="line">def selectionSort(alist):</span><br><span class="line">    &quot;&quot;&quot;选择排序&quot;&quot;&quot;</span><br><span class="line">    for i in range(len(alist)-1):</span><br><span class="line">        for j in range(i+1,len(alist)):</span><br><span class="line">            if alist[i] &gt; alist[j]:</span><br><span class="line">                alist[i] , alist[j] &#x3D; alist[j] , alist[i]</span><br><span class="line">                </span><br><span class="line">    return alist</span><br><span class="line">alist &#x3D; selectionSort(alist)</span><br><span class="line">print(&quot;排序后:&quot;,alist)</span><br></pre></td></tr></table></figure><h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">alist &#x3D; list(range(10))</span><br><span class="line">random.shuffle(alist)</span><br><span class="line">print(&quot;排序前:&quot;,alist)</span><br><span class="line"></span><br><span class="line">def insertSort(alist):</span><br><span class="line">    &quot;&quot;&quot;插入排序&quot;&quot;&quot;</span><br><span class="line">    for i in range(1,len(alist)):</span><br><span class="line">        for j in range(i,0,-1):</span><br><span class="line">            if alist[j-1] &gt; alist[j]:</span><br><span class="line">                alist[j] , alist[j-1] &#x3D; alist[j-1] , alist[j]</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line">                </span><br><span class="line">    return alist</span><br><span class="line">alist &#x3D; insertSort(alist)</span><br><span class="line">print(&quot;排序后:&quot;,alist)</span><br></pre></td></tr></table></figure><h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">alist &#x3D; list(range(10))</span><br><span class="line">random.shuffle(alist)</span><br><span class="line">print(&quot;排序前:&quot;,alist)</span><br><span class="line"></span><br><span class="line">def fastSort(alist,first,last):</span><br><span class="line">    &quot;&quot;&quot;快速排序&quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    :first 左边开始点</span><br><span class="line">    :last 右边结束点</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    if last &lt;&#x3D; first:</span><br><span class="line">        return  </span><br><span class="line">    mid_value &#x3D; alist[first]</span><br><span class="line">    left &#x3D; first</span><br><span class="line">    right &#x3D; last</span><br><span class="line">    while left &lt; right:</span><br><span class="line">        while left &lt; right and alist[right] &gt;&#x3D; mid_value:</span><br><span class="line">            right -&#x3D; 1</span><br><span class="line">        alist[left] &#x3D; alist[right]</span><br><span class="line"></span><br><span class="line">        while left &lt; right and alist[left] &lt; mid_value:</span><br><span class="line">            left +&#x3D; 1</span><br><span class="line">        alist[right] &#x3D; alist[left]</span><br><span class="line">        </span><br><span class="line">    # left &#x3D;&#x3D; right</span><br><span class="line">    alist[left] &#x3D; mid_value</span><br><span class="line">    </span><br><span class="line">    fastSort(alist,first,left-1)</span><br><span class="line">    fastSort(alist,left+1,last)</span><br><span class="line">    </span><br><span class="line">#     return alist</span><br><span class="line">                </span><br><span class="line">fastSort(alist,0,len(alist)-1)</span><br><span class="line">print(&quot;排序后:&quot;,alist)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python高阶语法随笔</title>
      <link href="/blog/5218e405.html"/>
      <url>/blog/5218e405.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><h2 id="魔法函数"><a href="#魔法函数" class="headerlink" title="魔法函数"></a>魔法函数</h2><p>__str__()：让print打印类，出来的信息可读。</p><p>__repr__()：让print打印的类可读，并且不用print也可读。</p><p>__call__()：让类像函数一样操控。</p><p>__len__()：让类拥有len()方法。</p><p>__setattr__()：让实例可以动态添加新的属性。</p><p>__delattr__()：增加del命令删除属性。</p><p>__getattr__()：在调用本没有的属性时，会触发该函数，返回函数中的内容，不会直接报错。</p><p>__getattribute__()：这是__getattr__的扩充，无论有没有调用的属性，都会返回函数中的内容。</p><p>__setitem__()：让类拥有添加新元素和值的功能</p><p>__getitem__()：获取的功能。</p><p>__delitem__()：与__setitem__相对应。</p><p>__iter__()：给类添加迭代器的功能。</p><p>__del__()：该对象引用数将为0的时候触发该函数。</p><h2 id="修饰函数"><a href="#修饰函数" class="headerlink" title="修饰函数"></a>修饰函数</h2><p>@property：当想把某一个方法定义为属性的时候，可以给函数加上该修饰。<br>@classmethod：定义类函数，可以不用实例化调用。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ReLu激活函数</title>
      <link href="/blog/6a3ffb6e.html"/>
      <url>/blog/6a3ffb6e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p> ReLU函数的计算是在卷积之后进行的，因此它与tanh函数和sigmoid函数一样，同属于非线性激活函数。ReLU函数的倒数在正数部分是恒等于1的，因此在深度网络中使用relu激活函数就不会导致梯度小时和爆炸的问题。并且，ReLU函数计算速度快，加快了网络的训练。不过，如果梯度过大，导致很多负数，由于负数部分值为0，这些神经元将无法激活（可通过设置较小学习率来解决）。<br><a id="more"></a></p><p><img src="images\ReLu.png" alt="ReLu"></p><h2 id="1-ReLu"><a href="#1-ReLu" class="headerlink" title="1.ReLu"></a>1.ReLu</h2><script type="math/tex; mode=display">\operatorname{Re} \mathrm{LU}(\mathrm{x})=\max (\mathrm{x}, 0)=\left\{\begin{array}{l}{0, x<0} \\ {x, x>0}\end{array}\right.</script><p>后向推导过程：设$l$层输出为$z^l$,经过激活函数后的输出为$z^{l+1}$；记损失函数L关于第$l$层的输出$z^l$的偏导为$\delta^{l}=\frac{\partial L}{\partial z^{l}}$,则损失函数L关于第$l$层的偏导为：</p><script type="math/tex; mode=display">\delta^{l}=\frac{\partial L}{\partial z^{l+1}} \frac{\partial z^{l+1}}{\partial z^{l}} \\ =\delta^{l+1} \frac{\partial \operatorname{Re} L U\left(z^{l}\right)}{\partial z^{l}} \\ =\delta^{l+1}\left\{\begin{array}{ll}{1} & {z^{l}>0} \\ {0} & {z^{l}<=0}\end{array}\right.</script><hr><h2 id="2-LeakReLU"><a href="#2-LeakReLU" class="headerlink" title="2.LeakReLU"></a>2.LeakReLU</h2><script type="math/tex; mode=display">LeakReLU(z)=\left\{\begin{array}{ll}{z} & {z>0} \\ {\alpha z} & {z<=0, \alpha=0.1}\end{array}\right.</script><p>在负数部分给予一个小的梯度。由Relu可知损失函数L关于第$l$层的偏导为：</p><script type="math/tex; mode=display">\delta^{l}=\left\{\begin{array}{ll}{\delta^{l+1}} & {z^{l}>0} \\ {\alpha \delta^{l+1}} & {z^{l}<=0, \alpha=0.1}\end{array}\right.</script><hr><h2 id="3-PReLU"><a href="#3-PReLU" class="headerlink" title="3.PReLU"></a>3.PReLU</h2><p>表达式与LeakReLu相同，只不过$\alpha$可以学习。损失函数L关于参数$\alpha$的偏导为：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \alpha}=\frac{\partial L}{\partial z^{l+1}} \frac{\partial z^{l+1}}{\partial \alpha}\\\delta^{l}=\delta^{l+1} \frac{\partial P R e L U\left(z^{l}\right)}{\partial \alpha} \\\delta^{l}=\delta^{l+1}\left\{\begin{array}{ll}{0} & {z^{l}>0} \\ {z^{l}} & {z^{l}<=0}\end{array}\right. \\\delta^{l}=\left\{\begin{array}{ll}{0} & {z^{l}>0} \\ {\delta^{l+1} z^{l}} & {z^{l}<=0}\end{array}\right.</script><hr><h2 id="4-ELU"><a href="#4-ELU" class="headerlink" title="4.ELU"></a>4.ELU</h2><script type="math/tex; mode=display">f(z)=\left\{\begin{array}{ll}{z} & {z>0} \\ {\alpha(\exp (z)-1)} & {z \leq 0}\end{array}\right.</script><p>由LeakRelu可知损失函数L关于第$l$层的偏导为：</p><script type="math/tex; mode=display">\delta^{l}=\left\{\begin{array}{ll}{\delta^{l+1}} & {z^{l}>0} \\ {\alpha \delta^{l+1} \exp \left(z^{l}\right)} & {z^{l}<=0}\end{array}\right.</script><hr><h2 id="5-SELU"><a href="#5-SELU" class="headerlink" title="5.SELU"></a>5.SELU</h2><script type="math/tex; mode=display">\operatorname{SELU}(z)=\lambda\left\{\begin{array}{ll}{z} & {z>0} \\ {\alpha(\exp (z)-1)} & {z<=0}\end{array}\right.</script><p>由ELU可知损失函数L关于第$l$层的偏导为：</p><script type="math/tex; mode=display">\delta^{l}=\lambda\left\{\begin{array}{ll}{\delta^{l+1}} & {z^{l}>0} \\ {\alpha \delta^{l+1} \exp \left(z^{l}\right)} & {z^{l}<=0}\end{array}\right.</script><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p> 当激活值的均值非0时，就会对下一层造成一个bias，如果激活值之间不会相互抵消（即均值非0），会导致下一层的激活单元有bias shift。如此叠加，单元越多时，bias shift就会越大。除了ReLU，其它激活函数都将输出的平均值接近0，从而加快模型收敛，类似于Batch Normalization的效果，但是计算复杂度更低。虽然LeakReLU和PReLU都也有负值，但是它们不保证在不激活状态下（就是在输入为负的状态下）对噪声鲁棒。反观ELU在输入取较小值时具有软饱和的特性，提升了对噪声的鲁棒性。</p><h2 id="题图代码"><a href="#题图代码" class="headerlink" title="题图代码"></a>题图代码</h2><details><summary><b>Python Relu Code</b></summary><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">## 公众号:深度学习视觉</span><br><span class="line">## Author:Fain</span><br><span class="line">## Blog:Fainke.com</span><br><span class="line">#</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">%matplotlib inline</span><br><span class="line">sns.set(style&#x3D;&quot;darkgrid&quot;) </span><br><span class="line">#</span><br><span class="line">fig &#x3D; plt.figure(figsize&#x3D;(12,6))</span><br><span class="line">#</span><br><span class="line">plt.xlim([-10, 10]);</span><br><span class="line">plt.ylim([-1, 1.6]);</span><br><span class="line">#</span><br><span class="line"># 定义数值</span><br><span class="line">x &#x3D; np.sort(np.linspace(-10,10,1000))</span><br><span class="line">#</span><br><span class="line"># ReLu 函数</span><br><span class="line">relu&#x3D; [max(item,0) for item in x]</span><br><span class="line">#</span><br><span class="line"># LeakReLu函数</span><br><span class="line">alpha &#x3D; 0.1</span><br><span class="line">leakRelu &#x3D; [item if item&gt;0 else item*alpha for item in x]</span><br><span class="line">#</span><br><span class="line"># PReLu函数</span><br><span class="line">alpha &#x3D; 0.1 # 可以学习的参数</span><br><span class="line">leakRelu &#x3D; [item if item&gt;0 else item*alpha for item in x]</span><br><span class="line">#</span><br><span class="line"># ELU函数</span><br><span class="line">alpha &#x3D; 0.2</span><br><span class="line">elu &#x3D; [item if item&gt;0 else (np.exp(item)-1)*alpha for item in x]</span><br><span class="line">#</span><br><span class="line"># SELU函数</span><br><span class="line">alpha &#x3D; 1</span><br><span class="line">r &#x3D; 0.5</span><br><span class="line">selu &#x3D; [item if item&gt;0 else (np.exp(item)-1)*alpha for item in x]</span><br><span class="line">selu &#x3D; list(map(lambda x:x*r,selu))</span><br><span class="line">#</span><br><span class="line"># 绘图</span><br><span class="line">plt.plot(x,relu,color&#x3D;&quot;#ff0000&quot;, label &#x3D; r&quot;ReLu&quot;, marker&#x3D;&#39;*&#39;)</span><br><span class="line">plt.plot(x,leakRelu,color&#x3D;&quot;#0000ff&quot;, label &#x3D; r&quot;LeakReLu&quot;)</span><br><span class="line">plt.plot(x,elu,color&#x3D;&quot;#00ff00&quot;, label &#x3D; r&quot;ELU&quot;)</span><br><span class="line">plt.plot(x,selu,color&#x3D;&quot;#00ffee&quot;, label &#x3D; r&quot;SELU&quot;)</span><br><span class="line"></span><br><span class="line">plt.legend(prop&#x3D;&#123;&#39;family&#39; : &#39;Times New Roman&#39;, &#39;size&#39;   : 16&#125;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></details>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 激活函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ScratchDet - Train from Scratch</title>
      <link href="/blog/f5df260e.html"/>
      <url>/blog/f5df260e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>论文名：ScratchDet: Training Single-Shot Object Detectors from<br>论文链接：<a href="https://arxiv.org/pdf/1810.08425.pdfScratch" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.08425.pdfScratch</a></strong></p><h3 id="这篇论文主要的贡献如下"><a href="#这篇论文主要的贡献如下" class="headerlink" title="这篇论文主要的贡献如下"></a>这篇论文主要的贡献如下</h3><p>(1) 这是一个融入了BatchNorm使得更好地收敛的检测器，在诸如VGG与Resnet上都可以很好的表现。<br>(2) 修改了网络第一层结构，使得检测准确性有明显的提升，尤其是在小物体检测上。<br>(3) SractchDet比最前沿的train_from_scratch还要优秀，甚至比一些基于预训练的网络得到的结果也好。<br><a id="more"></a></p><h3 id="BatchNorm的影响"><a href="#BatchNorm的影响" class="headerlink" title="BatchNorm的影响"></a>BatchNorm的影响</h3><p><img src="images/ScratchDet-01.png" alt=""></p><ol><li>使用BatchSize为128，并且没有加入BatchNorm，最后在VOC2007上得到67.6mAP。</li><li>加上BatchNorm后，得出的结果提升到71.0mAP，并且优化曲面更加平滑，因此可以使用更大的学习率来加速训练。</li><li>大学习率的使用导致更容易跳出局部最优解。修改初始学习率10倍后，得出的结果提升到75.6mAP。</li></ol><p><img src="images/ScratchDet-02.png" alt=""></p><ol><li>BatchNorm的使用，使得在大的learn rate下，使用预训练的结果反而不如不使用预训练的结果。没有BatchNorm的情况下使用大学习率，模型很容易崩溃不收敛。</li></ol><h3 id="第一层下采样的影响"><a href="#第一层下采样的影响" class="headerlink" title="第一层下采样的影响"></a>第一层下采样的影响</h3><p><img src="images/ScratchDet-03.png" alt=""></p><ol><li>一般情况下，RestNet-101优秀于VGG-16，但是，在小输入下（300x300）,基于SSD，VGG-16却在检测上表现得更好。该现象发生的原因是由于Resnet在第一层卷积时的下采样操作（stride=2），而VGGNet第一层stride=1。这点差异使得小目标检测下VGGNet表现得更好。</li><li>为了验证上述观点得正确性，实验中将ResNet-18得第一层下采样修改stride=1，使得结果从73.1mAP提升到77.6mAP。在此之下，又将第二层做了同样的修改，然而这次的实验结果并没有多大的提升。所以，通过实验得到，第一层的下采样对于检测有着重大影响，尤其是小目标的检测。</li></ol><h3 id="四种结构的实验结果"><a href="#四种结构的实验结果" class="headerlink" title="四种结构的实验结果"></a>四种结构的实验结果</h3><p><img src="images/ScratchDet-04.png" alt=""></p><p>图中四种结构在Pascal2012与2007上做训练，在2007test集上做测试的mAP从左到右分别为73.1，75.3，77.6，78.5。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像检测 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Beta分布随笔</title>
      <link href="/blog/6883cd97.html"/>
      <url>/blog/6883cd97.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简介：</strong> beta分布可以看作一个概率的概率分布，描述所有概率出现的可能性大小。</p><p><strong>举例：</strong> 手中有一枚硬币，该硬币均匀度未知，现在让你说出抛一次出现正面的概率是多少。通过以往的先验知识来判断，正面概率为0.5的这个情况的概率最大。<br><a id="more"></a></p><p><img src="images/BetaDistribution_1.png" alt="image.png"></p><p>这张图是取了120次抛币的实验数据画出的Beta分布图，图中给出0.5的正面概率为最高的。假如现在连续抛了10次，8次为正面，那么此时你判断正面朝上最大概率的概率应该是多少。<br><img src="images/BetaDistribution_2.png" alt="image.png"></p><p>通过Beta图像可以看出最大概率的正面概率已经大于0.5。</p><p><strong>与其它分布的联系：</strong><br>以上Beta分布就简单介绍结束，其实写Beta分布是因为最近在研究狄利克雷分布。<br>Beta分布是二项分布的共轭先验概率分布；<br>Dirichlet分布是多项式分布的共轭先验概率分布。<br>Beat分布可以描述二项分布的概率，是二项分布的概率分布。<br>Dirichlet分布可以描述出多项分布的概率，是多项分布的概率分布，会为每个事件选择概率最高的多项分布作为它的分布。在无监督聚类的时候会使用。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据分布 </tag>
            
            <tag> Beta分布 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XGBoost二阶泰勒展开式推导</title>
      <link href="/blog/4fe4eb0b.html"/>
      <url>/blog/4fe4eb0b.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><p><strong>目标函数：</strong> $\mathrm{obj}=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t)}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right)$<br>其中$y_i$是真实值，$\hat{y}_{i}^{(t)}$是总t棵树的预测值，$l$是loss function，$\Omega$是正则项，防止过拟合。$f$是一棵CART树，$f_{t}\left(x_{i}\right)$是输入数据$x_i$后第t棵树的输出值。<br><strong>$\hat{y}_{i}^{(t)}$与$f_{t}\left(x_{i}\right)$的关系为：</strong><br>$\hat{y}_{i}^{(t)}=\sum_{k=1}^{t} f_{k}\left(x_{i}\right)=\hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)$<br><strong>因此，目标函数即可转为：</strong><br>$\begin{aligned} \mathrm{obj}^{(t)} &amp;=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t)}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\ &amp;=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+\text {constant } \end{aligned}$</p><p><strong>泰勒展开公式：</strong> $f(x+\Delta x) \simeq f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}$<br><strong>将损失函数泰勒展开至二阶：</strong><br>$\mathrm{obj}^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)+constant$<br>其中$g_{i}=\partial_{\hat{y}^{(t-1)}} l\left(y_{i}, \hat{y}^{(t-1)}\right)$，$h_{i}=\partial_{\hat{y}^{(t-1)}}^{2} l\left(y_{i}, \hat{y}^{(t-1)}\right)$<br>分别表示对$\hat{y}_{i}^{(t-1)}$求一次与二次偏导。<br>与泰勒展开式对应来看，其中x为$\hat{y}_{i}^{(t-1)}$，$\Delta x$为$f_{t}\left(x_{i}\right)$</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 决策树 </tag>
            
            <tag> XGBoost </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection使用</title>
      <link href="/blog/c7370826.html"/>
      <url>/blog/c7370826.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>1.用conda创建一个新的虚拟环境<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">conda create -n mmdetection python&#x3D;3.7</span><br><span class="line">conda activate mmdetection</span><br><span class="line"></span><br><span class="line"># 安装必要模块</span><br><span class="line">conda install pytorch&#x3D;1.1.0 torchvision&#x3D;0.3.0 cudatoolkit&#x3D;10.0 -c pytorch</span><br><span class="line">pip install cython &amp;&amp; pip --no-cache-dir install -r requirements.txt</span><br><span class="line"></span><br><span class="line"># 安装mmdetection</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;open-mmlab&#x2F;mmdetection.git</span><br><span class="line">cd mmdetection</span><br><span class="line"># 安装</span><br><span class="line">python setup.py install</span><br><span class="line"># 编译</span><br><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure></p><ol><li>demo测试安装是否成功<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#如果安装成功，则该文件可以运行成功。</span><br><span class="line">#coding&#x3D;utf-8</span><br><span class="line"> </span><br><span class="line">from mmdet.apis import init_detector</span><br><span class="line">from mmdet.apis import inference_detector</span><br><span class="line">from mmdet.apis import show_result</span><br><span class="line"> </span><br><span class="line"># 模型配置文件</span><br><span class="line">config_file &#x3D; &#39;.&#x2F;configs&#x2F;cascade_rcnn_r50_fpn_1x.py&#39;</span><br><span class="line"> </span><br><span class="line"># 预训练模型文件</span><br><span class="line">checkpoint_file &#x3D; &#39;..&#x2F;..&#x2F;checkpoints&#x2F;cascade_rcnn_r50_fpn_20e_20181123-db483a09.pth&#39;</span><br><span class="line"> </span><br><span class="line"># 通过模型配置文件与预训练文件构建模型</span><br><span class="line">model &#x3D; init_detector(config_file, checkpoint_file, device&#x3D;&#39;cuda:0&#39;)</span><br><span class="line"> </span><br><span class="line"># 测试单张图片并进行展示</span><br><span class="line">img &#x3D; &#39;demo.jpg&#39;</span><br><span class="line">result &#x3D; inference_detector(model, img)</span><br><span class="line">show_result(img, result, model.CLASSES)</span><br></pre></td></tr></table></figure><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools&#x2F;train.py configs&#x2F;.py --gpus 1</span><br></pre></td></tr></table></figure></li></ol><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><h4 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h4><p>Soft-NMS 改进了之前比较暴力的 NMS，当 IOU 超过某个阈值后，不再直接删除该框，而是降低它的置信度 (得分)，如果得分低到一个阈值，就会被排除；但是如果降低后仍然较高，就会被保留。</p><h4 id="OHEM"><a href="#OHEM" class="headerlink" title="OHEM"></a>OHEM</h4><p>OHEM (online hard example mining)，翻译过来就是在线难例挖掘，就是对所有的 ROI 的损失进行评估，选择损失较大的来优化网络，详情移步：<a href="https://zhuanlan.zhihu.com/p/58162337" target="_blank" rel="noopener">OHEM 论文解读</a></p><h4 id="损失选择"><a href="#损失选择" class="headerlink" title="损失选择"></a>损失选择</h4><p>针对分类的损失函数可以试试如 GHM-C Loss，针对回归的损失函数可以试试如 GHM-R Loss。IOU可以使用 GIou Loss，<a href="https://arxiv.org/abs/1902.09630" target="_blank" rel="noopener">Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</a><br>。</p><h4 id="warmup-lr"><a href="#warmup-lr" class="headerlink" title="warmup lr"></a>warmup lr</h4><p>翻译一下就是对学习率进行预热，最开始是在 ResNet 的论文中提到的一种方法，原始是先在前几个 epoch 或 iter 或目标达到一个水准之前以小于预设值得 lr 进行训练，然后再恢复 lr 到初始值。后来 Facebook 提出了改良版本，详情请移步论文： <a href="https://arxiv.org/pdf/1706.02677v2.pdf" target="_blank" rel="noopener">Gradual warmup</a>[5]</p><h2 id="提分点"><a href="#提分点" class="headerlink" title="提分点"></a>提分点</h2><p>在训练中对gt进行了0.9-1.1的随机缩放以适应不够精确的标注。</p><h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><ol><li><p>若改动框架源代码后，一定要注意重新编译后再使用<br>python setup.py develop</p></li><li><p>所有数值类型不可以轻易改为int64以下，cuda要求数值符合Long类型</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mmdetection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>天池农业AI挑战赛-总结</title>
      <link href="/blog/bf3e34f1.html"/>
      <url>/blog/bf3e34f1.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="赛题社会价值"><a href="#赛题社会价值" class="headerlink" title="赛题社会价值"></a>赛题社会价值</h2><p>通过计算机自动识别大面积卫星图中的物体，有助于预估农产品产量，城市面积等工作。<br><a id="more"></a></p><hr><h2 id="赛题所属类型"><a href="#赛题所属类型" class="headerlink" title="赛题所属类型"></a>赛题所属类型</h2><p>图像分割与分类</p><hr><h2 id="赛题特点"><a href="#赛题特点" class="headerlink" title="赛题特点"></a>赛题特点</h2><ol><li>类间差异小；</li><li>存在标注噪声；</li><li>物体尺度差异大；</li><li>有效物体占比低；</li><li>图片尺寸达到30亿左右的像素，无法直接训练。</li></ol><hr><h2 id="赛题工作"><a href="#赛题工作" class="headerlink" title="赛题工作"></a>赛题工作</h2><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>本次分割的图像中，全局信息很重要，某一个类别的确定会受到它周边像素与类别的影响。<br>本次比赛最佳模型框架deeplab v3+。</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ol><li><p>为了应对图片过大的现象，本次比赛采取了滑动裁剪的方法，每次选取图片大小1024x1024，滑动步长设置为512，剔除无效区域占比过高的样本。由于滑动采样操作会对边缘的预测产生影响，所以，预测结果只保留中间区域（512x512）。</p></li><li><p>一些常规的数据增强方法。</p></li></ol><h3 id="训练处理"><a href="#训练处理" class="headerlink" title="训练处理"></a>训练处理</h3><ol><li><p>本次分类使用的是多分类交叉熵损失函数，并为不同类别添加不同的权重。</p></li><li><p>标签平滑。采取软标签训练，区别于0和1的这样的硬标签，可以为难易程度不同的样本给予不同程度的标签值。</p></li><li><p>使用半监督的方式，为没有标签的图片生成软标签，增加样本。</p></li><li><p>因为数据集比较小，即使使用了各种数据增强技术，还是会有过拟合的风险，可以选取多个snapshot使用参数均值的方法对模型参数进行融合可以提高模型的泛化能力。但是传统的方法是对一个模型进行多次训练来取得多个snapshot，这会需要很多的计算时间。相比之下，根据不同评价标准选择融合的snapshot，也就是选择最小验证loss，最大mIoU，和训练最后（通常是训练loss最小）的三个模型参数进行融合。为了增加三个模型的差异性，可以采用Cyclic Cosine Annealing的方法。反复进入多个局部最小值。</p></li></ol><p><img src="images/detective_1.png" alt=""></p><h3 id="预测结果处理"><a href="#预测结果处理" class="headerlink" title="预测结果处理"></a>预测结果处理</h3><ol><li>由于预测生成的图片会存在一些毛刺，小连通域等现象。所以，采取了一些图像的膨胀与腐蚀的处理。<a href="https://fainke.com/blog/61e6e20f.html">形态学开运算闭运算</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 语义分割 </tag>
            
            <tag> 实例分割 </tag>
            
            <tag> 图像分割 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>命名实体识别与关系抽取</title>
      <link href="/blog/7119a6b7.html"/>
      <url>/blog/7119a6b7.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="实体关系抽取"><a href="#实体关系抽取" class="headerlink" title="实体关系抽取"></a>实体关系抽取</h2><p>需求方提供与糖尿病相关的中文学术论文及糖尿病临床指南。我们从中抽取实体之间的关系。实体之间的关系共十类。<br><a id="more"></a></p><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>本方案通过枚举所有实体对之间是否有关系建模，所以需要产生所有实体对之间的关系数据(有关系与无关系)。</p><p><strong>正样本与负样本：</strong><br>例子：句子：实体1xxx实体2,xxx实体3。<br>由上述句子可以生成实体1-实体2，实体1-实体3，实体2-实体3，共三个备选样本，假设实体1-实体2为一个正样本(即这两个样本之间有关系)，那么剩余的两种组合即为负样本。当然，这种样本制作方式会带来很高的正负样本比。</p><p><strong>数据分析：</strong><br>通过数据分析，可以得到，两个有关系的实体有71%可能在一个句子中，有21%的可能分布在相邻的两个句子中。</p><p>实体含有的信息：实体名字与其表示的向量，实体位置，</p><p><strong>数据样本生成：</strong></p><ol><li>如果通过常规的句子切割方式，一来诸如半角符号的存在，无法判断是小数点还是句子结束符。二来通过这样的方式生成的样本长度均值在150左右。</li><li>本方案通过将【实体1xxx实体2】这样的结构作为一条样本，但是，考虑到上下文的重要性，又在这样的样本前后追加20个字符【xx实体1xxx实体2xx】。最后的文本长度控制在100左右。中间文本超阈值范围的不计。</li><li>为了再次降低正负样本比例，清除无关实体构成的句子。</li></ol><p><strong>特征制作：</strong></p><ol><li><p>词性特征：将字的所属词的词性进行embedding.</p></li><li><p>词边界特征：通过BIOE标记法获得的标记进行embedding.</p></li><li><p>标记实体所在位置。实体位置标记1，其它字标志为0。</p></li><li><p>由于疾病最后一个字往往比较重要，所以将标注方式换为B(Begin),I(Inside),O(Outside),E(End),S(Single)。多了E和S。</p></li><li><p>实体对之间的距离作为关系。</p></li></ol><p><strong>采用字向量：</strong></p><ol><li>中文的分词困难，特别是医疗领域含有大量的专业词汇。</li><li>对于稀少的专有名词的训练很艰难。</li><li>大量的未登录词，词的覆盖率只有55+%，而字的覆盖率达到90+%</li></ol><p><strong>字向量的选择：</strong></p><ol><li><p>Word2Vec获得的字向量本次实验效果优于Glove.但是由于负样本的上下文环境多种多样，所以引进了动态字向量。动态字词向量含有上下文的语义信息。</p></li><li><p>由于 Word2Vec 和 Glove 学习得到的字向量是固定不变的，即一个字只有一种字向量，显然不适合用于多义词。而 ELMo 算法使用了深度双向语言模型 (biLM)，只训练语言模型，而字向量是在输入句子实时获得的，因此字向量与上下文信息密切相关，可以较好地区分歧义。</p></li><li><p>ELMo 是一种动态词向量算法，在大型的语料库里训练一个 biLSTM (双向LSTM模型)<strong>语言模型</strong>。下游任务需要获取单词词向量的时候，将整个被向量化的句子输入biLSTM（在 ELMo 中使用了 CNN-BIG-LSTM 生成的词向量），利用 biLSTM 的输出作为单词的词向量，包含了上下文信息。可以理解成，biLSTM 是一个函数，函数的输入是一个句子，输出是句子中单词的词向量。</p></li><li><p>biLSTM 中不同层得到的词向量侧重点不同，输入层采用的 CNN-BIG-LSTM 词向量可以比较好编码词性信息，第 1 层 LSTM 可以比较好编码句法信息，第 2 层 LSTM 可以比较好编码单词语义信息。通过多层词向量的融合得到最终词向量，最终词向量可以兼顾多种不同层次的信息。</p></li></ol><p><strong>Loss的设置：</strong></p><p>由于负样本的文本模式复杂多样，无规律可循，所以，对于负样本作为一个类别去预测就会很难提取这个类别的共性特征。因此，将10+1类的预测改为10类的预测，然后设置阈值来区分是不是负样本，这样提高了召回率。</p><p>预测阶段，设t是模型正负样本的判断阈偵：<br>1、如果有预测得分人于等于t，则选取最大得分对应的类别为预测类别；<br>2、如果预测得分均小0，则该样本为负类。</p><p><strong>Loss公式:</strong>$L=log(1+exp(\gamma(m^+ - s_{\theta(x)_{y^+}}))) + log(1+exp(\gamma(m^- + s_{\theta(x)_{c^-}})))$</p><p>m+ = 2.5, 指的是正样本的阈值，要大于2.5。</p><p>m- = 0.5, 指的是负样本的阈值，要小于0.5。</p><p>$\gamma$为模型损失的缩放超参。</p><p>$s_{\theta}$是sigmod函数。</p><p>$c^-$是除了预测正确的类别，第二大预测的分值。</p><p>本Loss比交叉熵Loss的准确率低，但召回率高，F1也高。</p><h3 id="图谱的功能"><a href="#图谱的功能" class="headerlink" title="图谱的功能"></a>图谱的功能</h3><p>查询某一个实体的属性与对应的关系实体。比如疾病与其对应相关的药物，对应的检查方法。关于药物也可以推理出它的用量用法属性。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 实体关系抽取 </tag>
            
            <tag> 命名实体识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【故障检测】LGSPP-Bayes</title>
      <link href="/blog/864b817.html"/>
      <url>/blog/864b817.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h3><ol><li>在大规模且复杂性高的数据中及时检测故障愈发重要，面对该问题出现了诸多数据降维算法。</li><li>PCA与其衍生算法虽然可以降低数据的复杂型，但是只考虑了数据的全局结构。</li><li>局部保持投影LPP算法能够发现原始高维数据的内在特征或非线性结构，通过该算法得到的投影子空间保存了原始样本点的局部信息。</li><li>结合了PCA与LPP的LGSPP算法将原始数据投影到具有相似局部结构的低维空间的同时也保证在低维空间中数据方差最大化。</li><li>贝叶斯分类是模式识别中一种利用概率统计进行分类的散发，具有方法简单、分类准确率高、速度快的特点。所以，在使用LGSPP处理高维数据后，在使用Bayes来进行故障检测。<a id="more"></a></li></ol><h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><ol><li>对训练样本数据进行标准化处理；</li><li>计算处理后的训练样本$X$的协方差矩阵$C$;</li><li>分别计算相似矩阵$W$，对角线矩阵$D$以及拉普拉斯矩阵$L$；</li><li>计算前m个最大特征值对应的特征向量$A=a1,a2,…,al(l&lt;=m)$;</li><li>对降维矩阵$A$计算降维空间的样本均值向量$m_{fi}$和样本方差阵$S_{fj}$;</li><li>计算Bayes函数$g_i(x)$,使用该函数进行检测与识别。</li></ol><h3 id="LGSPP算法介绍"><a href="#LGSPP算法介绍" class="headerlink" title="LGSPP算法介绍"></a>LGSPP算法介绍</h3><ol><li>PCA的目标函数为：<script type="math/tex; mode=display">J(A)_{PCA} = \mathop{max}\limits_A\sum_{i=1}^n(y_i-\overline y)^2 = \mathop{max}\limits_A\sum_{i=1}^nA^T(x_i - \overline x)(x_i - \overline x)^TA = \mathop{max}\limits_A A^TCA</script></li></ol><p>其中:</p><script type="math/tex; mode=display">\overline y = \frac{1}{n}\sum_{i=1}^ny_i ，\overline x = \frac{1}{n} \sum_{i=1}^nx_i</script><p>协方差阵</p><script type="math/tex; mode=display">C = \frac{1}{n}\sum_{i=1}^n(x_i - \overline x)(x_i - \overline x)^T</script><p>符合矩阵$A = [a_1,a_2,…,a_l]$为与协方差矩阵前$l$个最大特征值对应的特征向量，$l$为所选主元的个数</p><ol><li>LPP的目标函数为：<script type="math/tex; mode=display">J(A)_{LPP} = \mathop{min}_A\sum_{ij}(y_i - y_j)^2W_{ij} = \mathop{min}_A 2\sum_{i=1}^ny_iD_{ii}y_i^T - 2\sum_{ij} y_iW_{ij}y_j^T=\mathop{min}_A A^TXLX^TA = \mathop{min}_A A^T UA</script></li></ol><p>其中：<br>$U=XLX^T$为局部矩阵，<br>$L=D-W$称为拉普拉斯矩阵，<br>$D$为对角线矩阵，对角线元素为矩阵$W$每一列元素之和，即$D_{ij} = \sum_j W_{ij}$。<br>矩阵$W$称为相似性矩阵，当xi与xj互为k最近邻时，$W_{ij} = w(x_i,x_j)$，其中w(x_i,x_j)表示样本间的相似性，可以用欧氏距离或者高斯核函数来衡量。</p><ol><li>LGSPP为了同时保留与原始数据间相同的整体和局部特征，可以最小化LPP与PCA目标函数的比值：<script type="math/tex; mode=display">\mathop{min}_A J(A) = \mathop{min}_A \frac{J(A)_{LPP}}{J(A)_{PCA}} = \mathop{min}_A \frac{A^TUA}{A^TCA}</script>上述问题可以转为如下广义特征值问题：$UA = \lambda CA$。<br>令$A=[a_1,a_2,…,a_m]$，其中$a_i$为上述广义特征值问题的特征向量，如果只保留$A$中与前$l$个最大特征值对应的特征向量，那么原始高维空间中的数据$x$的维数就减少为低维空间数据$y=A^{T} x$的维数。</li></ol><h3 id="基于Bayes分类器的故障检测识别"><a href="#基于Bayes分类器的故障检测识别" class="headerlink" title="基于Bayes分类器的故障检测识别"></a>基于Bayes分类器的故障检测识别</h3><p>假设数据服从正态分布，训练样本的方差阵和均值向量分别为$S_j$和$m_j$，观测样本个数为$n_j$，设$\delta_j$为故障类$w_j$的数据集。</p><script type="math/tex; mode=display">p(x|w_j) \sim N(m_j,S_j)</script><script type="math/tex; mode=display">M_J = \frac{1}{n_j}\sum_{x \in \delta_j}x</script><script type="math/tex; mode=display">S_j = \frac{1}{n_j-1}\sum_{x\in\delta_j}(x-m_j)(x-m_j)^T</script><p>观测x在故障类$w_j$条件下的类条件概率密度函数为(det是求行列式的函数)【公式有修改】：</p><script type="math/tex; mode=display">P(x|w_j) = \frac{1}{\sqrt {(2\pi)}(S_j)^\frac{1}{2}} \exp[-\frac{1}{2}(x-m_j)^TS_j^{-1}(x-m_j)]</script><script type="math/tex; mode=display">P(x|w_j) = \frac{1}{\sqrt{(2\pi)^n(det(S_j))}} \exp[-\frac{1}{2}(x-m_j)^TS_j^{-1}(x-m_j)]</script><p>判别函数【公式有修改】：</p><script type="math/tex; mode=display">g_j(x) = lnP(x|w_j) + lnP(w_j) = -\frac{1}{2}(x-m_j)^TS_j^{-1}(x-m_j)-\frac{n}{2}ln2\pi - \frac{1}{2}ln[det(S_j)]  + lnP(w_j)</script><p>利用LGSPP算法进行降维后得到的投影空间中的样本为$y = A^Tx$，则降维后的样本均值向量和样本方差阵为：</p><script type="math/tex; mode=display">m_{fj} = \frac{1}{n_j}\sum_{x\in\delta_j}A^Tx = A^Tm_j</script><script type="math/tex; mode=display">S_{fj} = \frac{1}{n_j-1}\sum_{x\in\delta_j}(A^Tx - m_{fj})(A^Tx - m_{fj})^T = A^TS_jA</script><p>则Bayes判别函数变为（常数部分去除）：</p><script type="math/tex; mode=display">g_{fj}(x) = -\frac{1}{2}(A^Tx-m_{fj})^TS_i^{-1}(A^Tx-m_{fj}) - \frac{1}{2}ln[det(S_fj)] + lnP(w_j)\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -\frac{1}{2}(x-m_j)^TA(A^TS_jA)^{-1}A^T(x-m_j) - \frac{1}{2}ln[det(A^TS_jA)] + lnP(w_j)</script><p>令训练样本数据分别为无故障正常操作情况下的样本数据以及故障数据，对测试样本x分别计算判别函数，设$g_{f0}(x)$是训练样本为正常数据时的判别函数，$g_{fi}(x)(i = 1,…f)$是训练样本为第$i$类故障数据时的判别函数，比较函数值大小，当$g_{fi}(x) &gt; g_{f0}(x)$时说明测试样本中有故障发生。假设有C类训练样本数据时，分别计算对应的C个判别函数，通过比较C个判别函数值的大小，将测试样本归于最大判别函数值所对应的故障类别。</p><blockquote><p>参考文献：<br>Qin Liu, LGSPP-Bayes for Fault Detection and Diagnosis </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 故障检测 </tag>
            
            <tag> LGSPP </tag>
            
            <tag> Bayes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【故障预测】隐马尔可夫模型HMM</title>
      <link href="/blog/57c7c3ba.html"/>
      <url>/blog/57c7c3ba.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>前言</strong><br>现代设备维修和管理方式要求需要有效地避免设备意外故障停机和定期维修所造成地<strong>欠修</strong>和<strong>过修</strong>的问题，降低维修和管理费用。<br><a id="more"></a></p><p><strong>HMM的优势</strong><br>HMM适用于动态过程时间序列建模并具有强大的时序模式分类能力，特别使用于非平稳、重复再现性不佳的信号分析。</p><p><strong>定义HMM的描述参数</strong><br>HMM定义为$\lambda = (N,M,\pi,A,B)$</p><p><strong>N：</strong>模型中马尔可夫链的状态数目$[s_1,s_2,…,s_N]$。如果记t时刻Markov链所处的状态$q_t$，那么$q_t \in (s_1,s_2,…,s_N)$。</p><p><strong>M：</strong>每个状态可能输出的观测符号数目$[\theta_1,\theta_2,…,\theta_M]$。如果记t时刻Markov链所处的观测值维$O_t$，那么$O_t \in (\theta_1,\theta_2,…,\theta_M)$。</p><p><strong>$\pi$：</strong>初始状态概率分布矢量，$\pi = (\pi_1,\pi_2,…,\pi_N)$。某一时刻处于某一状态的概率。$\pi = P(q_t=s_i),1 \leq i \leq N $。</p><p><strong>A：</strong>状态转移概率矩阵。$A=\{ a_{ij} \}_{NN}$ 。$a_ij = P(q_{t+1}=s_j,q_t = s_i);1\leq i,j\leq N$表示两个状态之间的转移概率。</p><p><strong>B：</strong>观测符号概率分布，$B = \{ b_j(k)\}_{NM}$。其中：$b_j(k) = P(O_t=V_k \mid q_i = s_j)$。对于连续HMM，B是一组观察值概率函数，即$B = \{b_j(X),j=1,2,…,N \}$。</p><p><strong>设备剩余寿命公式</strong></p><script type="math/tex; mode=display">L_{RU} = a_{ii}u(h_i) + u(h_{i+1}) + ... +u(h_N) = a_{ii}u(h_i) + \sum^N_{t=i+1}u(h_t)</script><p>其中$u(h_i),\theta^2(h_i)$分别表示状态驻留时间的均值和方差。$a_{ii}$从最终的状态转移矩阵中得到，表示下一状态还是此态的转移概率。</p><p>假设每个状态驻留时间的密度函数$h_t$服从Gauss分布，状态转移矩阵由最大化$logP(s \lambda,T) = \sum^N_{i=1}logP(d_n,h_i)$得到。其中设备寿命$T = \sum^N_{i=1}D(h_i)$，$D(h_i)$为每个状态的驻留时间。<br>$D(h_i) = u(h_i) + \rho \sigma^2(h_i) $<br>$\rho = (T-\sum^N_{i=1}u(h_i)) / \sum^N_{i=1}\rho^2(h_i)$<br>其中，$u(h_i),\rho^2(h_i)$分布表示驻留时间的均值和方差，由训练得到。</p><p><strong>问题：</strong><br>最大化函数需要写细节。目前从本论文中无法得出。</p><blockquote><p>文献：基于HMM的设备故障预测方法研究 康建设，马伦，李望伟，赵强</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 故障检测 </tag>
            
            <tag> 马尔可夫 </tag>
            
            <tag> HMM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【故障预测】马尔可夫应用综述</title>
      <link href="/blog/c36d69ba.html"/>
      <url>/blog/c36d69ba.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>Ferguson J D</strong>率先将HMM的状态驻留时间显示化，形成隐半马尔可夫模型。【26】<br><a id="more"></a></p><hr><p><strong>Eric Bechhoefer</strong>等人使用HSMM预测了转轴的剩余使用寿命。【27】</p><hr><p><strong>Ming Dong</strong>等人提出了基于HSMM和分段HSMM的故障预测统计建模方法，通过显示高斯概率密度函数建立健康状态驻留时间模型，利用状态时间概率分布预测设备的剩余使用寿命，但是没有考虑状态驻留时间对状态转移概率的影响。【28-30】</p><hr><p><strong>Qingming liu</strong>等人将隐半马尔可夫模型与序列蒙特卡罗方法相结合进行设备的在线健康预测，采用HSMM获取健康状态和状态时间之间的转移概率，SMC描述健康状态和设备监测的观测值之间的概率关系。【31】</p><hr><p><strong>杨志波、董明</strong>提出自回归隐半马尔可夫模型，改进了传统HMM假设各观测量相互独立的问题，但是状态数的划分是通过经验值设定的，不具有通用性。【32】</p><hr><p><strong>李巍华</strong>等人提出了连续隐半马尔可夫模型，可用于时间序列的动态建模，并无需全寿命的先验知识，可用于早期故障的在线检测。【33】</p><hr><p><strong>孙磊、贾云</strong>等人利用动态贝叶斯网络对设备早期异常状态进行了自动识别，该方法可以减少模型参数，提高故障识别率，但是退化过程的识别程度有待进一步划分。【34】</p><hr><p><strong>扈玉辰、姚竹婷</strong>通过经验模式分解(Empirical Mode Decomposition EMD)对故障信号进行分解，将形成的本征模函数作为故障特征输入到HSMM中进行训练，有效地提取了非线性、非平稳信号地特征，加快了参数训练速度，提高了故障识别率，但是EMD特征提取的稳定性有待提高。【35】</p><hr><p><strong>曾庆虎</strong>等人使用核主元分析和小波相关特征尺度熵提取特征向量，以此向量作为HSMM的输入进行训练，建立基于HSMM的设备运行状态分类器与故障预测模型，实现设备退化状态识别与故障预测，并利用滚动轴承的失效数据验证其方法的有效性，并进一步提出了基于KPCA-HSMM的设备退化状态识别算法，消除了多通道观测信息冗余，降低了故障特征维度。【36-38】</p><hr><p><strong>张星辉、李风学</strong>等人提出了基于曲线距离分析(Curvilinear Distance Analysis CDA)和HSMM-DBN(Dynamic Bayesian Networks, HSMM-DBN)相结合的齿轮箱齿轮磨损状态识别方法，该方法利用CDA对非线性信号特征进行降维，并利用HSMM-DBN结构降低复杂模型求解的难度。【39】</p><hr><p><strong>王宁、孙树栋</strong>等人提出一种基于时变转移概率的隐半马尔可夫模型(Duration Dependent HSMM,DD-HSMM)，基于改进的前后向算法使参数估计能够自我更新。【40】</p><hr><p><strong>夏震宇、杨波</strong>对HSMM算法进行了改进，将状态持续时间概率分布连续化并假定其服从威布尔分布，根据各阶段状态持续时间概率，计算各时刻的时变故障状态转移概率，改进后的算法提高了故障预测能力，且更加接近设备退化过程。【41】</p><hr><p><strong>何兆民、王少萍</strong>假设设备从开始使用到最终失效会经历3个退化阶段，并针对3个退化阶段给出了三种不同状态的转移概率，结合初始状态转移矩阵，最终得出随时间变化的状态转移矩阵，但是其3个状态的划分是基于经验假设，不具有通用性。【24】</p><hr><p><strong>张正道、崔宝同</strong>为了提高系统分辨率引入加权系数，并基于模糊C均值聚类方法(Fuzzy c-means,FCM)对输入输出进行聚类，将聚类过程中得到的隶属值作为HSMM的附加参数，有效预知了系统状态之间的转移概率，简化了模型的建模计算过程。【42】</p><hr>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 马尔可夫 </tag>
            
            <tag> HMM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【特征工程】关联规则</title>
      <link href="/blog/82d28521.html"/>
      <url>/blog/82d28521.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="关联规则衡量指标"><a href="#关联规则衡量指标" class="headerlink" title="关联规则衡量指标"></a>关联规则衡量指标</h2><p>关联规则常利用支持度、置信度和增益等三个衡量指标来分别表示其显著性、正确性及价值，通过给定<strong>最小支持度</strong>与<strong>最小置信度</strong>作为支持度与置信度的门槛值，再评估该规则的信息价值和增益。若该规则的支持度与置信度大于或等于所规定的门槛值，表示该规则有助于进行推论，若该规则的增益满足大于1的条件，则表示其发生的条件概率有比原先的概率提高，即该规则有效。<br><a id="more"></a></p><ol><li><p><strong>支持度（support）</strong><br>支持度衡量的是前提项目X与结果项目Y一起出现的概率$P(X \cap Y)$，表示该规则在全部交易记录中出现的比率。去除较小的组合。</p><script type="math/tex; mode=display">Support(X=>Y) = P(X \cap Y)</script></li><li><p><strong>置信度（confidence）</strong><br>置信度衡量的是前提项目X发生的情况下，结果项目Y发生的条件概率$P(Y|X)$，表示在前提项目X发生时，可推得结果项目Y的概率。置信度是衡量关联规则是否具有可信度的指标，通常置信度水平置为0.5。</p><script type="math/tex; mode=display">Confidence(X=>Y)=P(Y|X)=\frac{P(X \cap Y)}{P(X)}</script></li><li><p><strong>增益（lift）</strong><br>增益衡量用于比较置信度与结果项目Y单独发生时两者概率间的大小$P(Y|X)/P(Y)$。增益值的物理意义是比较关联规则置信度与原本结果项目Y发生的概率以衡量该规则的价值和相对效益，因此增益值至少要大于1，表示该关联规则的预测结果比原本表现好，亦即其置信度大于原本结果项目Y发生的概率。<br>$Lift(X=&gt;Y)=\frac{P(Y|X)}{P(Y)}=\frac{P(X \cap Y)}{P(X)P(Y)}$</p></li></ol><p><strong>关联规则衡量指标总结</strong><br>进行数据挖掘时，通常会先设定挖掘所得的规则的支持度与置信度的阈值作为挑选准则。当满足这两个条件后，再判断这些规则的增益值是否大于1，大于则保留。</p><h2 id="关联规则的类型"><a href="#关联规则的类型" class="headerlink" title="关联规则的类型"></a>关联规则的类型</h2><ol><li><p><strong>以规则中属性值的形态为基础</strong><br><strong>布尔关联规则：</strong> 指的是数据中只存在是与否的概念，比如买与不买，贵于不贵。<br><strong>量化关联规则：</strong> 拥有具体数量产生的相关性，比如买多少，贵的具体价格。</p></li><li><p><strong>以规则中所涵盖的数据维度为基础</strong><br><strong>单一维度关联规则：</strong> 规则的项目或属性针对单一维度，比如无论买书还是买笔都是着眼于“买”这个维度。<br><strong>复合维度关联规则：</strong> 规则的项目或属性到达两个以上，比如涉及到用户年龄、性别等多个维度。涉及多个维度时，计算复杂度就会上升，所以可以自定义维度的范围，只对重要的几个维度关联处理。</p></li><li><p><strong>以规则集合中所涵盖的抽象层级为基础</strong><br><strong>单一层级关联规则：</strong> 比如购买书与购买笔。<br><strong>多阶层级关联规则：</strong> 比如购买文具到购买笔。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 关联规则 </tag>
            
            <tag> 特征工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主流分割网络</title>
      <link href="/blog/8105101d.html"/>
      <url>/blog/8105101d.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><h3 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h3><h3 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h3><h3 id="ENet"><a href="#ENet" class="headerlink" title="ENet"></a>ENet</h3><h3 id="CRFasRNN"><a href="#CRFasRNN" class="headerlink" title="CRFasRNN"></a>CRFasRNN</h3><h3 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h3><h3 id="ParseNet"><a href="#ParseNet" class="headerlink" title="ParseNet"></a>ParseNet</h3><h3 id="RefineNet"><a href="#RefineNet" class="headerlink" title="RefineNet"></a>RefineNet</h3><h3 id="ReSeg"><a href="#ReSeg" class="headerlink" title="ReSeg"></a>ReSeg</h3><h3 id="LSTM-CF"><a href="#LSTM-CF" class="headerlink" title="LSTM-CF"></a>LSTM-CF</h3><h3 id="DeepMask"><a href="#DeepMask" class="headerlink" title="DeepMask"></a>DeepMask</h3><p><a href="https://zhuanlan.zhihu.com/p/68456636" target="_blank" rel="noopener">参考文章</a></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像分割 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>似然函数介绍</title>
      <link href="/blog/20f1ce7c.html"/>
      <url>/blog/20f1ce7c.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>概述：</strong>统计学中，似然函数是一种关于统计模型参数的函数。当给定输出$x$时，关于参数$\theta$的似然函数$L(\theta | x)$似然值等于给定参数$\theta$后变量$x$的发生概率$L(\theta | x)=P(X=x | \theta)$。<br><a id="more"></a></p><p><strong>实列：</strong>一枚正反对称值的硬币，做上抛一次正面朝上的概率为0.5，那么上抛三次都为正面的<strong>概率P</strong>为$0.5 <em> 0.5 </em> 0.5=0.125$。但是，如果已知上抛十次硬币，且有七次为正面，三次为反面，则这枚硬币的对称值L(正面朝上的<strong>极大似然值</strong>)为0.7。如果上抛无穷次都为正面朝上的话，那么正面朝上的<strong>极大似然值</strong>就为1，表示接下来抛硬币正面朝上的概率为1。</p><p><strong>求解：</strong>对上述例子进行求解最大似然值。<br>上述抛十次硬币的例子转为公式:$P(A)=p^{7} *(1-p)^{3}$<br>对该式子取对数可得:</p><script type="math/tex; mode=display">\ln (P(A))=\ln \left(p^{7} *(1-p)^{3}\right)=7 \ln (p)+3 \ln (1-p)</script><p>令$ \ln ^{\prime}(P(A))=0$可得$\frac{7}{p}+\frac{3}{p-1}=0 $，求解得p=0.7。表示这种事件的最大概率为0.7。</p><p><strong>公式解说：</strong></p><p>假设样本集$D=\left\{x_{1}, x_{2}, \cdots, x_{N}\right\}$中的样本都是独立分布，似然函数为：$l(\theta)=p(D | \theta)=p\left(x_{1}, x_{2}, \cdots, x_{N} | \theta\right)=\prod_{i=1}^{N} p\left(x_{i} | \theta\right)$，求使似然函数$l(\theta)$最大的$\theta$。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 似然函数 </tag>
            
            <tag> 概率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>余弦距离介绍</title>
      <link href="/blog/a999b398.html"/>
      <url>/blog/a999b398.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>概述</strong>：在机器学习领域中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常用余弦相似度表示。例如将两篇文章向量化，余弦距离可以避免因为文章的长度不同而导致距离偏大，余弦距离只考虑两篇文章生成的向量的夹角。<br><a id="more"></a></p><p>余弦相似度的取值范围是[-1,1]，相同两个向量的之间的相似度为1。</p><p>余弦距离的取值范围是[0,2]。</p><p>余弦相似度的定义公式为： $\cos (A, B)=\frac{A \cdot B}{|A|_{2}|B|_{2}} $</p><p>归一化后:：$|A|_{2}=1,|B|_{2}=1,|A|_{2}|B|_{2}=1$</p><p>余弦距离：</p><p>$\operatorname{dist}(A, B)=1-\cos (A, B)=\frac{|A|_{2}|B|_{2}-A \cdot B}{|A|_{2}|B|_{2}}</p><p>欧式距离：$|A-B|^{2}=|A|<em>{2}^{2}+|B|</em>{2}^{2}-2 A \cdot B=2-2 A \cdot B=2(1-A \cdot B)=&gt;|A-B|=\sqrt{2 d i s t(A, B)}$</p><p>由公式可以看出归一化后，欧式距离与余弦距离存在单调性关系。此时两种距离的值域都为[0,2]。</p><p><strong>欧式距离与余弦距离的对比：</strong></p><p>1.欧式距离的数值受到维度的影响，余弦相似度在高维的情况下也依然保持低维完全相同时相似度为1等性质。</p><p>2.欧式距离体现的是距离上的绝对差异，余弦距离体现的是方向上的相对差异。</p><p><strong>不同情况不同选择：</strong></p><p>1.两个人分别取了蓝球(1,0)与红球(0,1)，这两个向量的欧式距离较小，可是事实是这两个球是不同的,而余弦距离为2表示的是完全不同的意思。所以在这种情况下选择余弦距离更具合理性。</p><p>2.两个人对APP的使用次数与使用时长分别表示为(1,10),(10,100),可知余弦相似度较小，说明这两个人的行为时相同的，可是，事实是不同的，两个人的活跃度有着极大的差异，第二个人的活跃度更高。</p><p><strong>余弦距离满足正定性和对称性，但是不满足三角不等式，因此余弦距离不是一个严格定义的距离。</strong></p><p><strong>距离的定义：</strong></p><p>在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理（正定性，对称性，三角不等式）成立，则该实数可以称为这对元素之间的距离。</p><p><strong>证明：</strong></p><p>1.正定性</p><p>余弦距离公式：$\operatorname{dist}(A, B)=1-\cos \theta$，因为$-1 \leq \cos \theta \leq 1$，所以$\operatorname{dist}(A, B) \geq 0$满足正定性。</p><p>2.对称性：</p><p>$\operatorname{dist}(A, B)=1-\cos (A, B)=\frac{|A|_{2}|B|_{2}-A \cdot B}{|A|_{2}|B|_{2}}=\frac{|B|_{2}|A|_{2}-B \cdot A}{|B|_{2}|A|_{2}}=\operatorname{dist}(B, A)$满足对称性。</p><p>3.三角不等式：</p><p>给定A=(1,0),B=(1,1),C=(0,1)，则有$\operatorname{dist}(A, B)=1-\frac{\sqrt{2}}{2}, \operatorname{dist}(B, C)=1-\frac{\sqrt{2}}{2}, \operatorname{dist}(A, C)=1$，因此有$\operatorname{dist}(A, B)+\operatorname{dist}(B, C)=2-\sqrt{2}&lt;1=\operatorname{dist}(A, C)$，所以得出余弦距离不符合三角不等式。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 余弦距离 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>假设检验-T检验</title>
      <link href="/blog/ab9f665d.html"/>
      <url>/blog/ab9f665d.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>假设检验介绍：</strong><br>由于样本的抽样存在误差，所以出现了假设检验。假设检验是用来判断样本与样本，样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。假设检验的结论是概率性的，不是绝对的肯定或否定。</p><p>检验假设是针对总体特征而言，包括相互对立的两个方面：<strong>零假设</strong>和<strong>备选假设</strong>，它们在逻辑方面是互补的，也就是说，如果其中一个假设为真，则另一个假设为假；如果我们推翻了其中一个假设，那就必须承认另一个假设。<br><a id="more"></a></p><p><strong>样例：</strong><br>假设某种产品要求厚度不高于17.5，现在抽样了一笔数据 [16.9,16.9,16.9,15.8,16.9,17.9,16.9,16.9,16.9,16.9]，均值位16.89，存在一个厚度17.9的产品。那么这批产品是否合格。<br>零假设(H0)：不合格。<br>备选假设(H1)：合格。<br>接下来我们要用统计概率的知识来证明这笔数据合格。<br>计算这笔数据在17.5要求下的t值与概率p<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from scipy import stats</span><br><span class="line">height &#x3D; [16.9,16.9,16.9,15.8,16.9,17.9,16.9,16.9,16.9,16.9]</span><br><span class="line">t,p &#x3D; stats.ttest_1samp(height ,17.5)</span><br><span class="line"># 得到 t&#x3D;-3.893, p&#x3D;0.0036  &#x3D;&gt; p&#x2F;2&#x3D;0.0018</span><br><span class="line"># 0.0036是双侧检验值，这里是左尾单侧检验问题，所以除以2。</span><br><span class="line"># t位负数，表示样本平均数在总体均数的左边。</span><br><span class="line"># p值表示该样本分布下以17.5为均值的概率，0.0018&lt;0.05表示不在接受区域内。</span><br><span class="line"># 在这里，t位负的时候，p越小则产品越满足要求,有足够的证据拒绝原假设H0。</span><br><span class="line"># 如果p&#x2F;2靠近显著水平值0.05时，则产品越接近H0不合格的零假设（原假设）。</span><br></pre></td></tr></table></figure><br><strong>假设检验存在的风险：</strong><br>假设检验是根据样本的情况作的统计推断，该推断存在出错的可能，一般假设检验有如下两类错误。</p><ol><li>Ⅰ型错误，第一类错误、假阳性错误,就是在假设检验作推断结论时，拒绝了实际上是正确的原假设H0，其概率用α表示（拒绝正确）。Ⅰ型错误是针对原假设而言的， α就是事先规定 的 允 许 犯 Ⅰ 型 错 误 的 概 率 值 ， 如 规 定α=0.05，意味着在某特定总体抽样， 100次拒绝H0的假设检验中，最多有5次允许发生第一类错误。与此相应，推断正确的可能性为1-α， 1-α又称为可信度。</li><li>Ⅱ型错误，第二类错误、假阴性错误， 即接受实际上是不成立的H0。就是无效假设原本是不正确的，但所算得的统计量不足以拒绝它，错误地得出了无差别的结论（接受错误）。Ⅱ型错误是针对备择假设而言的，其概率值用β表示。β值的大小一般未知，只有在不同总体特征已知的基础上，按预定的α和n才能做出估算。</li></ol><p><strong>知识补充：</strong></p><ol><li>标准误差SE = S(样本标准差)/sqrt(样本数)</li><li>t检验值t=(样本均值-总体均值)/样本标准差</li><li>t值的正负表示样本数据得均值在总体数据均值的左右。根据查表可以得到概率P，概率P取单侧检验值还是双侧检验值取决于具体任务。</li><li>著名的英国统计家 Ronald Fisher 把1/20 作为标准，即 0.05，称作<strong>显著水平</strong>，小于这个值就表示零假设不成立。</li></ol><div class="table-container"><table><thead><tr><th>假设检验类型</th><th>目的</th><th>案例  </th></tr></thead><tbody><tr><td>单样本检测</td><td>检验单个样本的平均值是否等于目标值。</td><td>抽样的产品的均值是否低于总体均值。</td><td></td></tr><tr><td>相关配对检测</td><td>检验相关样本观测值之差的平均值是否等于目标值。</td><td>验证斯特鲁普效应。</td><td></td></tr><tr><td>独立双样本检测</td><td>检验两个独立样本的平均值是否等于目标值。</td><td>喝牛奶与不喝牛奶的两组人群的身高对比统计。</td><td></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 假设检验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树ID3,C4.5,CART</title>
      <link href="/blog/f56787e3.html"/>
      <url>/blog/f56787e3.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简述：</strong> 决策树是一种自上而下，对样本数据进行树形分类的过程，由节点和有向边组成。节点分为内部节点和叶子节点，其中每个<strong>内部节点</strong>表示一个<strong>特征或属性</strong>，<strong>叶子节点</strong>表示<strong>类别</strong>。决策树常用于分类问题于回归问题，完全生长的决策树模型具有简单直观、解释性强的特点。<br><a id="more"></a></p><h3 id="常用的决策树算法"><a href="#常用的决策树算法" class="headerlink" title="常用的决策树算法"></a>常用的决策树算法</h3><p>通常，我们希望决策树能够低复杂度的拟合训练数据，达到良好的分类效果，但是从若干个决策树中选取最优的决策树是一个NP完全问题。常用的决策树算法有ID3，C4.5，CART。</p><p><strong>ID3-最大信息增益</strong><br>设样本集合为D，类别数为K，数据集D的经验熵表示为：<br>$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log _{2} \frac{\left|C_{k}\right|}{|D|}$<br>其中$C_k$是样本集合D中属于$k$类的样本子集，$|C_k|$表示该子集的元素个数，$|D|$表示样本集合元素个数。<br>再计算某个特征A对于数据集D的经验条件熵$H(D|A)$为：<br>$H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{\left|D \right|}\left(-\sum_{k=1}^{k} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|}\right)$<br>其中，$D_i$表示数据集D中特征A取第$i$个特征的样本子集，$D_{ik}$表示$D_i$中属于第$k$个类别的样本子集。于是信息增益$g(D,A)$可以表示为二者之差，为：<br>$g(D,A)=H(D)-H(D|A)$</p><p><strong>C4.5-最大信息增益比</strong><br>特征A对于数据集D的信息增益比定义为：$g_{R}(D, A)=\frac{g(D, A)}{H_{A}(D)}$<br>其中$H_{A}(D)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|}$称为数据集D关于A的取值熵。</p><p><strong>CART-最大基尼指数（Gini）</strong><br>Gini描述的是数据的纯度，与信息熵含义类似。<br>$\operatorname{Gini}(D)=1-\sum_{k=1}^{n}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}$<br>CART在每一次迭代中选择的基尼指数最小的特征及其对应的切分点进行分类。但与ID3、C4.5不同的是，CART是一颗二叉树，采用二元切割法，每一步将数据按特征A的取值切割成两份，分别进入左右子树。特征A的基尼指数定义为：<br>$\operatorname{Gini}(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \operatorname{Gini}\left(D_{i}\right)$</p><h3 id="ID3，C4-5，CART差异"><a href="#ID3，C4-5，CART差异" class="headerlink" title="ID3，C4.5，CART差异"></a>ID3，C4.5，CART差异</h3><p><strong>从样本类型的角度：</strong><br>ID3只能处理离散型变量，而C4.5和CART都可以处理连续型变量。C4.5处理连续型变量时，通过对数据排序之后找到类别不同的分割线作为切分点，根据切分点把把连续属性转换为布尔型，从而将连续型变量转换成多个取值区间的离散型变量。而对于CART，由于其构建时每次都会对特征进行二值划分，因此可以可以很好的适用于连续型变量。<br><strong>从应用角度：</strong><br>ID3和C4.5只能用于分类任务，而CART(Classification and Regression Tree,分类回归树)既可以用于分类，也可以用于回归任务（回归树使用最小平方误差准则）。<br><strong>从细节、优化过程角度：</strong><br>ID3对样本特征缺失值比较敏感，而C4.5和CART可以对缺失值进行不同方式的处理；ID3和C4.5可以在每个节点上产生多叉分支，且每个特征在层级之间不会复用，而CART每个节点只会产生两个分支，因此最后会形成一颗二叉树，且每个特征可以被重复使用；ID3和C4.5通过剪枝来权衡树的准确性于泛化能力，而CART直接利用全部数据发现所有可能的树结构进行对比。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树剪枝</title>
      <link href="/blog/fdb0cab9.html"/>
      <url>/blog/fdb0cab9.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>为什么要剪枝</strong><br>一颗完全生长的决策树难免会遇到过拟合的情况。因此，我们需要对决策树进行剪枝，提升模型的泛化能力。<br>决策树的剪枝操作通常有两种方法，预剪枝与后剪枝。</p><a id="more"></a><p><strong>预剪枝</strong><br>预剪枝的核心思想是在树中节点进行扩展之前，先计算当前的划分是否能带来模型泛化能力的提升，如果不能，则不再继续生长子树。此时可能存在不同类别的样本同时存于节点中，可以按照多数投票的原则判断该节点所属类别。预剪枝对于何时停止决策树的生长有以下几种方法：<br>(1) 当树达到一定深度的时候，停止树的生长；<br>(2) 当到达当前节点的样本数量小于某个阈值的时候，停止树的生长；<br>(3) 计算每次分裂对测试集的准确度的提升，当小于某个阈值的时候，不再继续生长。<br>预剪枝具有思想直接、算法简单、效率高等特点，适合解决大规模数据的问题。但是，对于上述阈值，需要经验判断。此外，预剪枝有欠拟合的风险，因为，虽然当前的划分会导致测试集准确率降低或提升不高，但在之后的划分中，准确率可能会有显著提升。</p><p><strong>后剪枝</strong><br>后剪枝的核心思想是让算法生成一颗完全生长的决策树，然后自底向上计算是否剪枝。剪枝过程将子树删除，有一个叶子节点替代，该节点的类别同样用投票决定。同样，后剪枝也可以通过在测试集上的准确率来判断，如果剪枝过后准确率有所提升，则进行剪枝。相比于预剪枝，后剪枝的泛化能力更强，但是计算开销会更大。</p><p><strong>后剪枝方法：</strong>错误率降低剪枝(Reduced Error Pruning,REP)、悲观剪枝(Pessimistic Error Pruning,PEP)、代价复杂度剪枝(Cost Complexity Pruning,CCP)、最小误差剪枝(Minimum Error Pruning,MEP)、CVP(Critical Value Pruning)、OPP(Optimal Pruning)等。</p><p><strong>CCP代价复杂度剪枝：</strong><br>(1) 从完整决策树$T_0$开始，生成一个子树序列$\{T_0,T_1,T_2,…,T_n\}$，其中$T_{i+1}$由$T_i$生成。$T_n$为树的根节点（剪到最后只剩根节点）。<br>(2) 在子树序列中，根据真实误差选择最佳的决策树。<br><strong>详细剪枝步骤：</strong><br>步骤(1)从${T_0}$开始，剪枝$T_i$中关于训练数据集合误差增加最小的分支以得到$T_{i+1}$。具体的，当一棵树$T$在节点$t$处剪枝时，它的误差增加可以用$R(t)-R(T_t)$表示，其中$R(t)$表示进行剪枝之后的该节点误差，$R(T_t)$表示未进行剪枝时子树$T_t$的误差。考虑到树的复杂性因素，我们用$|L(T_t)|$表示子树$T_t$的叶子节点个数，则树在节点$t$处剪枝后的误差增加率为$\alpha = \frac{R(t)-R(T_t)} {|L(T_t)|-1}$ 在得到$T_t$后，我们每一步选择$\alpha$最小的节点进行剪枝。</p><p>步骤(2),我们需要从子树序列中选出真实误差最小的决策树。CCP给出了两种常用的方法：一种是基于独立剪枝数据集，该方法与REP类似，但是由于只能从子树序列$\{T_0,T_1,T_2,…,T_n\}$中选择最佳决策树，而非像REP能在所有可能的子树中寻求最优解，因此模型效果上会有一定的不足。另一只方案是采取K折交叉验证来选取最优决策树。</p><p><strong>总结</strong><br>代价复杂度剪枝使用交叉验证策略的时候，不需要用到测试数据集，精度与REP差不多，但形成的树复杂度小。但是，由于生成子树序列的时间复杂度与原始决策树的非叶子节点个数呈现二次关系，导致算法相比REP、PEP、MEP等线性复杂度的后剪枝方法运行时间更大。</p><p>剪枝过程在决策树模型中占据着极其重要的地位，有很多研究表明，剪枝比树的生成更为关键。对于不同划分标准生成的过拟合决策树，在经过剪枝之后都能保留最重要的属性划分，因此最终的性能差距并不大。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>几种主要的数据分布介绍</title>
      <link href="/blog/1876f78f.html"/>
      <url>/blog/1876f78f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>内容范围：正态分布，泊松分布，多项分布，二项分布，伯努利分布</strong></p><p><strong>简述：</strong>正态分布是上述分布趋于极限的分布，属于连续分布。其它属于离散分布。<br><a id="more"></a></p><p><strong>伯努利分布</strong>(两点分布/0-1分布)：<strong>伯努利试验</strong>指的是只有两种可能结果的单次随机试验。如果对伯努利试验独立重复n次则为n重伯努利试验。</p><p>伯努利分布函数为：</p><p>$f(x | p)=\left\{\begin{array}{ll}{p^{x} q^{1-x},} &amp; {x=0,1} \\ {0,} &amp; {x \neq 0,1}\end{array}\right.$</p><p><strong>二项分布：</strong>二项分布是n重伯努利试验成功系数的离散概率分布。硬币正面朝上的概率为p,重复抛n次硬币，k次为正面的概率即为一个二项分布概率。</p><p>二项分布概率分布函数：</p><p>$p(x)=C_{n}^{x} p^{x} q^{n-x}(x=0,1,2,3, n)$其中n是试验次数，x是试验结果为正的次数，q是试验结果为正的概率，1-q是试验结果为负的概率。均值：$\mu=n p$；方差：$\sigma^{2}=n p q$；标准差：$\sigma=\sqrt{n p q}$</p><p><strong>多项分布：</strong>多项分布是二项分布的推广。二项式做n次伯努利实验，规定了每次试验的结果只有两个，如果现在还是做n次试验，只不过每次试验的结果可以有多k个，且k个结果发生的概率互斥且和为1，则发生其中一个结果X次的概率就是多项式分布。多项分布的联合概率函数为：</p><p>$P\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{k}=x_{k}\right)=\frac{n !}{x_{1} ! x_{2} ! \cdots x_{k} !} p_{1}^{x_{1}} p_{2}^{x_{2}} \cdots p_{k}^{x_{k}}$</p><p>多项分布对其每一个结果都有均值和方差，分别为：$E\left(x_{i}\right)=n p_{i}, \operatorname{Var}\left(x_{i}\right)=n p_{i}\left(1-p_{i}\right)$</p><p><strong>泊松分布：</strong>适合用来描述单位时间<strong>/</strong>空间内随机事件发生的个数与其对应的概率。比如某医院平均每小时出生3个婴儿，在这种只知道平均数的情况下预测下一个小时会出生几个和其概率是多少。</p><p>泊松分布概率分布函数：$P(N(t)=n)=\frac{(\lambda t)^{n} e^{-\lambda t}}{n !}$，其中P表示概率，N表示一种函数关系，$\lambda$在这里表示是时间频率，t 在这里表示时间，n 表示数量，P(N(1) = 3) 表示的是1个小时内出生3个婴儿的概率。接下来两个小时，一个婴儿都不出生的概率为</p><p>$P(N(2)=0)=\frac{(3 \times 2)^{0} e^{-3 \times 2}}{0 !} \approx 0.0025$</p><p>可以看出该事件的发生可能性十分小。</p><p>均值：$\mu=\lambda$；方差：$\sigma^{2}=\lambda$</p><p><strong>指数分布：</strong>可以从泊松分布推断出来。如果t时间内没有任何婴儿出生，则：</p><p>$\begin{aligned} P(X&gt;t) &amp;=P(N(t)=0)=\frac{(\lambda t)^{0} e^{-\lambda t}}{0 !} =e^{-\lambda t} \end{aligned}$</p><p>，事件在t之内发生的概率为1减上述的值，为：</p><p>$P(X \leq t)=1-P(X&gt;t)=1-e^{-\lambda t}$</p><p>例如，接下来15分钟，会有婴儿出生的概率是52.76%。</p><p>$\begin{aligned} P(X \leq 0.25) &amp;=1-e^{-3 \times 0.25} \approx 0.5276 \end{aligned}$</p><p><strong>正态分布：</strong>概率密度函数为:$f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)$</p><p>当$\mu=0, \sigma=1$时称为标准正态分布，此时函数为：$f(x)=\frac{1}{\sqrt{2 \pi}} e^{\left(-\frac{x^{2}}{2}\right)}$</p><p><strong>如何评判正态分布：</strong></p><p><strong>1.</strong>  图形感受法：建立直方图或者枝干图，看图像的形状是否类似正态曲线，既土墩形或者钟形，并且两端对称。</p><p><strong>2.</strong>计算区间$\overline{x} \pm s, \overline{x} \pm 2 s, \overline{x} \pm 3 s$，看落在区间的百分百是否近似于68%，95%，100%。</p><p><strong>3.</strong>求IQR和标准差s，计算IQR/s，如若是正态分布，则IQR/s≈1.3。</p><p><strong>4.</strong>  建立正态概率图，如果近似正态分布，点会落在一条直线上。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 正态分布 </tag>
            
            <tag> 泊松分布 </tag>
            
            <tag> 多项分布 </tag>
            
            <tag> 二项分布 </tag>
            
            <tag> 伯努利分布 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anchor尺寸选择</title>
      <link href="/blog/510b302a.html"/>
      <url>/blog/510b302a.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文Link：<a href="https://arxiv.org/pdf/1701.04128.pdf" target="_blank" rel="noopener">Understanding the Effective Receptive Field in Deep Convolutional Neural Networks</a><br>Code:<a href="https://github.com/sfzhang15/SFD" target="_blank" rel="noopener">https://github.com/sfzhang15/SFD</a></p><p>这篇人脸检测器论文依据感受野来设计anchor的大小。</p><p>在物体检测中，Anchor在每一层对应尺度该如何选择。<br><a id="more"></a></p><ol><li>传播间隔相等原则<br>检测层的步长大小决定了anchor的间隔。例如conv3_3的步长为4，而其anchor尺寸为16x16，即每隔4个像素存在一个16x16的anchor，在所有检测层上，anchor的 尺寸均为步长的4倍，即为传播间隔相等原则。从而确保图像上不同尺寸的anchor<strong>密度</strong>相同，使得不同大小人脸能够很好的与anchor匹配上。</li></ol><p>如果网络浅层anchor设计中设计了很多小尺寸的anchor，因此会造成负样本数量剧增，从而引起小尺寸人脸的高false-positive率。<br>那么可以对于每一个小尺寸anchor，进行N次人脸和背景分类，选择其中某个<strong>背景score最高</strong>的一个作为该anchor的score，以此降低误检为人脸的anchor数量，从而降低假阳性率。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anchor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>双流检测Gated-SCNN</title>
      <link href="/blog/ac56438f.html"/>
      <url>/blog/ac56438f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>这篇文章提出two-stream CNN架构，two-stream包括经典网络结构regular stream和处理边界信息的shape stream。这两个处理流并行处理不同的任务，相互协调工作。regular stream可以帮助shape stream只关注边界信息而不被一些无用的噪声干扰；shape stream可以辅助regular stream做更精确的识别。并且该架构在微小物体上有着明显提升。</p><a id="more"></a><p><img src="images/GatedSCNN_1.png" alt="Gated-SCNN.png"></p><h2 id="细节描述"><a href="#细节描述" class="headerlink" title="细节描述"></a>细节描述</h2><h3 id="Shape-Stream是如何工作的"><a href="#Shape-Stream是如何工作的" class="headerlink" title="Shape Stream是如何工作的"></a>Shape Stream是如何工作的</h3><p>作者在Shape Stream中添加了门控结构Gated Convolutional Layer，让Shape Stream将注意力放在它该处理的任务上即边界信息。<br><strong>其中attention map 的公式为：</strong></p><script type="math/tex; mode=display">\alpha_{t}=\sigma\left(C_{1 \times 1}\left(s_{t} \| r_{t}\right)\right)</script><ol><li>$r_t$与$s_t$分别对应regular and shape streams；</li><li>||表示的是$s_t$与$r_t$concatenating；</li><li>最后对1x1卷积添加sigmoid卷积。至此一个attention map就形成了。</li></ol><p><strong>GCL 的计算公式为:</strong></p><p><img src="images/GatedSCNN_2.png" alt="GCL"></p><p>表示的是：$s_t$逐像素与attention map$\alpha_t$点乘，取得感兴趣区域信息。再通过加权值为wt的残差网络。</p><p><strong>多任务学习损失函数：</strong></p><ol><li>预测边界信息使用的是BCE，用来监督更新both the regular and shape streams的参数；</li><li>预测语义信息使用的是CE，监督更新所有的网络参数。<script type="math/tex; mode=display">\mathcal{L}^{\theta \phi, \gamma}=\lambda_{1} \mathcal{L}_{B C E}^{\theta, \phi}(s, \hat{s})+\lambda_{2} \mathcal{L}_{C E}^{\theta \phi, \gamma}(\hat{y}, f)</script></li></ol><p>这里的$\lambda_1,\lambda_2$是用来控制两种损失权重的超参。</p><p><strong>Dual Task Regularizer：</strong><br>最后对two-stream的误差函数加入正则化项。<br>$\mathcal{L}^{\theta \phi, \gamma}=\mathcal{L}_{r e g \rightarrow}^{\theta \phi, \gamma}+ \mathcal{L}_{r e g_{\leftarrow}}^{\theta \phi, \gamma}$<br>其中<br>$\mathcal{L}_{r e g \rightarrow}^{\theta \phi, \gamma}=\lambda_{3} \sum_{p^{+}}\left|\zeta\left(p^{+}\right)-\hat{\zeta}\left(p^{+}\right)\right|$<br>$\mathcal{L}_{r e g_{\leftarrow}}^{\theta \phi, \gamma}=\lambda_{4} \sum_{k, p} \mathbb{1}_{s_{p}}\left[\hat{y}_{p}^{k} \log p\left(y_{p}^{k} | r, s\right)\right]$<br>$\zeta=\frac{1}{\sqrt{2}}\left|\nabla\left(G * \arg \max _{k} p\left(y^{k} | r, s\right)\right)\right|$</p><ol><li>$\zeta$表示指定像素是否属于输入图像的某个语义信息，通过对分割输出求空间导数即可。</li><li>$P^+$表示的是真值与预测值都非零的像素坐标。</li><li>$\lambda_3,\lambda_4$都是权重超参。</li><li>$\mathbb{1}_{s}=\{1 : s&gt;\text { thrs }\}$，置信度阈值，论文中定为0.8。</li></ol><h2 id="成绩"><a href="#成绩" class="headerlink" title="成绩"></a>成绩</h2><p>在用 Cityscapes 基准测试中，这个模型的 mIoU 比 DeepLab-v3 高出 1.5%，F-boundary 得分比 DeepLab-v3 高 4%。在更小的目标上，该模型能够实现 7% 的 IoU 提升。</p><p><img src="images/GatedSCNN_3.png" alt="Comparison in terms of IoU vs state-of-the-art baselines on the Cityscapes val set"></p><p><strong>总结：</strong><br>论文得来终觉浅，绝知此事要代码。等代码出来后再好好梳理一遍。<br><img src="images/GatedSCNN_4.png" alt="Gated-SCNN"></p><blockquote><p>论文：Gated-SCNN: Gated Shape CNNs for Semantic Segmentation（2019.07）<br>地址：<a href="https://arxiv.org/abs/1907.05740" target="_blank" rel="noopener">https://arxiv.org/abs/1907.05740</a><br>来自：英伟达</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 物体检测 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>命名实体识别步骤</title>
      <link href="/blog/18a085b4.html"/>
      <url>/blog/18a085b4.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><p><strong>input：</strong></p><ol><li>所有文字的字典文件，{index：word,…}；</li><li>所有文字的embedding文件，{word:embedding,…}；<a id="more"></a><strong>output：</strong><br>将字典中的文字全部用embedding表示,{index:embedding}。<br>tensorflow提供索引的方式，每次索引对应word的embedding向量。</li></ol><hr><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p><strong>input_x:[batch_size,max_sentence_length,embedding]</strong></p><ol><li>batch_size：每批次sentence的条数。</li><li>max_sentence_length：max指的是本批次句子中最大的长度，其它不足该长度的句子做padding操作。</li><li>embedding：对于每个word都会有对应的embedding。bs[sl[em]]</li></ol><p><strong>input_y:[batch_size,max_sentence_length]</strong></p><ol><li>batch_size：每批次sentence的条数。</li><li>max_sentence_length：max指的是本批次句子中最大的长度，其它不足该长度的句子做padding操作，length中所有位置都有label。</li><li>label:[‘B-LAW’,’I-LOC’,…]</li></ol>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 命名实体识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像开运算与闭运算</title>
      <link href="/blog/61e6e20f.html"/>
      <url>/blog/61e6e20f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>腐蚀和膨胀是对像素值大的部分而言的，即高亮白部分而不是黑色部分；以下图片前景物体为高亮像素，背景为低亮像素。<br><a id="more"></a></p><p><strong>膨胀(dilated)</strong> 是图像中的高亮部分进行膨胀，领域扩张，效果图拥有比原图更大的高亮区域；操作的时候表现为相邻区域用极大值代替，高亮区域增加。</p><p><strong>腐蚀(eroded)</strong> 是图像中的高亮部分被腐蚀掉，领域缩减，效果图拥有比原图更小的高亮区域；操作的时候表现为相邻区域用极小值代替,高亮区域减少。</p><p><strong>开运算</strong><br>先腐蚀再膨胀<br>① 开运算能够除去孤立的小点，毛刺和小桥，而总的位置和形状不便。<br>② 开运算是一个基于几何运算的滤波器。<br>③ 结构元素大小的不同将导致滤波效果的不同。<br>④ 不同的结构元素的选择导致了不同的分割，即提取出不同的特征。</p><p>开运算的效果图如下图所示：清除噪点，把一些太小的物体过滤。<br><img src="images/开运算.png" alt="image.png"></p><p><strong>闭运算</strong><br>先膨胀再腐蚀<br>① 闭运算能够填平前景物体内的小裂缝，而总的位置和形状不变。<br>② 闭运算是通过填充图像的凹角来滤波图像的。<br>③ 结构元素大小的不同将导致滤波效果的不同。<br>④ 不同结构元素的选择导致了不同的分割。</p><p>闭运算的效果图如下图所示：融合细微连接的图块，如果图像中存在断连物体，可以用此方法修复连接。<br><img src="images/闭运算.png" alt="image.png"></p><details><summary><b>Python Code</b></summary><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line">img = cv2.imread(<span class="string">'./image.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 定义核结构元素</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 腐蚀图像</span></span><br><span class="line">eroded = cv2.erode(img,kernel)</span><br><span class="line"><span class="comment"># 显示腐蚀后的图像</span></span><br><span class="line">cv2.imshow(<span class="string">"Eroded Image"</span>,eroded)</span><br><span class="line"><span class="comment">#膨胀图像</span></span><br><span class="line">dilated = cv2.dilate(img,kernel)</span><br><span class="line"><span class="comment">#显示膨胀后的图像</span></span><br><span class="line">cv2.imshow(<span class="string">"Dilated Image"</span>,dilated);</span><br><span class="line"><span class="comment"># 开运算</span></span><br><span class="line">opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)</span><br><span class="line"><span class="comment"># 显示开运算后的图像</span></span><br><span class="line">cv2.imshow(<span class="string">"Open"</span>, opened)</span><br><span class="line"><span class="comment">#闭运算</span></span><br><span class="line">closed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)</span><br><span class="line"><span class="comment">#显示闭运算后的图像</span></span><br><span class="line">cv2.imshow(<span class="string">"Close"</span>,closed);</span><br></pre></td></tr></table></figure></details><details><summary><b>删除图像中小物体的Python API</b></summary><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">skimage.morphology.remove_small_objects(ar, min_size=<span class="number">64</span>, connectivity=<span class="number">1</span>, in_place=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># ar: 待操作的bool型数组。</span></span><br><span class="line"><span class="comment"># min_size: 最小连通区域尺寸，小于该尺寸的都将被删除。默认为64.</span></span><br><span class="line"><span class="comment"># connectivity: 邻接模式，1表示4邻接(up,down,left,right)，2表示8邻接(up_left,up_right,down_left,down_right)</span></span><br><span class="line"><span class="comment"># in_place: bool型值，如果为True,表示直接在输入图像中删除小块区域，否则进行复制后再删除。默认为False.</span></span><br></pre></td></tr></table></figure></details><blockquote><p>参考链接<br><a href="https://blog.csdn.net/hanshanbuleng/article/details/80657148" target="_blank" rel="noopener">https://blog.csdn.net/hanshanbuleng/article/details/80657148</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>均值滤波器滤波</title>
      <link href="/blog/308c4d8b.html"/>
      <url>/blog/308c4d8b.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简介</strong></p><ol><li>均值滤波器属于低通滤波器；</li><li>输出为模板内领域像素的简单平均值；</li><li>主要用于图像的模糊和降噪，去除尖锐部分，比滤波器模板尺寸小的像素区域将会过滤掉；</li><li>与此同时，边缘也会被平滑、模糊。<a id="more"></a></li></ol><h2 id="线性均值滤波器"><a href="#线性均值滤波器" class="headerlink" title="线性均值滤波器"></a>线性均值滤波器</h2><h3 id="算术均值滤波器"><a href="#算术均值滤波器" class="headerlink" title="算术均值滤波器"></a>算术均值滤波器</h3><p>可以去除均匀噪声和高斯噪声，但会对图像造成一定程度的模糊。</p><h3 id="盒状滤波器Box-Filter"><a href="#盒状滤波器Box-Filter" class="headerlink" title="盒状滤波器Box Filter"></a>盒状滤波器Box Filter</h3><p>滤波器的模板的所有的系数都相等时称之为盒状滤波器。可以很方便的计算图像像素邻域的和，它在求解方差、Haar滤波、引导滤波器中都有使用到。</p><h3 id="加权的均值滤波器"><a href="#加权的均值滤波器" class="headerlink" title="加权的均值滤波器"></a>加权的均值滤波器</h3><p>加权的均值滤波器使用的模板系数，会根据像素和窗口中心像素的距离而取不同的系数。赋予中心点最高的权重，然后随着离中心点的距离增加而减小系数，这样做的目的是在平滑图像的同时尽量降低对图像的模糊。比算术均值滤波器好。</p><h2 id="非线性均值滤波器"><a href="#非线性均值滤波器" class="headerlink" title="非线性均值滤波器"></a>非线性均值滤波器</h2><h3 id="几何均值滤波器-Geometric-Mean-Filte"><a href="#几何均值滤波器-Geometric-Mean-Filte" class="headerlink" title="几何均值滤波器 Geometric Mean Filte"></a>几何均值滤波器 Geometric Mean Filte</h3><p> 和算术均值滤波器相比，几何均值滤波器能够更好的取出高斯噪声，并且能够更多的保留图像的边缘信息。但是，如果在滤波器的窗口内只要有一个像素的灰度值为0，就会造成滤波器的输出结果为0。</p><h3 id="谐波均值滤波器-Harmonic-Mean-Filter"><a href="#谐波均值滤波器-Harmonic-Mean-Filter" class="headerlink" title="谐波均值滤波器 Harmonic Mean Filter"></a>谐波均值滤波器 Harmonic Mean Filter</h3><p>谐波均值滤波器对盐粒噪声（白噪声）效果较好，不适用于胡椒噪声（黑噪声）；比较适合处理高斯噪声。</p><h3 id="逆谐波均值滤波器-Contra-Harmonic-Mean-Filter"><a href="#逆谐波均值滤波器-Contra-Harmonic-Mean-Filter" class="headerlink" title="逆谐波均值滤波器 Contra-Harmonic Mean Filter"></a>逆谐波均值滤波器 Contra-Harmonic Mean Filter</h3><p>该滤波器可以通过修改滤波器的阶数值Q来消除胡椒噪声（黑噪声）或者盐粒噪声（白噪声）。</p><h3 id="Yp均值滤波器"><a href="#Yp均值滤波器" class="headerlink" title="Yp均值滤波器"></a>Yp均值滤波器</h3><p>通过修改P值可以有效的滤去盐粒（白）噪声或者滤胡椒（黑）噪声</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 滤波器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于HDP-HMM的机械设备故障预测</title>
      <link href="/blog/49522bf9.html"/>
      <url>/blog/49522bf9.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>HMM算法：</strong></p><ol><li>设置设备状态数，此乃需要靠谱的先验知识，如果没有靠谱的先验知识，这时可以选择聚类算法，但是聚类算法中需要数据涵盖所有的状态类别。</li><li>为了增加HMM的鲁棒性和泛化性，一般需要采用多个观测样本进行训练，但在训练多组观测值序列时，只能先训练单一观测序列，在综合所有单个预测值序列得到的训练结果，计算时间长，计算量大。<a id="more"></a></li></ol><p><strong>HMM算法延申HDP-HMM：</strong></p><ol><li>HDP-HMM中的状态数可以是不确定的，即状态空间无限，实现了扩展有限空间状态的隐马尔可夫模型到无限维度，并利用狄利克雷（Dirichlet Process,DP）过程的性质实现HMM状态数自动生成。</li><li>HDP是在DP基础上扩展基础分布，使多个数据源之间不必满足独立同分布条件，利用参数共享，实现多维特征的信息融合和聚类。</li></ol><p><strong>应用描述：</strong><br>设备的性能退化是一个输出特性参数可见、状态隐藏的随机过程，可以用HMM描述。假设HMM描述的设备全寿命周期共有S={1,2,…,k}个隐藏状态，{1}为设备的正常状态，{2,3,…,k-1}分别为设备k-2个一次严重程度的退化状态，{k}为为设备故障状态。到T时刻为止，产生的隐藏状态序列为{s1,s2,…,sT}，不同状态下的观测值为{x1,x2,…,xT}，观测值xt关于状态st条件独立。设备各时刻所属的状态可以从k个不同的状态中取值，不同状态之间的转移由转移概率矩阵决定，其中的元素为<script type="math/tex">\pi_{ij}=P(S_t=j|S_{t-1}=i)</script><br>。当HMM的参数$\lambda$确定的情况下，离散状态s和观测序列x的联合概率密度函数可以表示为</p><script type="math/tex; mode=display">p(s,x|\lambda) = \prod^{T}_{t=1}p(s_t|s_{t-1})p(x_t|s_t)</script><hr><blockquote><p>参考文献：<br>基于HDP-HMM的机械设备故障预测方法研究</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 故障检测 </tag>
            
            <tag> 马尔可夫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>层次分析法介绍</title>
      <link href="/blog/2a6766e.html"/>
      <url>/blog/2a6766e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>美国运筹学家Sasty于20世纪70年代初提出层次分析法AHP(Analytic Hierarchy Process)<br>AHP：一种定量与特性相结合的、系统化、层次化的分析法。<br><a id="more"></a></p><p>深入分析实际问题，将有关因素自上而下分层（目标-准则/指标-方案/对象），上层受下层影响，而层内各因素基本上相对独立。</p><h2 id="建立层次分析结构模型的步骤"><a href="#建立层次分析结构模型的步骤" class="headerlink" title="建立层次分析结构模型的步骤"></a>建立层次分析结构模型的步骤</h2><p><strong>step1:</strong> 将决策问题分为3个层次：目标层O，准则层C，方案层P；每层有若干元素，各层元素间的关系用相连的直线表示。<br><strong>step2:</strong> 构造成对比较阵，用成对比较阵法和1-9尺度，构造各层对上一层每一因素的成对比较阵。</p><p><strong>例子：</strong> 选择旅游地<br><strong>目标层：</strong> O选择旅游地<br><strong>准则层：</strong> C1景色，C2费用，C3居住，C4饮食，C5旅途<br><strong>方案层：</strong> P1桂林，P2黄山，P3北戴河</p><p>接下来每个方案对每个准则进行评判。<br><strong>成对比较阵的元素：</strong> 元素之间两两对比，采用相对比较尺度。<br><strong>相对比较尺度$a_{ij}$</strong> 是由Sasty等人提出1-9尺度$a_{ij}$取值1,2,…,9及其互反数1,1/2,…,1/9。</p><h3 id="定性到定量的转化"><a href="#定性到定量的转化" class="headerlink" title="定性到定量的转化"></a>定性到定量的转化</h3><div class="table-container"><table><thead><tr><th style="text-align:center">尺度$a_{ij}$</th><th>1 2 3 4 5 6 7 8 9</th></tr></thead><tbody><tr><td style="text-align:center">$C_i:C_j$的重要性</td><td>相同 稍强 强 明显强 绝对强 …</td></tr></tbody></table></div><p>如果因素Ci与Cj对目标影响相同，则尺度定义为1。</p><h3 id="准则层对目标层的成对比较阵"><a href="#准则层对目标层的成对比较阵" class="headerlink" title="准则层对目标层的成对比较阵"></a>准则层对目标层的成对比较阵</h3><p>利用相对比较尺度$a_{ij}$，比较各准则$C_1,C_2,…,C_n$对目标的重要性$C_i:C_j=&gt;a_{ij}$。设矩阵$A = (a_{ij})_{m*n},a_{ij}&gt;0,a_{ji}=\frac{1}{a_{ij}}$。在这个例子里，A是5x5矩阵。</p><p>同理可得<strong>方案层对准则层各因素的成对比较阵</strong>。3x3矩阵。</p><h2 id="层次分析法求解步骤"><a href="#层次分析法求解步骤" class="headerlink" title="层次分析法求解步骤"></a>层次分析法求解步骤</h2><h3 id="数学表达式"><a href="#数学表达式" class="headerlink" title="数学表达式"></a>数学表达式</h3><ol><li>第2层对第1层的权重向量为：<br>$w^{(2)}=\left(w_{1}^{(2)}, \cdots, w_{n}^{(2)}\right)^{T}$</li><li>第3层对第2层的权重向量为：<br>$w_{k}^{(3)}=\left(w_{k 1}^{(0)}, \cdots, w_{k m}^{(3)}\right)^{T}, k=1,2, \cdots, n$<br>构造矩阵$W^{(3)}=\left[w_{1}^{(3)}, \cdots, w_{n}^{(3)}\right]$<br>则第3层对底1层的组合权向量$w^{(3)}=W^{(3)} w^{(2)}$</li><li>第s层对第1层的权重向量为:<br>$w^{(s)}=W^{(s)} W^{(s-1)} \cdots W^{(3)} w^{(2)}$<br>其中$W^{(p)}$是由第p层对第p-1层权向量组成的矩阵。</li></ol><h3 id="计算权向量并作一致性检验"><a href="#计算权向量并作一致性检验" class="headerlink" title="计算权向量并作一致性检验"></a>计算权向量并作一致性检验</h3><p>对每一成对比较阵计算最大特征根和特征向量，作一致性检验，若通过，则特征向量为权重向量。<br><strong>成对比较阵完全一致的情况：</strong><br>元素满足$a_{i j} \cdot a_{j k}=a_{i k}, \quad i, j, k=1,2, \cdots, n$的正反阵A称一致阵。<br><strong>一致阵性质：</strong><br>① A的秩为1，A的唯一非零特征根为n；<br>② A的任一列向量是对应于n的特征向量；<br>③ A的归一化特征向量可作为权向量。<br><strong>成对比较阵不一致的情况：</strong><br>对于实际问题中不一致（但在允许范围内）的成对比较阵A，我们可用对应于最大特征根$\lambda$的特征向量作为权向量$w$，$Aw = \lambda w$</p><h3 id="组合权向量（作组合一致性检验）"><a href="#组合权向量（作组合一致性检验）" class="headerlink" title="组合权向量（作组合一致性检验）"></a>组合权向量（作组合一致性检验）</h3><p>将多层的权向量组合可作为决策的定量依据。</p><h3 id="一致性检验"><a href="#一致性检验" class="headerlink" title="一致性检验"></a>一致性检验</h3><p>已知：n阶一致阵的唯一非零特征根为n；<br>结论：n阶正互反阵最大特征根$\lambda \geq n$，且$\lambda = n$时为一致阵<br>一致性指标：$CI = \frac{\lambda -n}{n-1}$，CI越大，不一致越严重。<br>由于CI的大小受到矩阵规模的影响，所以加入了随机一致性指标RI，随机模拟得到$a_{ij}$形成A，多次计算CI得到RI来修正。<br>|n| 1 | 2 | 3 | 4 | 5 | … |<br>|:-:|:-:|:-:|:-:|:-:|:-:|:-:|<br>|RI| 0 | 0 | 0.58 | 0.90 | 1.12 | … |<br><strong>定义一致性比率：</strong><br>$CR = CI/RI$<br>当CR&lt;0.1时，通过一致性检验。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p><strong>组合权向量：</strong>第三层对第二层的计算结果<br>| $k$ | 1| 2 | 3 | 4 | 5 |<br>| :—-: | :-: | :-: | :-: | :-: | :-: |<br>|$w_k^{(3)}$| 0.595 <br> 0.277 <br> 0.129 <br>| 0.082 <br> 0.236 <br> 0.682 <br>| 0.429 <br> 0.429 <br> 0.142 <br>| 0.633 <br> 0.193 <br> 0.175 <br>| 0.166 <br> 0.166 <br> 0.668 <br>|<br>|$\lambda_k$|3.005 | 3.002 | 3.0 | 3.009 | 3.0 |<br>|$CI_k$| 0.003 | 0.001 | 0.0 | 0.005 | 0.0 |<br>其中第二层对第一层的计算结果为$w^{(2)} : (0.263，0.475，0.055，0.090，0.110)$<br>$RI=0.58(n=3),得CI_k$均可通过一致性检验。<br>方案$P_1$对目标的组合权重为0.595x0.263+…=0.300<br>方案层对目标的组合权重向量为$(0.300，0.246，0.456)^T$<br>可以得到第三个方案最优。</p><blockquote><p>参考自华中农业大学数学建模课程</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 层次分析法 </tag>
            
            <tag> 决策 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>损失函数</title>
      <link href="/blog/4863b368.html"/>
      <url>/blog/4863b368.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>主要内容：</strong> 0-1,Hinge,Logistic,Cross Entropy,Square,Absolute,Huber<br><strong>简述：</strong> 损失函数刻画了模型与训练样本的匹配程度。<br><a id="more"></a></p><h2 id="分类损失"><a href="#分类损失" class="headerlink" title="分类损失"></a>分类损失</h2><p><img src="images/分类损失.png" alt="分类损失.png"><br><strong>1. 对于二分类问题，Y={1,-1}，我们希望$sign$ $f(x_i,\theta)=y_i$</strong></p><p><strong>0-1损失：$L_{0-1}(f,y)=1_{f.y\leq0}$</strong><br>最自然的损失函数是0-1损失，表示的是，当且仅当预测不正确的时候取值为1，否则取值为0。该损失函数能够直观的刻画分类的错误率，但是由于其非凸、非光滑的特点，使得算法很难直接对该函数进行优化。</p><p><strong>Hinge损失：$L_{hinge}(f,y)=max\{0,1-f.y\}$</strong><br>Hinge损失函数是0-1损失函数相对紧的凸上界，且当$f.y\leq1$时候,该函数不对其做任何处罚。由于Hinge损失在f.y=1处不可导，因此不能使用梯度下降算法优化，而是使用次梯度下降法。</p><p><strong>Logistic损失函数：$L_{logistic}=log_2(1+exp(-f.y))$</strong><br>Logistic损失函数也是0-1损失函数的凸上界，且该函数处处光滑，因此可以使用梯度下降法进行优化。但是，该函数对所有样本点都做惩罚，因此对异常点更为敏感。</p><p><strong>Cross Entropy：$L_{cross_entropy}=-log_2((1+f.y)/2)$</strong><br>交叉熵损失函数是常用的二分类损失函数。交叉熵损失函数也是0-1损失的光滑凸上界。</p><h2 id="回归损失"><a href="#回归损失" class="headerlink" title="回归损失"></a>回归损失</h2><p><img src="images/回归损失.png" alt="回归损失.png"></p><p><strong>1.对于回归问题,我们期望$f(x_i,\theta)\approx y_i$</strong></p><p><strong>Square损失：$L_{square}(f,y)=(f-y)^2$</strong><br>平方损失函数是光滑函数，能够使用梯度下降法优化。然而当预测值距离真实值越远时，平方损失函数的惩罚力度越大，因此对异常点比较敏感。</p><p><strong>Absolute损失：$L_{absolute}(f,y)=|f-y|$</strong><br>绝对损失函数相当于在做中值回归，相比做均值回归的平方损失函数，绝对损失函数对异常点更鲁棒。但是，绝对损失函数在f=y处无法求导。</p><p><strong>Huber损失：$L_{huber}(f,y)=\left\{\begin{array}{l}{(f-y)^2, |f-y|\leq\delta} \\ {2\delta |f-y|-\delta ^2, |f-y|&gt;\delta }\end{array}\right\}$</strong><br>Huber损失函数在|f-y|较小时为平方损失，在|f-y|较大的时采用线性损失，处处可导，且对异常点鲁棒。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 损失函数 </tag>
            
            <tag> LOSS </tag>
            
            <tag> 分类损失 </tag>
            
            <tag> 回归损失 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据规约</title>
      <link href="/blog/bb540bde.html"/>
      <url>/blog/bb540bde.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="数据维度规约"><a href="#数据维度规约" class="headerlink" title="数据维度规约"></a>数据维度规约</h2><h3 id="特征选取法"><a href="#特征选取法" class="headerlink" title="特征选取法"></a>特征选取法</h3><h4 id="决定特征的衡量准则"><a href="#决定特征的衡量准则" class="headerlink" title="决定特征的衡量准则"></a>决定特征的衡量准则</h4><ol><li><p><strong>一致性测量法（consistency measurement）</strong><br>每一个特征在不同取值下目标值不一致的数据笔数的总和，越少表示相应特征越重要。（先判断最多笔数的取值，剩下的都是不一致取值）</p><a id="more"></a></li><li><p><strong>关联性测量法（association measurement）</strong><br>每一个特征在不同取值下，最多相同目标取值的笔数占总数的比率的乘积越大表示关联性越强。</p></li><li><strong>判别测量（discriminant measurement）</strong><br>判断每一个特征不同取值的判断能力。</li><li><strong>信息增益测量（information measurement）</strong><br>又称决策树特征选取法，其目的是通过决策树的熵来衡量变量对目标变量的区分能力，去除较不相关或多余的变量。</li></ol><h4 id="组合特征产生方法"><a href="#组合特征产生方法" class="headerlink" title="组合特征产生方法"></a>组合特征产生方法</h4><ol><li><strong>逐步向前挑选法（sequential forward generation）</strong><br>首先依据特征测量法选取第一层最优特征，然后逐步增加一个数据维度得到第二层成对特征组合，接着计算第二层测量值，按测量值进行特征选取。</li><li><strong>逐步向后删减法（sequential backward generation）</strong><br>该方法只是与逐步向前挑选法相反，是从最上层开始，最上层是所有单一特征的组合，然后向下逐步减少一个维度。</li><li><strong>混合法（bidirectional generation）</strong><br>结合了逐步向前挑选法与逐步向后删减法同时操作。</li><li><strong>随机选取法（random generation）</strong><br>随机决定逐步向前挑选法与逐步向后删减法和随机组合特征。</li></ol><h4 id="特征选取策略"><a href="#特征选取策略" class="headerlink" title="特征选取策略"></a>特征选取策略</h4><p>特征选取策略取决于特征维度，假设数据中存有N个维度，所有可能的特征组合为$2^N$，其中2的意思是选取或不选取这个特征。由于计算复杂度随着维度的增加指数级增长，所以一般情况，我们可以自行控制算法结束的时间，例如，不一致的数据笔数少于3、信息增益大于0.8、相关程度大于0.95、数据特征组合大于5等。以下将介绍两种常用特征选取策略。</p><ol><li><strong>穷举搜索策略（exhaustive search strategy）</strong><br>该方法采用广度搜索的策略，将所有可能的组合列出，比较不同特征维度，以找出最佳特征组合的策略，非常耗时。</li><li><strong>启发式搜索策略（heuristic search strategy）</strong><br>该方法采用深度优先搜索，从各个特征中选取N个最佳特征，接着根据所选的特征产生N个维度的组合，并挑选最好的N个组合，以次类推。虽然不能保证能得到最佳解，但有较高的执行效率。</li><li><strong>随机搜索策略（random search strategy）</strong><br>随机搜索策略是以所选的特征为衡量基准，以随机增加或删除特征的方式，任意增删特征的维度，不断改进不同的特征组合以产生较佳的组合，直到符合所设定的停止条件。</li></ol><h3 id="主成分分析法"><a href="#主成分分析法" class="headerlink" title="主成分分析法"></a>主成分分析法</h3><p>利用主成分分析法降低特征维度。</p><h2 id="数据数值规约"><a href="#数据数值规约" class="headerlink" title="数据数值规约"></a>数据数值规约</h2><h3 id="离散化"><a href="#离散化" class="headerlink" title="离散化"></a>离散化</h3><p>有时候离散型的数据比连续型的数据更容易解释。此时就必须将连续型数据离散化，以符合工具能处理的数据格式。在数值规约方面，通过将属性值阈划分区间范围，离散化技术可以减少连续尺度的数据个数。</p><h3 id="概念阶层"><a href="#概念阶层" class="headerlink" title="概念阶层"></a>概念阶层</h3><p>连续型数据数值具有具有大小顺序关系，通过离散化技术可将其划分为几个不同的区间。离散型数据数值因为本身往往仅具有名目上的意义，并无法得知其数值是否相同或数值差异大小等，所以无法使用相同的方法达到数据数值规约的目的。而需要使用概念层阶将数据一般化，并用高阶层概念替换低阶层的原始数据。例如将小时时间映射到天，周月这些更高层的概念；还有5寸到100寸的液晶屏可以规范到小中大。概念阶层的转换需要专家确认，防止反作用的转化。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程 </tag>
            
            <tag> 数据规约 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最小二乘法与最小一乘法</title>
      <link href="/blog/cd0593c0.html"/>
      <url>/blog/cd0593c0.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>什么是最小二乘法：</strong><br>最小二乘法是一种误差度量方法，一种被优化的问题，在线性最小二乘问题中可以直接求解$x=\left(A^{T} A\right)^{-1} A^{T} b$得到全局最优，但是在非线性最小二乘问题中无法用此方法求解，此时就需要迭代法来求解，比如梯度下降法，牛顿法。<br><a id="more"></a></p><p><strong>最小二乘与极大似然的关系：</strong><br>在测量误差服从高斯分布的情况下，最小二乘法等价于极大似然估计。</p><p><strong>举例：</strong><br>假设样本是从高斯分布中采样获得，高斯概率分布函数为：<br>$f(x ; \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)$<br>噪声服从高斯分布的意思就是说，样本取值的期望 u 落在我们将要拟合的直线上。但是由于高斯噪声的存在，会一个偏差，该偏差符合正态分布，在两个标准差之间的范围内，两个标准差内的概率约为96%。这里的每一个样本都独立同分布，于是他们的联合概率应该满足：<br>$p_{X, Y}(x, y)=p_{X}(x) \cdot p_{Y}(y)$<br>累乘的结果是：<br>$\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu 1)^{2}}{2 \sigma^{2}}\right) \cdot \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu 2)^{2}}{2 \sigma^{2}}\right) \dots$<br>省略后面的乘项。上式相乘简化为指数相加，指数部分变为：<br>$\left(-\frac{(x-\mu 1)^{2}}{2 \sigma^{2}}\right)+\left(-\frac{(x-\mu 2)^{2}}{2 \sigma^{2}}\right)+\ldots$<br>只看分子，得：<br>$-\left[(x-\mu 1)^{2}+(x-\mu 2)^{2}+(x-\mu 3)^{2} \ldots\right]$<br>这便是最小二乘的模样。最小二乘法的思想是要求平方和尽可能小。上式前面加上了负号，也就是上式尽可能大，上式是一个指数，指数越大，便是联合概率越大，联合概率越大，表示样本的落点越有可能贴近拟合的直线，这便是最大似然的思想。</p><p><strong>最小一乘法介绍：</strong><br>最小一乘法只要求各实测点到回归直线的纵向距离的绝对值之和为最小。它不要求随机误差服从正态分布，“稳健性”比最小二乘法好。在数据随机误差不服从正态分布时，最小一乘法的统计性能优于最小二乘法。【百度百科】</p><p><strong>举例：</strong><br>当噪声服从拉普拉斯分布时<br>的概率分布为：<br>$f(x | \mu, b)=\frac{1}{2 b} \exp \left(-\frac{|x-\mu|}{b}\right)$<br>此时指数部分为绝对值，表示的是，所有数据到拟合出的直线的距离之和最小。新样本有最大可能的靠近该拟合的直线。</p><p><strong>结论：</strong><br>对于噪声的分布不同，应该选取对应的拟合方式。如果数据符合高斯分布，此时做线性回归应该用最小二乘法。</p><blockquote><p>参考链接：<br><a href="https://www.zhihu.com/question/24095027" target="_blank" rel="noopener">https://www.zhihu.com/question/24095027</a><br><a href="https://baike.baidu.com/item/%E6%9C%80%E5%B0%8F%E4%B8%80%E4%B9%98%E6%B3%95/585848?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E6%9C%80%E5%B0%8F%E4%B8%80%E4%B9%98%E6%B3%95/585848?fr=aladdin</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 最小二乘法 </tag>
            
            <tag> 最小一乘法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>样本方差为何除以n-1</title>
      <link href="/blog/8fcf8959.html"/>
      <url>/blog/8fcf8959.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><p><strong>1.</strong>设样本均值为$\overline{X}$，样本方差为$S^2$，总体均值为$\mu$，总体方差为$\sigma^{2}$，那么样本方差$S^2$的公式为：$S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\overline{X}\right)^{2}$</p><p><strong>2.知识补充</strong></p><p>（1）为何样本均值的方差等于总体方差除以总体单位数？</p><p>答：设X为随机变量，X1,X2,…,Xn为其n个样本，D(X)为方差。根据方差的性质，有$D(X+Y)=D X+D Y$，以及$D(k X)=k^{2} * D(X)$，其中X和Y相互独立，k为常数。于是有$D\left(\frac{\sum_{i=1}^{n} X_{i}}{n}\right)=D\left(\sum_{i=1}^{n} \frac{X_{i}}{n}\right)=\frac{\sum_{i=1}^{n} D\left(X_{i}\right)}{n^{2}}=\frac{1}{n} D(X)$</p><p><strong>3.公式证明</strong></p><p>假设样本方差的公式为:$S_{1}^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}$有：</p><p>$E\left(S_{1}^{2}\right)=\frac{1}{n} \sum_{i=1}^{n} E\left(\left(X_{i}-\overline{X}\right)^{2}\right)=\frac{1}{n} E\left(\sum_{i=1}^{n}\left(X_{i}-\mu+\mu-\overline{X}\right)^{2}\right)$<br>$=\frac{1}{n} E\left(\sum_{i=1}^{n}\left(\left(X_{i}-\mu\right)^{2}-2\left(X_{i}-\mu\right)(\overline{X}-\mu)+(\overline{X}-\mu)^{2}\right)\right)$<br>$=\frac{1}{n} E\left(\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}-2 \sum_{i=1}^{n}\left(X_{i}-\mu\right)(\overline{X}-\mu)+n(\overline{X}-\mu)^{2}\right)$<br>$=\frac{1}{n} E\left(\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}-n(\overline{X}-\mu)(\overline{X}-\mu)+n(\overline{X}-\mu)^{2}\right)$<br>$=\frac{1}{n} E\left(\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}-n E(\overline{X}-\mu)(\overline{X}-\mu)+n(\overline{X}-\mu)^{2}\right)$<br>$=\frac{1}{n}\left(\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}-n E(\overline{X}-\mu)(\overline{X}-\mu)+n(\overline{X}-\mu)^{2}\right)$<br>$=\frac{1}{n}(n \operatorname{Var}(X)-n \operatorname{Var}(\overline{X}))$<br>$=\operatorname{Var}(X)-\operatorname{Var}(\overline{X})=\sigma^{2}-\frac{\sigma^{2}}{n}=\frac{n-1}{n} \sigma^{2}$</p><p>样本方差有偏是因为样本均值相对总体有偏，在这种情况下，样本方差比总体方差小1/n个总体方差，所以分母为n-1即可做到无偏。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 样本方差 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降与牛顿法</title>
      <link href="/blog/c7300247.html"/>
      <url>/blog/c7300247.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><p><strong>梯度下降：</strong></p><p>$\theta_{1}=\theta_{0}-\alpha \nabla J(\theta_0) \quad$ evaluated at $\theta_{0}$<br><strong>计算举例：</strong></p><p>假设目标函数为$f(\theta)=\theta^2$，初始值$\theta_0=1$，步长$\alpha=0.5$则</p><script type="math/tex; mode=display">\theta_{1}=\theta_{0}-\alpha\nabla J(\theta_0)=\theta_{0}-\alpha*2\theta_0=1-0.5*2=0</script><p>在这里取$\alpha=0.5$正好一步到位，如果取得小得话，越靠近极小值时收敛速度越慢，牛顿法是越靠近越快。如果取较大的话则震荡或者无法收敛，比如$\alpha = 1$的话，则无法收敛。对于$\alpha$值的判断方法有：<br>$\theta _1 = \theta_0-\alpha*2\theta_0 = (1-2\alpha)\theta$<br>则为了能够收敛需要$-1&lt;1 - 2\alpha&lt;1$得$0&lt;\alpha&lt;1$，<br>收敛并且不发生震荡得取值范围为$0&lt;\alpha&lt;0.5$</p><p><strong>梯度下降与牛顿法的比较：</strong></p><p>梯度下降是求解目标函数值的极值，比如上例就是求得$\theta=0$的时候，函数得到极值。牛顿法是求解目标函数值为0的时候，变量的取值。虽然解释不同，但是，公式类似，梯度下降中没有计算hessian矩阵，而是用了步长 $\alpha$。可以说，牛顿法的优缺点都是由hessian矩阵带来的。</p><p>梯度下降法用目标函数的一阶偏导、以负梯度方向作为搜索方向，只考虑目标函数在迭代点的局部性质。牛顿法同时考虑了目标函数的一、二阶偏导数，考虑了梯度变化趋势，因而能更合适的确定搜索方向加快收敛。</p><p>从收敛速度来看，梯度下降是线性收敛，牛顿法是二阶收敛</p><p><strong>牛顿法：</strong><br>$x_{k+1}=x_{k}-\frac{f^{\prime}\left(x_{k}\right)}{f^{\prime \prime}\left(x_{k}\right)}, \quad k=0,1, \cdots$<br>对于矩阵：$\mathbf{x}_{k+1}=\mathbf{x}_{k}-H_{k}^{-1} \cdot \mathbf{g}_{k}, \quad k=0,1, \cdots$<br>其中g为一阶导数梯度向量，H为二阶导数海森矩阵。</p><ol><li>牛顿法收敛的前提是目标二阶导数必须存在，必须连续可微。如果在下降的某一处存在线性变化区域，二阶导数不存在，则无法收敛。</li><li>牛顿法收敛速度为二阶，对于正定二次函数一步迭代即达最优解。比如$(x-1)^2$</li><li>牛顿法是局部收敛的，当初始点选择不当时，往往导致不收敛。</li><li>牛顿法不是下降算法，当二阶海塞矩阵非正定时，不能保证产生方向是下降方向。</li><li>二阶海塞矩阵必须可逆。</li></ol><p><strong>牛顿法步骤：</strong><br><img src="images/牛顿法.png" alt="牛顿法.png"></p><p><strong>计算举例：</strong></p><p>假设目标函数为：$f(x) = x^3$<br>取初始值$x_0=1$，则$x_1 = x_0 - \frac{3x^2}{6x}=1-\frac{1}{2}=\frac{1}{2}$</p><p><strong>牛顿法总结：</strong></p><p>当目标函数是二次函数时，由于二次泰勒展开函数与原目标函数不是近似而是完全相同的二次式，海森矩阵退化成一个常数矩阵，从任一初始点出发，只需要一步即可达到极小值点，因此牛顿法是一种具有二次收敛性的算法，对于非二次函数，若函数的二次态度较强，或迭代点已进入极小点的领域，则其收敛速度也是非常快。但是，原始牛顿法由于迭代公式中没有步长因子，而是定步长迭代，对于非二次型目标函数，有时会使函数值上升，即出现$f\left(\mathbf{x}_{k+1}\right)&gt;f\left(\mathbf{x}_{k}\right)$的情况，这表明牛顿法不能保证函数值的稳定下降，在严重的情况下甚至可能造成迭代结果发散。因为要计算Hessian矩阵的逆，当Hessian矩阵很稠密时，每次迭代的计算量很大。随着数据规模的增大，那么Hessian矩阵会越大，需要的存储空间会增多，计算量也会增大，有时候大到不可计算，比如深度学习中参数的计算，牛顿法不再适用。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降 </tag>
            
            <tag> 牛顿法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降优化方法总结</title>
      <link href="/blog/17ea3cd3.html"/>
      <url>/blog/17ea3cd3.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1. 主要内容"></a>1. 主要内容</h1><p><strong>SGD，Momentum，AdaGrad，RMSProp，Adam</strong><br><a id="more"></a></p><h2 id="1-1-SGD"><a href="#1-1-SGD" class="headerlink" title="1.1. SGD"></a>1.1. SGD</h2><h3 id="1-1-1-Batch-Gradient-Descent"><a href="#1-1-1-Batch-Gradient-Descent" class="headerlink" title="1.1.1 Batch Gradient Descent"></a>1.1.1 Batch Gradient Descent</h3><p>在每一轮的训练过程中，Batch Gradient Descent算法用整个训练集的数据计算cost fuction的梯度，并用该梯度对模型参数进行更新：<br>$\Theta=\Theta-\alpha \cdot \nabla_{\Theta} J(\Theta)$<br><strong>优点：</strong>cost fuction若为凸函数，能够保证收敛到全局最优值；若为非凸函数，能够收敛到局部最优值。<br><strong>缺点：</strong><br>①由于每轮迭代都需要在整个数据集上计算一次，所以批量梯度下降可能非常慢<br>②训练数较多时，需要较大内存<br>③批量梯度下降不允许在线更新模型，例如新增实例。</p><h3 id="1-1-2-Stochastic-Gradient-Descent"><a href="#1-1-2-Stochastic-Gradient-Descent" class="headerlink" title="1.1.2 Stochastic Gradient Descent"></a>1.1.2 Stochastic Gradient Descent</h3><p>和批梯度下降算法相反，Stochastic gradient descent 算法每读入一个数据，便立刻计算cost fuction的梯度来更新参数：<br>$\Theta=\Theta-\alpha \cdot \nabla_{\Theta} J\left(\Theta ; x^{(i)}, y^{(i)}\right)$<br><strong>优点：</strong><br>①算法收敛速度快(在Batch Gradient Descent算法中, 每轮会计算很多相似样本的梯度, 这部分是冗余的)<br>②可以在线更新<br>③有几率跳出一个比较差的局部最优而收敛到一个更好的局部最优甚至是全局最优<br><strong>缺点：</strong>容易收敛到局部最优，并且容易被困在鞍点</p><h3 id="1-1-3-Mini-batch-Gradient-Descent"><a href="#1-1-3-Mini-batch-Gradient-Descent" class="headerlink" title="1.1.3 Mini-batch Gradient Descent"></a>1.1.3 Mini-batch Gradient Descent</h3><p>mini-batch Gradient Descent的方法是在上述两个方法中取折衷, 每次从所有训练数据中取一个子集（mini-batch） 用于计算梯度：<br>$\Theta=\Theta-\alpha \cdot \nabla_{\Theta} J\left(\Theta ; x^{(i : i+n)}, y^{(i : i+n)}\right)$<br>Mini-batch Gradient Descent在每轮迭代中仅仅计算一个mini-batch的梯度，不仅计算效率高，而且收敛较为稳定。该方法是目前深度学训练中的主流方法<br><strong>上述三个方法面临的主要挑战如下：</strong><br>①选择适当的学习率α较为困难。太小的学习率会导致收敛缓慢，而学习速度太块会造成较大波动，妨碍收敛。<br>②目前可采用的方法是在训练过程中调整学习率大小，例如模拟退火算法：预先定义一个迭代次数m，每执行完m次训练便减小学习率，或者当cost function的值低于一个阈值时减小学习率。然而迭代次数和阈值必须事先定义，因此无法适应数据集的特点。<br>③上述方法中, 每个参数的 learning rate 都是相同的，这种做法是不合理的：如果训练数据是稀疏的，并且不同特征的出现频率差异较大，那么比较合理的做法是对于出现频率低的特征设置较大的学习速率，对于出现频率较大的特征数据设置较小的学习速率。<br>④近期的的研究表明，深层神经网络之所以比较难训练，并不是因为容易进入local minimum。相反，由于网络结构非常复杂，在绝大多数情况下即使是 local minimum 也可以得到非常好的结果。而之所以难训练是因为学习过程容易陷入到马鞍面中，即在坡面上，一部分点是上升的，一部分点是下降的。而这种情况比较容易出现在平坦区域，在这种区域中，所有方向的梯度值都几乎是 0。</p><h2 id="1-2-Momentum"><a href="#1-2-Momentum" class="headerlink" title="1.2. Momentum"></a>1.2. Momentum</h2><p>SGD方法的一个缺点是其更新方向完全依赖于当前batch计算出的梯度，因而十分不稳定。Momentum算法借用了物理中的动量概念，它模拟的是物体运动时的惯性，即更新的时候在一定程度上保留之前更新的方向，同时利用当前batch的梯度微调最终的更新方向。这样一来，可以在一定程度上增加稳定性，从而学习地更快，并且还有一定摆脱局部最优的能力：<br>$v_{t}=\gamma \cdot v_{t-1}+\alpha \cdot \nabla_{\Theta} J(\Theta)$<br>$\Theta=\Theta-v_{t}$<br>Momentum算法会观察历史梯度$v_{t-1}$，若当前梯度的方向与历史梯度一致（表明当前样本不太可能为异常点），则会增强这个方向的梯度，若当前梯度与历史梯方向不一致，则梯度会衰减。</p><h2 id="1-3-Nesterov-Momentum"><a href="#1-3-Nesterov-Momentum" class="headerlink" title="1.3. Nesterov Momentum"></a>1.3. Nesterov Momentum</h2><p>在小球向下滚动的过程中，我们希望小球能够提前知道在哪些地方坡面会上升，这样在遇到上升坡面之前，小球就开始减速。这方法就是Nesterov Momentum，其在凸优化中有较强的理论保证收敛。并且，在实践中Nesterov Momentum也比单纯的 Momentum 的效果好：<br>$v_{t}=\gamma \cdot v_{t-1}+\alpha \cdot \nabla \Theta J\left(\Theta-\gamma v_{t-1}\right)$<br>$\Theta=\Theta-v_{t}$<br>这里对$\Theta-\gamma v_{t-1}$求梯度，就是对未来进行一次展望，如果未来的梯度方向相反，则本次更新步伐降低。</p><h2 id="1-4-Adagrad"><a href="#1-4-Adagrad" class="headerlink" title="1.4. Adagrad"></a>1.4. Adagrad</h2><p>上述方法中，对于每一个参数θi<br>的训练都使用了相同的学习率α。Adagrad算法能够在训练中自动的对learning rate进行调整，对于出现频率较低参数采用较大的α更新；相反，对于出现频率较高的参数采用较小的α更新。因此，Adagrad非常适合处理稀疏数据。<br>设$g_{t, i}$为第<strong>t</strong>轮第<strong>i</strong>个参数的梯度，即$g_{t, i}=\nabla_{\Theta} J\left(\Theta_{i}\right)$。因此，SGD中参数更新的过程可写为：<br>$\Theta_{t+1, i}=\Theta_{t, i}-\alpha \cdot g_{t, i}$<br>Adagrad在每轮训练中对每个参数θi<br>的学习率进行更新，参数更新公式如下：<br>$\Theta_{t+1, i}=\Theta_{t, i}-\frac{\alpha}{\sqrt{G_{t, i i}+\epsilon}} \cdot g_{t, i}$<br>其中，$G_{t} \in \mathbb{R}^{d \times d}$为对角矩阵，每个对角线位置$i, i$为对应参数θi从第1轮到第t轮梯度的平方和。ϵ是平滑项，用于避免分母为0，一般取值1e−8。Adagrad的缺点是在训练的中后期，分母上梯度平方的累加将会越来越大，从而梯度趋近于0，使得训练提前结束。方差表示的意思时，越少更新的，方差越小，更新幅度越大。</p><h2 id="1-5-RMSprop"><a href="#1-5-RMSprop" class="headerlink" title="1.5. RMSprop"></a>1.5. RMSprop</h2><p>RMSprop是Geoff Hinton提出的一种自适应学习率方法。Adagrad会累加之前所有的梯度平方，而RMSprop仅仅是计算对应的平均值，因此可缓解Adagrad算法学习率下降较快的问题。<img src="images/梯度下降-01.png" alt="image.png"><br>在图中这样的情况时，梯度下降在横轴方向前进，在纵轴方向却会有大幅度的抖动。<br>$E\left[g^{2}\right]_{t}=0.9 E\left[g^{2}\right]_{t-1}+0.1 g_{t}^{2}$<br>$\Theta_{t+1}=\Theta_{t}-\frac{\alpha}{\sqrt{E\left[g^{2}\right]_{t}+\epsilon}} \cdot g_{t}$</p><h2 id="1-6-Adam"><a href="#1-6-Adam" class="headerlink" title="1.6. Adam"></a>1.6. Adam</h2><p>Adam(Adaptive Moment Estimation)是另一种自适应学习率的方法，是Momentum算法与RMSprop算法的结合。它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。<img src="images/梯度下降-02.png" alt="image.png"><br>公式如下：</p><p>$m_{t}=\beta_{1} m_{t-1}+\left(1-\beta_{1}\right) g_{t}$<br>$v_{t}=\beta_{2} v_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2}$<br>$\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}}$<br>$\hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}}$<br>$\Theta_{t+1}=\Theta_{t}-\frac{\alpha}{\sqrt{\hat{v}_{t}}+\epsilon} \hat{m}_{t}$<br>对$\hat{m}_{t} / \sqrt{\hat{v}_{t}}$理解：根据梯度大小与梯度稳定性一起决定学习速率。越稳定更新速率越大，反之越小。天生具备退火能力。$\alpha$步长，$\epsilon$:稳定化参数$10^{-8}$</p><h1 id="2-可视化"><a href="#2-可视化" class="headerlink" title="2. 可视化"></a>2. 可视化</h1><p><img src="images/梯度下降.gif" alt="image"><br>在图中我们可以看到，Adagrad，Adadelta和RMSprop几乎立即朝着正确的方向前进，同样快速地收敛，而Momentum和NAG被引导偏离轨道，唤起了球从山上滚下来的形象。然而，NAG很快就能够纠正其进程，因为它通过向前看并提高到最低限度来提高响应速度。<br><img src="images/梯度下降2.gif" alt="image"><br>该图显示了算法在鞍点处的行为，即一维具有正斜率的点，而另一维具有负斜率，这对我们之前提到的SGD造成困难。请注意，SGD，Momentum和NAG发现打破对称很困难，尽管后者最终设法逃脱了鞍点，而Adagrad，RMSprop和Adadelta迅速降低了负斜率。</p><h1 id="3-参考文献"><a href="#3-参考文献" class="headerlink" title="3. 参考文献"></a>3. 参考文献</h1><p>主要参考链接：<br>[<a href="https://blog.csdn.net/u010089444/article/details/76725843" target="_blank" rel="noopener">https://blog.csdn.net/u010089444/article/details/76725843</a>]<br>[<a href="https://ruder.io/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">https://ruder.io/optimizing-gradient-descent/index.html</a>]<br>[<a href="https://blog.csdn.net/weixin_40170902/article/details/80092628" target="_blank" rel="noopener">https://blog.csdn.net/weixin_40170902/article/details/80092628</a>]</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度爆炸与梯度消失</title>
      <link href="/blog/c1d77713.html"/>
      <url>/blog/c1d77713.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><h2 id="梯度爆炸与梯度消失"><a href="#梯度爆炸与梯度消失" class="headerlink" title="梯度爆炸与梯度消失"></a>梯度爆炸与梯度消失</h2><p><strong>sigmoid数学公式:</strong> $f(x)=\frac{1}{1+e^{-x}}$ 值域为[0,1]</p><p><strong>sigmoid求导公式：</strong> $f^{\prime}(x)=f(x)(1-f(x))$ 值域为[0,1/4]</p><p><strong>实际现象：</strong> 当我们使用sigmoid function作为激活函数时，随着神经网络的隐藏层数增加，训练误差反而增大，造成了深度网络的不稳定。</p><p><strong>梯度弥散：</strong> 靠近输出层的hidden layer 梯度大，参数更新更快，所以很快就会收敛。而靠近输入层的hidden layer梯度小，参数更新慢，几乎和初始状态一样，随机分布。</p><p><strong>梯度爆炸：</strong> 当前面hidden layer的梯度通过训练变大，而后面的梯度将会指数级增大。</p><p><strong>现象原因：</strong> sigmoid函数会将[+∞,-∞]的输入压缩到[0,1]，导致当输入更新时，输出的更新会很小。在这种情况下，就会随着隐藏层数的增加，反向传递时，数值更新将会越来越小。</p><p><strong>解决方法：</strong></p><ol><li><p>Relu函数代换Sigmoid函数。</p></li><li><p>逐层贪婪预训练，如同训练自编码器的过程，每次只训练一层参数。由于得到的参数将会是局部最优，所以需要对整个网络再进行调优。</p></li><li><p>梯度减切Gradient Clip。设置一个梯度减切的阈值，如果在更新梯度的时候，梯度超过这个阈值，则会将其限制在这个范围之内，防止梯度爆炸。</p></li><li><p>正则。对参数加入正则规范，限制参数范数过大。</p></li><li><p>加入batch normalization层。</p></li><li><p>加入残差结构。</p></li><li><p>LSTM层由于有记忆，可以缓解梯度消失的发生。</p></li></ol><h2 id="Gradient-Clip"><a href="#Gradient-Clip" class="headerlink" title="Gradient Clip"></a>Gradient Clip</h2><h3 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h3><p>该方法简单，但是粗暴，阈值人为定义。设置上界阈值，面对梯度爆炸，设置下界阈值，也可以用于梯度消失。</p><h3 id="梯度爆炸解释"><a href="#梯度爆炸解释" class="headerlink" title="梯度爆炸解释"></a>梯度爆炸解释</h3><p>在一个只有一个隐藏节点的网络中，损失函数和权值w偏置b构成error surface，宛如一堵墙，如下所示<br><img src="images/GradientClip_wb.jpg" alt="GradientClip_wb"><br>损失函数每次迭代都是每次一小步，但是当遇到这堵墙时，在墙上的某点计算梯度，梯度会瞬间增大，指向某处不理想的位置。如果我们将大梯度缩放，就可以把该梯度的误导控制在可接受范围内，如虚线箭头所示。</p><h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><p><img src="images/GradientClip_1.jpg" alt="GradientClip——算法步骤"></p><ol><li>设置梯度阈值threshold</li><li>求出梯度的L2范数||g||。</li><li>比较||g||与threshold的大小。</li><li>如果||g||大于threshold,则求threshold/||g||得到缩放因子。</li><li>将梯度乘上缩放因子得到最终的梯度。</li></ol><h3 id="效果实验"><a href="#效果实验" class="headerlink" title="效果实验"></a>效果实验</h3><p><strong>无gradient clip:</strong><br>模型在2000次迭代出发生了梯度爆炸。<br><img src="images/GradientClip_loss_1.jpg" alt="GradientClip——Loss"></p><p><strong>有gradient clip:</strong><br>可以发现clip_gradient在前期有效了控制了梯度爆炸的影响，使得最终的loss能下降到满意的结果<br><img src="images/GradientClip_loss_2.jpg" alt="GradientClip——Loss"></p><h3 id="Tensorflow-and-Pytorch-GradientClip"><a href="#Tensorflow-and-Pytorch-GradientClip" class="headerlink" title="Tensorflow and Pytorch GradientClip"></a>Tensorflow and Pytorch GradientClip</h3><h4 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 计算局部范数（快）</span></span><br><span class="line">tf.clip_by_norm(grads, clip_norm=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 2. 计算全局范数（慢）</span></span><br><span class="line">tf.clip_by_global_norm(grads, clip_norm=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 计算所有梯度的平方和global_norm,</span></span><br><span class="line"><span class="comment"># 如果梯度平方和global_norm 超过我们指定的clip_norm，</span></span><br><span class="line"><span class="comment"># 那么就对梯度进行缩放；否则就按照原本的计算结果，</span></span><br></pre></td></tr></table></figure><h4 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个函数计算的是全局梯度范数</span></span><br><span class="line">torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=<span class="number">5</span>, norm_type=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># parameters: an iterable of Variables that will have gradients normalized</span></span><br><span class="line"><span class="comment"># max_norm: max norm of the gradients(阈值设定)</span></span><br><span class="line"><span class="comment"># norm_type: type of the used p-norm. Can be'inf'for infinity norm(定义范数类型)</span></span><br></pre></td></tr></table></figure><h4 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="comment"># 所有参数梯度将被裁剪，让其l2范数最大为1：g * 1 / max(1, l2_norm)</span></span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, clipnorm=<span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有参数d 梯度将被裁剪到数值范围内：</span></span><br><span class="line"><span class="comment"># 最大值0.5</span></span><br><span class="line"><span class="comment"># 最小值-0.5</span></span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, clipvalue=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降 </tag>
            
            <tag> 梯度爆炸 </tag>
            
            <tag> 梯度消失 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>检测任务Loss之GIOU</title>
      <link href="/blog/b08494e7.html"/>
      <url>/blog/b08494e7.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="GIoU提出背景"><a href="#GIoU提出背景" class="headerlink" title="GIoU提出背景"></a>GIoU提出背景</h3><p>从图中我么可以看出，优化BBox参数的常用距离损失与使该度量值最大化之间存在差距。常理来说，度量最佳目标是度量本身，直接用IoU作为loss来计算会更加有效，但是IoU指的是BBox之间的交并比，前提是必须有交集的两个Box才能计算，为了解决这个问题，GIoU被提出。<br><a id="more"></a><br><img src="images/GIOU_1.png" alt=""></p><h3 id="GIou介绍"><a href="#GIou介绍" class="headerlink" title="GIou介绍"></a>GIou介绍</h3><p>对于任意两个Box，我们可以找到一个最小的封闭框C，让C把A,B包含在内，然后我们计算C中没有覆盖A和B的面积占C总面积的比值，然后用A与B的IoU减去这个比值。</p><script type="math/tex; mode=display">GIoU_{AB} = IoU_{AB} - \frac{C-(A \bigcup B)}{|C|},Loss = 1 - GIoU</script><h4 id="表现"><a href="#表现" class="headerlink" title="表现"></a>表现</h4><p><img src="images/GIOU_2.png" alt=""></p><p><img src="images/GIOU_3.png" alt=""></p><p>从图上我们可以看出，GIoU在MS COCO 2018的test数据集上更加优秀。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LOSS </tag>
            
            <tag> IOU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型剪枝工具推荐</title>
      <link href="/blog/439cc94e.html"/>
      <url>/blog/439cc94e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>剪枝一直都是一个十分必要的工作。</strong></p><p><strong>谷歌：</strong><br>Link:<a href="https://github.com/tensorflow/model-optimization" target="_blank" rel="noopener">TensorFlow Model Optimization Toolkit</a><br><a id="more"></a></p><p><strong>百度：</strong><br>Link:<a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleSlim" target="_blank" rel="noopener">PaddleSlim</a></p><p><strong>腾讯：</strong><br>Link:<a href="https://github.com/Tencent/PocketFlow" target="_blank" rel="noopener">PocketFlow</a></p><p><strong>Intel(基于Pytorch):</strong><br>Link:<a href="https://github.com/NervanaSystems/distiller" target="_blank" rel="noopener">distiller</a></p><p><strong>微软：</strong><br>Link:<a href="https://github.com/microsoft/nni" target="_blank" rel="noopener">NNI</a></p><p><strong>Pytorch社区：</strong><br>Link:<a href="https://github.com/666DZY666/model-compression" target="_blank" rel="noopener">model-compression</a></p><p><strong>Keras社区：</strong><br>Link:<a href="https://github.com/BenWhetton/keras-surgeon" target="_blank" rel="noopener">keras-surgeon</a></p><p>模型剪枝相关论文实现：<br>Link:<a href="https://github.com/yeyun11/pytorch-network-slimming" target="_blank" rel="noopener"> Learning Efficient Convolutional Networks Through Network Slimming</a></p><p>Link:<a href="https://github.com/Roll920/ThiNet" target="_blank" rel="noopener">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression</a></p><hr><p>Deep Compression是一个模型量化和压缩框架。<br>Deep Compression综合应用了剪枝、量化、编码三个步骤来进行模型压缩，是2016 ICLR最佳论文。在不影响精度的前提下，把500M的VGG压缩到了11M。</p><p>(1) 网络剪枝</p><p>即移除不重要的连接，包括3个步骤，分别是普通网络训练，删除权重小于一定阈值的连接得到稀疏网络，对稀疏网络再训练，这是一个反复迭代的过程。这一步对于AlexNet和VGG-16模型，分别将参数降低为原来的1/9和1/13。</p><p>(2) 权重量化</p><p>权值量化是把网络的连接权值从高精度转化成低精度的操作过程，例如将32位浮点数float32转化成8位定点数int8或二值化为1bit，转换后的模型准确率等指标与原来相近，但模型大小变小，运行速度加快。一般操作是先训练模型，再进行量化，<strong>测试时</strong>使用量化后的模型。</p><p>(3) 霍夫曼编码</p><p>霍夫曼编码是一种成熟的编码技巧，与CNN无关，它有效地利用了权重的有偏分布，可以进一步减少需要存储的参数体积。</p><p><strong>串行的合并：</strong> 就是将Pooling、LRN，BN等网络层与相邻近的Conv层进行合并</p><p><strong>分支合并</strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型剪枝工具 </tag>
            
            <tag> 模型剪枝 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型评价指标</title>
      <link href="/blog/9fc22fc9.html"/>
      <url>/blog/9fc22fc9.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>混淆矩阵：</strong><br>也称为误差矩阵，是一种特定的表格布局，允许可视化算法的性能，通常是监督学习的算法（在无监督学习通常称为<strong>匹配矩阵</strong>）。矩阵的每一行代表预测类中的实例，而每列代表实际类中的实例（反之亦然）。从字面理解：看出系统是否混淆了两个类（即通常将一个类错误标记为另一个类）（多类可以合并为二分类）。<br><a id="more"></a></p><p><strong>一级评价指标：</strong><br>由四个基础指标构成：<strong>TP、FN、FP、TN</strong><br>① 真实值是positive，模型认为是positive的数量（True Positive=<strong>TP</strong>）<br>② 真实值是positive，模型认为是negative的数量（False Negative=<strong>FN</strong>）：这就是统计学上的第一类错误（Type I Error）<br>③ 真实值是negative，模型认为是positive的数量（False Positive=<strong>FP</strong>）：这就是统计学上的第二类错误（Type II Error）<br>④ 真实值是negative，模型认为是negative的数量（True Negative=<strong>TN</strong>）</p><p>一级评价指标混淆矩阵图例：<br><img src="images/混淆矩阵图例1(一级评价指标" alt="一级评价指标混淆矩阵图例.png">.png)</p><p><strong>二级评价指标：</strong><br>准确率(Accuracy)：ACC<br>精确率(Precision)：PPV<br>灵敏度(Sensitivity)=召回率(Recall)=命中率=真实阳性率：TPR<br>特异度(Specificity)：TNR<br>（更多名词可查看维基百科）<br><img src="images/二级评价指标.png" alt="二级评价指标图例.png"></p><p><strong>三级评价指标：</strong><br>F1 Score：<br>$\mathrm{F1} =\frac{2 \mathrm{PR}}{\mathrm{P}+\mathrm{R}}$<br>其中，P代表Precision，R代表Recall。F1-Score指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。</p><p><strong>MCC 马修斯相关系数：</strong><br>衡量不平衡数据集的指标比较好。<br>$\mathrm{MCC}=\frac{T P \times T N-F P \times F N}{\sqrt{(T P+F P)(T P+F N)(T N+F P)(T N+F N)}}$</p><p><strong>ROC曲线：</strong><br>ROC曲线的横坐标为false positive rate（FPR），纵坐标为 true positive rate（TPR） 。当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。<br><img src="images/ROC.png" alt="ROC.png"></p><p><strong>PRC曲线：</strong><br>在正负样本分布得极不均匀(highly skewed datasets)的情况下，PRC比ROC能更有效地反应分类器的好坏。<br><img src="images/PRC.png" alt="PRC.png"></p><p><strong>实列理解：</strong><br><img src="images/混淆矩阵图例2.png" alt="混淆矩阵例2.png"><br>该图表示的是模型预测动物的预测数据图。通过该混淆矩阵，可以得到以下结论：</p><p><strong>Accuracy:</strong><br>在总共66个动物中，我们一共预测对了10 + 15 + 20=45个样本，所以准确率（Accuracy）=45/66 = 68.2%。<br>下面以猫为例，将上面的图合并为二分类问题，求出二级评价指标与三级评价指标：<br><img src="images/混淆矩阵图例3.png" alt="混淆矩阵例3.png"></p><p><strong>Precision：</strong><br>以猫为例，66只动物里有13只是猫，其中这13只猫只有10只预测对了。模型认为是猫的13只动物里，有1条狗，两只猪。所以，Precision（猫）= 10/13 = 76.9%</p><p><strong>Recall：</strong><br>以猫为例，在总共18只真猫中，我们的模型认为里面只有10只是猫，剩下的3只是狗，5只都是猪。这5只八成是橘猫，能理解。所以，Recall（猫）= 10/18 = 55.6%</p><p><strong>Specificity：</strong><br>以猫为例，在总共48只不是猫的动物中，模型认为有45只不是猫。所以，Specificity（猫）= 45/48 = 93.8%。虽然在45只动物里，模型依然认为错判了6只猪与4只狗，但是从猫的角度而言，模型的判断是没有错的。</p><p><strong>F1-Score:</strong><br>通过公式，可以计算出，对猫而言，F1-Score=（2 <em> 0.769 </em>  0.556）/（ 0.769 +  0.556） = 64.54%</p><blockquote><p>参考链接：<br>维基百科：<a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Confusion_matrix</a><br>CSDN:<a href="https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839" target="_blank" rel="noopener">https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型评价指标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习归一化</title>
      <link href="/blog/7d202220.html"/>
      <url>/blog/7d202220.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>内容包含：</strong>BatchNormalization、LayerNormalization、InstanceNorm、GroupNorm、SwitchableNorm<br><a id="more"></a></p><h1 id="1-简述"><a href="#1-简述" class="headerlink" title="1.简述"></a>1.简述</h1><h2 id="1-1-论文链接"><a href="#1-1-论文链接" class="headerlink" title="1.1 论文链接"></a>1.1 论文链接</h2><p>(1)、Batch Normalization<br><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.03167.pdf</a></p><p>(2)、Layer Normalizaiton<br><a href="https://arxiv.org/pdf/1607.06450v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1607.06450v1.pdf</a></p><p>(3)、Instance Normalization<br><a href="https://arxiv.org/pdf/1607.08022.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1607.08022.pdf</a><br><a href="https://github.com/DmitryUlyanov/texture_nets" target="_blank" rel="noopener">https://github.com/DmitryUlyanov/texture_nets</a></p><p>(4)、Group Normalization<br><a href="https://arxiv.org/pdf/1803.08494.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1803.08494.pdf</a></p><p>(5)、Switchable Normalization<br><a href="https://arxiv.org/pdf/1806.10779.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1806.10779.pdf</a><br><a href="https://github.com/switchablenorms/Switchable-Normalization" target="_blank" rel="noopener">https://github.com/switchablenorms/Switchable-Normalization</a></p><h2 id="1-2-整体介绍"><a href="#1-2-整体介绍" class="headerlink" title="1.2 整体介绍"></a>1.2 整体介绍</h2><p>归一化层，目前主要有这几个方法，Batch Normalization（2015年）、Layer Normalization（2016年）、Instance Normalization（2017年）、Group Normalization（2018年）、Switchable Normalization（2018年）；</p><p><strong>将输入的图像shape记为[N, C, H, W]，这几个方法主要的区别就是在:</strong></p><p>batchNorm是在batch上，对NHW做归一化，对小batchsize效果不好；<br>layerNorm在通道方向上，对CHW归一化，主要对RNN作用明显；<br>instanceNorm在图像像素上，对HW做归一化，用在风格化迁移；<br>GroupNorm将channel分组，然后再做归一化；<br>SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。<br><img src="images/BN_LN_IN_GN-01.png" alt="image.png"></p><h1 id="2-详细解说"><a href="#2-详细解说" class="headerlink" title="2.详细解说"></a>2.详细解说</h1><h2 id="2-1-Batch-Normalization"><a href="#2-1-Batch-Normalization" class="headerlink" title="2.1 Batch Normalization"></a>2.1 Batch Normalization</h2><p><img src="images/BatchNormalization.png" alt="image.png"><br><strong>算法过程：</strong><br>(1)、沿着通道计算每个batch的均值u<br>(2)、沿着通道计算每个batch的方差σ^2<br>(3)、对x做归一化，x’=(x-u)/开根号(σ^2+ε)<br>(4)、加入缩放和平移变量γ和β ,归一化后的值，y=γx’+β<br><strong>加入缩放平移变量的原因是：</strong> 不一定每次都是标准正态分布，也许需要偏移或者拉伸。保证每一次数据经过归一化后还保留原有学习来的特征，同时又能完成归一化操作，加速训练。 这两个参数是用来学习的参数。</p><p><strong>整体公式:</strong><br>$y=\frac{x-\mathrm{E}[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}} * \gamma+\beta$</p><p><strong>前向传播CODE:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def Batchnorm(x, gamma, beta, bn_param):</span><br><span class="line"></span><br><span class="line">    # x_shape:[B, C, H, W]</span><br><span class="line">    running_mean &#x3D; bn_param[&#39;running_mean&#39;]</span><br><span class="line">    running_var &#x3D; bn_param[&#39;running_var&#39;]</span><br><span class="line">    results &#x3D; 0.</span><br><span class="line">    eps &#x3D; 1e-5</span><br><span class="line"></span><br><span class="line">    x_mean &#x3D; np.mean(x, axis&#x3D;(0, 2, 3), keepdims&#x3D;True)</span><br><span class="line">    x_var &#x3D; np.var(x, axis&#x3D;(0, 2, 3), keepdims&#x3D;True0)</span><br><span class="line">    x_normalized &#x3D; (x - x_mean) &#x2F; np.sqrt(x_var + eps)</span><br><span class="line">    results &#x3D; gamma * x_normalized + beta</span><br><span class="line"></span><br><span class="line">    # 因为在测试时是单个图片测试，这里保留训练时的均值和方差，用在后面测试时用</span><br><span class="line">    running_mean &#x3D; momentum * running_mean + (1 - momentum) * x_mean</span><br><span class="line">    running_var &#x3D; momentum * running_var + (1 - momentum) * x_var</span><br><span class="line"></span><br><span class="line">    bn_param[&#39;running_mean&#39;] &#x3D; running_mean</span><br><span class="line">    bn_param[&#39;running_var&#39;] &#x3D; running_var</span><br><span class="line"></span><br><span class="line">    return results, bn_param</span><br></pre></td></tr></table></figure><p><strong>pytorch中的API:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BatchNorm1d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">torch.nn.BatchNorm2d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">torch.nn.BatchNorm3d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line"></span><br><span class="line"># num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x num_features [x width]’</span><br><span class="line"># eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</span><br><span class="line"># momentum： 动态均值和动态方差所使用的动量。默认为0.1。</span><br><span class="line"># affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br><span class="line"># track_running_stats：布尔值，当设为true，记录训练过程中的均值和方差</span><br></pre></td></tr></table></figure><h2 id="2-2-Layer-Normalizaiton"><a href="#2-2-Layer-Normalizaiton" class="headerlink" title="2.2 Layer Normalizaiton"></a>2.2 Layer Normalizaiton</h2><p><strong>batch normalization存在以下缺点：</strong></p><p>(1)、对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布；<br>(2)、BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。</p><p><strong>与BN不同，LN是针对深度网络的某一层的所有神经元的输入按以下公式进行normalize操作。</strong><br>$\mu^{l}=\frac{1}{H} \sum_{i=1}^{H} a_{i}^{l} \quad \sigma^{l}=\sqrt{\frac{1}{H} \sum_{i=1}^{H}\left(a_{i}^{l}-\mu^{l}\right)^{2}}$<br><strong>BN与LN的区别在于：</strong></p><p>(1)、LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；<br>(2)、BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。<br>(3)、LN用于RNN效果比较明显，但是在CNN上，不如BN。<br><strong>前向传播代码：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def Layernorm(x, gamma, beta):</span><br><span class="line"></span><br><span class="line">    # x_shape:[B, C, H, W]</span><br><span class="line">    results &#x3D; 0.</span><br><span class="line">    eps &#x3D; 1e-5</span><br><span class="line"></span><br><span class="line">    x_mean &#x3D; np.mean(x, axis&#x3D;(1, 2, 3), keepdims&#x3D;True)</span><br><span class="line">    x_var &#x3D; np.var(x, axis&#x3D;(1, 2, 3), keepdims&#x3D;True0)</span><br><span class="line">    x_normalized &#x3D; (x - x_mean) &#x2F; np.sqrt(x_var + eps)</span><br><span class="line">    results &#x3D; gamma * x_normalized + beta</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure><p><strong>Pytorch API:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.LayerNorm(normalized_shape, eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line"># normalized_shape： 输入尺寸[∗×normalized_shape[0]×normalized_shape[1]×…×normalized_shape[−1]]</span><br><span class="line"># eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</span><br><span class="line"># elementwise_affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br></pre></td></tr></table></figure><h2 id="2-3-Instance-Normalization"><a href="#2-3-Instance-Normalization" class="headerlink" title="2.3 Instance Normalization"></a>2.3 Instance Normalization</h2><p>BN注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p><p>但是<strong>图像风格化</strong>中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。<br><strong>公式：</strong>$y_{t i j k}=\frac{x_{t i j k}-\mu_{t i}}{\sqrt{\sigma_{t i}^{2}+\epsilon}}, \quad \mu_{t i}=\frac{1}{H W} \sum_{l=1}^{W} \sum_{m=1}^{H} x_{t i l m}, \quad \sigma_{t i}^{2}=\frac{1}{H W} \sum_{l=1}^{W} \sum_{m=1}^{H}\left(x_{t i l m}-m u_{t i}\right)^{2}$<br><strong>前向代码：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def Instancenorm(x, gamma, beta):</span><br><span class="line"></span><br><span class="line">    # x_shape:[B, C, H, W]</span><br><span class="line">    results &#x3D; 0.</span><br><span class="line">    eps &#x3D; 1e-5</span><br><span class="line"></span><br><span class="line">    x_mean &#x3D; np.mean(x, axis&#x3D;(2, 3), keepdims&#x3D;True)</span><br><span class="line">    x_var &#x3D; np.var(x, axis&#x3D;(2, 3), keepdims&#x3D;True0)</span><br><span class="line">    x_normalized &#x3D; (x - x_mean) &#x2F; np.sqrt(x_var + eps)</span><br><span class="line">    results &#x3D; gamma * x_normalized + beta</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure><p><strong>Pytorch API:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.InstanceNorm1d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;False, track_running_stats&#x3D;False)</span><br><span class="line">torch.nn.InstanceNorm2d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;False, track_running_stats&#x3D;False)</span><br><span class="line">torch.nn.InstanceNorm3d(num_features, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;False, track_running_stats&#x3D;False)</span><br><span class="line"></span><br><span class="line"># num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x num_features [x width]’</span><br><span class="line"># eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</span><br><span class="line"># momentum： 动态均值和动态方差所使用的动量。默认为0.1。</span><br><span class="line"># affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br><span class="line"># track_running_stats：布尔值，当设为true，记录训练过程中的均值和方差；</span><br></pre></td></tr></table></figure><h2 id="2-4-Group-Normalization"><a href="#2-4-Group-Normalization" class="headerlink" title="2.4 Group Normalization"></a>2.4 Group Normalization</h2><p>主要是针对Batch Normalization对小batchsize效果差，GN将channel方向分group，然后每个group内做归一化，算(C//G)<em>H</em>W的均值，这样与batchsize无关，不受其约束。<br><strong>前向code：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def GroupNorm(x, gamma, beta, G&#x3D;16):</span><br><span class="line"></span><br><span class="line">    # x_shape:[B, C, H, W]</span><br><span class="line">    results &#x3D; 0.</span><br><span class="line">    eps &#x3D; 1e-5</span><br><span class="line">    x &#x3D; np.reshape(x, (x.shape[0], G, x.shape[1]&#x2F;16, x.shape[2], x.shape[3]))</span><br><span class="line"></span><br><span class="line">    x_mean &#x3D; np.mean(x, axis&#x3D;(2, 3, 4), keepdims&#x3D;True)</span><br><span class="line">    x_var &#x3D; np.var(x, axis&#x3D;(2, 3, 4), keepdims&#x3D;True0)</span><br><span class="line">    x_normalized &#x3D; (x - x_mean) &#x2F; np.sqrt(x_var + eps)</span><br><span class="line">    results &#x3D; gamma * x_normalized + beta</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure><p><strong>Pytorch API:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.GroupNorm(num_groups, num_channels, eps&#x3D;1e-05, affine&#x3D;True)</span><br><span class="line"># num_groups：需要划分为的groups</span><br><span class="line"># num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x num_features [x width]’</span><br><span class="line"># eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</span><br><span class="line"># momentum： 动态均值和动态方差所使用的动量。默认为0.1。</span><br><span class="line"># affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</span><br></pre></td></tr></table></figure><h2 id="2-5-Switchable-Normalization"><a href="#2-5-Switchable-Normalization" class="headerlink" title="2.5 Switchable Normalization"></a>2.5 Switchable Normalization</h2><p><strong>本篇论文作者认为：</strong></p><p>(1)、第一，归一化虽然提高模型泛化能力，然而归一化层的操作是人工设计的。在实际应用中，解决不同的问题原则上需要设计不同的归一化操作，并没有一个通用的归一化方法能够解决所有应用问题；<br>(2)、第二，一个深度神经网络往往包含几十个归一化层，通常这些归一化层都使用同样的归一化操作，因为手工为每一个归一化层设计操作需要进行大量的实验。</p><p>因此作者提出自适配归一化方法——Switchable Normalization（SN）来解决上述问题。与强化学习不同，SN使用可微分学习，为一个深度网络中的每一个归一化层确定合适的归一化操作。<br><strong>公式：</strong>$\hat{h}_{n c i j}=\gamma \frac{h_{n c i j}-\Sigma_{k \in \Omega} w_{k} \mu_{k}}{\sqrt{\Sigma_{k \in \Omega} w_{k}^{\prime} \sigma_{k}^{2}+\epsilon}}+\beta$</p><p>$w_{k}=\frac{e^{\lambda_{k}}}{\Sigma_{z \in\{\mathrm{in}, \ln , \mathrm{bn}\}} e^{\lambda_{z}}}, \quad k \in\{\mathrm{in}, \ln , \mathrm{bn}\}$</p><p>$\mu_{\mathrm{in}}=\frac{1}{H W} \sum_{i, j}^{H, W} h_{n c i j}, \sigma_{\mathrm{in}}^{2}=\frac{1}{H W} \sum_{i, j}^{H, W}\left(h_{n c i j}-\mu_{\mathrm{in}}\right)^{2}$</p><p>$\mu_{\ln }=\frac{1}{C} \sum_{c=1}^{C} \mu_{\mathrm{in}}, \quad \sigma_{\ln }^{2}=\frac{1}{C} \sum_{c=1}^{C}\left(\sigma_{\mathrm{in}}^{2}+\mu_{\mathrm{in}}^{2}\right)-\mu_{\mathrm{ln}}^{2}$</p><p>$\mu_{\mathrm{bn}}=\frac{1}{N} \sum_{n=1}^{N} \mu_{\mathrm{in}}, \quad \sigma_{\mathrm{bn}}^{2}=\frac{1}{N} \sum_{n=1}^{N}\left(\sigma_{\mathrm{in}}^{2}+\mu_{\mathrm{in}}^{2}\right)-\mu_{\mathrm{bn}}^{2}$</p><p><strong>前向传播CODE：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def SwitchableNorm(x, gamma, beta, w_mean, w_var):</span><br><span class="line">    # x_shape:[B, C, H, W]</span><br><span class="line">    results &#x3D; 0.</span><br><span class="line">    eps &#x3D; 1e-5</span><br><span class="line"></span><br><span class="line">    mean_in &#x3D; np.mean(x, axis&#x3D;(2, 3), keepdims&#x3D;True)</span><br><span class="line">    var_in &#x3D; np.var(x, axis&#x3D;(2, 3), keepdims&#x3D;True)</span><br><span class="line"></span><br><span class="line">    mean_ln &#x3D; np.mean(x, axis&#x3D;(1, 2, 3), keepdims&#x3D;True)</span><br><span class="line">    var_ln &#x3D; np.var(x, axis&#x3D;(1, 2, 3), keepdims&#x3D;True)</span><br><span class="line"></span><br><span class="line">    mean_bn &#x3D; np.mean(x, axis&#x3D;(0, 2, 3), keepdims&#x3D;True)</span><br><span class="line">    var_bn &#x3D; np.var(x, axis&#x3D;(0, 2, 3), keepdims&#x3D;True)</span><br><span class="line"></span><br><span class="line">    mean &#x3D; w_mean[0] * mean_in + w_mean[1] * mean_ln + w_mean[2] * mean_bn</span><br><span class="line">    var &#x3D; w_var[0] * var_in + w_var[1] * var_ln + w_var[2] * var_bn</span><br><span class="line"></span><br><span class="line">    x_normalized &#x3D; (x - mean) &#x2F; np.sqrt(var + eps)</span><br><span class="line">    results &#x3D; gamma * x_normalized + beta</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure><h1 id="3-结果比较"><a href="#3-结果比较" class="headerlink" title="3 结果比较"></a>3 结果比较</h1><p><img src="images/BN_LN_IN_GN-02.png" alt="image.png"></p><h1 id="4-参考链接："><a href="#4-参考链接：" class="headerlink" title="4 参考链接："></a>4 参考链接：</h1><blockquote><p>本篇大部分内容摘抄自<a href="https://blog.csdn.net/liuxiao214/article/details/81037416" target="_blank" rel="noopener">https://blog.csdn.net/liuxiao214/article/details/81037416</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 归一化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习视觉中的感受野</title>
      <link href="/blog/f328077.html"/>
      <url>/blog/f328077.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="理论感受野"><a href="#理论感受野" class="headerlink" title="理论感受野"></a>理论感受野</h2><p>能够影响单个卷积输出值的输入区域。</p><p>比如1个3x3的卷积核，stride=1，输出的点是由3x3大小的感受野提供的。如果再跟上一个2x2的pooling层，那么pooling层输出的一个点是由4x4的感受野提供的。<br>解释，因为2x2的pooling层上的每个点是由3x3视野提供的，但是，卷积核的stride=1，所以，感受野上下增加1，为4x4。<br><a id="more"></a></p><p><strong>计算公式</strong><br>$kernel_size = 3,stride = 1$<br>初始感受野$RF_0=1$，<br>$feature_stride_0 = 1，l$表示层数。<br>其中feature_stride计算公式：$feature_stride_l = \prod^{l}_{i=1}$</p><p>第一次特征感受野：</p><script type="math/tex; mode=display">RF_1 = RF_0 + (kernel\_size_1)*feature\_stride_0 = 1 + (3-1) * 1 = 3</script><p>第二层特征，感受野:</p><script type="math/tex; mode=display">RF_2 = RF_1 + (kernel\_size_2)*feature\_stride_1 = 3 + (3-1) * 1 = 5</script><p>第三层特征，感受野:</p><script type="math/tex; mode=display">RF_3 = RF_2 + (kernel\_size_3)*feature\_stride_2 = 5 + (3-1) * 1 = 7</script><p>如果有dilated conv的话，计算公式为:</p><script type="math/tex; mode=display">RF_{l+1} = RF_l + (kernel\_size_{l+1}-1)*feature\_stride_l * dilation_{l+1}</script><h2 id="有效感受野"><a href="#有效感受野" class="headerlink" title="有效感受野"></a>有效感受野</h2><p>由于理论感受野所有像素对卷积输出的贡献并不是完全相同，而仅仅是一小部分区域对输出值能够产生有效的影响，而这一小部分区域则为有效感受野。<br>论文Link：<a href="https://arxiv.org/pdf/1701.04128.pdf" target="_blank" rel="noopener">Understanding the Effective Receptive Field in Deep Convolutional Neural Networks</a></p><p><img src="images/RecFields_1.png" alt="不同激活函数得到的有效感受野略有不同"></p><p><img src="images/RecFields_2.png" alt="层数、初始化方案和不同激活的效果"></p><p><img src="images/RecFields_3.png" alt="Subsampling 和 dilated convolution 都可以增加 有效感受野范围"></p><h3 id="有效感受野存在的原因"><a href="#有效感受野存在的原因" class="headerlink" title="有效感受野存在的原因"></a>有效感受野存在的原因</h3><p>两个kernel_size=3,stride=1的感受野为5，如下图所示：</p><p><img src="images/RecFields_4.png" alt="两层3x3conv计算流程图"></p><p>从图中可以发现，$x_{1,1}$只影响第一层feature map中的$o^1_{1,1}$；而$x_{3,3}$会影响第一层中的所有特征值。<br>第一层所有特征值都将会影响到第二层的特征值$o^2_{1,1}$。<br>但是$x_{1,1}$只能通过$o^1_{1,1}$一个点来影响$o^2_{1,1}$，很明显不如$x_{3,3}$更具影响力，因为第一层中的每一个特征值都和$x_{3,3}$有关。综上，输入中越靠感受野中间的元素对特征的贡献越大，边缘贡献最小。</p><h3 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h3><ol><li><p>Padding作用<br>①. 保留图片边界信息，Padding可以避免图片边缘只被卷积一次。<br>②. 对有差异图片补齐，使得输入一致。<br>③. 控制输出维度。</p></li><li><p>两种padding方式<br>① VALID如果发现剩下区域不够卷积，那么直接舍去。<br>② SAME会填充以保证边缘参与卷积。</p></li></ol><p>那么Padding操作会让图片所有区域的有效感受野都相同吗。<br>不可以，还有初始化方法与激活函数影响。（待写如何影响）</p><h2 id="如何扩大实际感受野"><a href="#如何扩大实际感受野" class="headerlink" title="如何扩大实际感受野"></a>如何扩大实际感受野</h2><p>将全局池化提取图像的全局特征，与局部特征融合起来。（ParseNet）<br>但是不同层之间的特征的尺度是不同的，所以需要归一化操作。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 感受野 </tag>
            
            <tag> 卷积 </tag>
            
            <tag> 池化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络结构图可视化工具</title>
      <link href="/blog/9908d8ed.html"/>
      <url>/blog/9908d8ed.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><ol><li>NN-SVG<br>Github:<a href="https://github.com/alexlenail/NN-SVG" target="_blank" rel="noopener">NN-SVG</a><a id="more"></a></li></ol><p><img src="images/NetVisualization_1.png" alt="NN-SVG"></p><ol><li>PlotNeuralNet (Star:7.3k)<br>Github:<a href="https://github.com/HarisIqbal88/PlotNeuralNet" target="_blank" rel="noopener">PlotNeuralNet</a></li></ol><p>使用门槛高，用LaTex语言编辑，但是美观。</p><p><img src="images/NetVisualization_2.png" alt=""></p><p><img src="images/NetVisualization_3.png" alt="PlotNeuralNet "></p><ol><li>Draw_convnet(Star:1.6k)<br>Github:<a href="https://github.com/gwding/draw_convnet" target="_blank" rel="noopener">Draw_convnet</a></li></ol><p>Python script for illustrating Convolutional Neural Network (ConvNet)</p><p><img src="images/NetVisualization_4.png" alt="Draw_convnet"></p><ol><li>Netscope<br>Github:<a href="https://github.com/ethereon/netscope" target="_blank" rel="noopener">Netscope</a></li></ol><p>caffe的网络结构可视化工具</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>积分图与BoxFilter滤波</title>
      <link href="/blog/ea81a742.html"/>
      <url>/blog/ea81a742.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简介</strong><br>积分图的出现使得Haar特征的计算更为高效，这是一种动态规划算法，以减少重复计算缩减算法时间。它可以使复杂度为O(MN)的求和，求方差等运算降低到O(4)的复杂度，而BoxFilter可以降到O(1)，不过BoxFilter不支持多尺度。<br><a id="more"></a></p><p><strong>积分图的缺陷</strong><br>因为一直在累加，所以，当原图很大的话，会出现溢出的情况，所以，不建议使用int64等类型。</p><p><strong>积分图讲解：</strong><br><strong>积分图中任意位置的值</strong>是由原图中该位置和其左上角所有位置值的和。<br>每一点$I(x,y)$的计算公式为：<br>$I(x,y) = i(x,y) + I(x-1,y) + I(x,y-1) - I(x-1,y-1)$</p><p><img src="images/积分图_1.png" alt=""></p><p><img src="images/积分图_2.png" alt=""></p><p>当得到积分图之后，阴影区域的和即可计算得到。该阴影矩形可以是任意形状。</p><script type="math/tex; mode=display">\sum_{A(x)<x^{\prime} \leq C(x) \atop A(y)<y^{\prime} \leq C(y)} i\left(x^{\prime}, y^{\prime}\right)=I(C_{右下})+I(A_{右下})-I(B_{右下})-I(D_{右下})</script><p><img src="images/积分图_3.png" alt=""></p><p>比如计算原图中间红色区域的和：</p><script type="math/tex; mode=display">Sum = Integral(3,3) + Integral(0,0) - Integral(3,0) - Integral(0,3) = 54+1-8-9</script>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉CV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 滤波器 </tag>
            
            <tag> 积分图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>粗糙集理论学习笔记</title>
      <link href="/blog/708eb5b2.html"/>
      <url>/blog/708eb5b2.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>粗糙集理论的主要思想是利用已知的知识库，将不精确或不确定的知识用已知的知识库中的知识来（近似）刻画。<br><a id="more"></a></p><hr><p><strong>基本粗糙集理论的主要存在的问题：</strong><br>1）对原始数据本身的模糊性缺乏相应的处理能力；<br>2）对于粗糙集的边界区域的刻画过于简单；<br>3）粗糙集理论的方法在可用信息不完全的情况下将对象们归类于某一具体的类，通常分类是确定的，但并未提供数理统计中所常用的在一个给定错误率的条件下将尽可能多的对象进行分类的方法，而实际中常常遇到这类问题。</p><hr><p>该理论与其他处理不确定和不精确问题理论的最显著的区别是它无需提供问题所需处理的数据集合之外的任何先验信息，所以对问题的不确定性的描述或处理可以说比较客观。</p><hr><p>论域：包含若干对象的非空有限集。<br>概念：任意集合X属于论域U为一个概念。<br>空概念：一个空集视为空概念。<br>知识：由任意个这样的X组成的自己簇形成了论域中抽象知识，是一种能力，用来分类对象。<br>对象：任何实体，物品、属性、概率等。<br>不可定义集：对于论域U上任意一个子集X，X不一定能用知识库中的知识来精确表达。</p><hr><p>信息系统四元组（U,Q,V,f），其中<br>U是对象集合，<br>Q是属性集合（包括条件属性C和决策属性D），<br>V是属性的值域，<br>f是一种映射，反应对象集合之间的值。</p><div class="table-container"><table><thead><tr><th style="text-align:center">U</th><th style="text-align:center">a</th><th style="text-align:center">b</th><th style="text-align:center">c</th><th style="text-align:center">d</th><th style="text-align:center">e</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">2</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr></tbody></table></div><p>U = (1,2,3,4,5,6,7,8)<br>Q = (a,b,c,d,e)<br>V = (0,1,2)<br>U/Ind(a) = ((1,4,5),(2,8),(3,6,7)),由条件属性a决定对U的划分。<br>U/Ind(a,b,c)=((1,5),(2,8),(3),(4),(6),(7))<br>若$(x,y)\in IND(P)$，则称x和y是P不可分辨的，即依据P中所含各属性无法将x和y区分开。比如2和8无法依据属性a分开。</p><hr><p>假定关于论域的某种知识，并使用属性和属性值来描述论域中的对象，如果两个对象（或对象集合）具有相同的属性和属性值，则它们之间具有不可分辨关系。</p><hr><p>一般约简<br>决策表T=(U,P,C,D)中条件属性集C的一个子集B是关于D独立的，并且PosB(D)=PosC(D)，则称B是C的一个D约简(reduct)，B和C在D上的效果是一样的。将所有类似B这样的约简子集求交集即可得到属性集合C的核(Core)。<br>核的意义：<br>(1)因为核包含于所有约简之中，所以核可以作为所有约简的计算基础。<br>(2)核在知识约简中是不能消去的特征集合。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 粗糙集理论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>罗尔中值, 拉格朗日中值, 柯西中值</title>
      <link href="/blog/658633c0.html"/>
      <url>/blog/658633c0.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简述：</strong> 罗尔==&gt;拉格朗日==&gt;柯西，特殊性逐渐渐减弱。<br><a id="more"></a></p><p><strong>罗尔中值定理：</strong> 一个物体往返运动时，一定有一点的瞬时速度为0。<br>如果函数f(x)满足（1）在闭区间[a,b]上连续；（2）在(a,b)内可导；（3）f(a)=f(b)，则至少存在一个$\xi \in(a, b)$，使得$f^{\prime}(\xi)=0$。<br><img src="images/中值定理-01.png" alt="image.png"></p><p><strong>拉格朗日中值定理：</strong> 在a,b之间一定能够找到一个瞬时速度等于这两点之间的平均速度。<br>如果函数f(x)满足以下条件，（1）在闭区间[a,b]上连续；（2）在(a,b)内可导；（3）那么存在一点$\xi \in(a, b)$，使得等式$f^{\prime}(\xi)=\frac{f(b)-f(a)}{b-a}$成立。<br><img src="images/中值定理-02.png" alt="image.png"></p><p><strong>柯西中值定理：</strong> 两个物体时间相同下，即使速度不同，也会存在一点，瞬时速度的比值等于平均速度的比值。<br>如果函数f(x)与g(x)满足以下条件，（1）在闭区间[a,b]上连续；（2）z在(a,b)内可导；（3）对任意$x \in(a, b), g^{\prime}(x) \neq 0$则在(a,b)内至少存在一点$\xi$，使得$\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f^{\prime}(\xi)}{g^{\prime}(\xi)}$ 。<br><img src="images/中值定理-03.png" alt="image.png"></p><blockquote><p>参考链接：<a href="https://www.zhihu.com/question/26803653/answer/116269605?utm_source=qq&amp;utm_medium=social" target="_blank" rel="noopener">https://www.zhihu.com/question/26803653/answer/116269605?utm_source=qq&amp;utm_medium=social</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中值定理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Boosting_Bagging介绍</title>
      <link href="/blog/3db5b568.html"/>
      <url>/blog/3db5b568.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>1.Boosting方法训练基分类器是采用串行的方式，各个基分类器之间有依赖。<br>2.Boosting的基本思路是将基分类器层层叠加，每一层在训练的时候，对前一层基分类器分错的样本给予更高的权重。测试时，根据各层分类器的结果的加权得到最终的结果。<strong>stacking</strong><br><a id="more"></a></p><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><ol><li>Bagging因为各基分类器之间无强依赖，所以可以进行串行训练。以基于决策树基分类器的随机森林为代表。</li><li>为了让基分类器之间相互独立，需要将数据集分为若干子集（当训练样本数量较少时，子集之间会有重叠部分）。</li><li>Bagging更像天赋不同且单一的几个孩子在单独学习，学习的内容可以相同也可以不同。由于个体之间有差异，最终做出的判断不完全一致，每个个体单独判断，然后通过投票的方式做出最后集体的决策。<strong>voting</strong></li></ol><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>接下来我们将会从消除基分类器的偏差和方差的角度来理解Boosting和Bagging方法的差异。<br>基分类器：弱分类器。基分类器的错误。是偏差和方差两种错误之和。<strong>偏差</strong>主要是由分类器的表达能力有限导致的系统性错误，表现在训练不够收敛。<strong>方差</strong>是由分类器对样本分布过于敏感，导致在训练样本过少时，产生过拟合。</p><ol><li>Boosting方法是通过逐步聚焦于基分类器分错的样本，减小集成分类器的偏差。</li><li>Bagging方法是采取分而治之的策略，通过训练样本多次采样，分别计算多个独立的基分类器，综合各个模型减小集成分类器的方差。基模型越多，整体思想越统一，不会受个别模型影响，方差越小。</li></ol><h2 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h2><p>集成学习一般可分为以下3个步骤：</p><ol><li>找到误差互相独立的基分类器；</li><li>训练基分类器；</li><li>合并基分类器的结果。</li></ol><p>合并的方式有voting和stacking两种。也可以将不同分类器的输出结果作为一个特征，使用逻辑回归作为融合模型进行最后的结果预测。</p><p>以Adaboost为例具体步骤如下：</p><ol><li>确定基分类器：由于树型模型结构简单，且较易产生随机性（制作相互独立的特性），这里可以选择ID3决策树作为基分类器。当然，其它非树型分类模型也可以作为基分类器。</li><li><p>训练基分类器：假设训练集为$\left\langle x_{i} y_{i}\right\rangle, k=1, \ldots, N$，其中$y_{i} \in\{-1,1\}$，并且有$T$个基分类器，则可以按照如下过程来训练基分类器。</p><p>① 初始化采样分布$D_{1}(i)=1 / N$；</p><p>② 令$t=1,2, \ldots, T$循环；</p><p>A.) 从训练集中，按照$D_t$分布，采样出子集$S_{t}=\left\{x_{i}, y_{i}\right\}, i=1, \dots, N_{i}$；</p><p>B.) 用$S_i$训练出基分类器$h_i$;</p><p>C.) 计算$h_i$的错误率：$\varepsilon_{1}=\frac{\sum_{i=1}^{N_{i}} I\left[h_{i}\left(x_{i}\right) \neq y_{i}\right] D_{i}\left(x_{i}\right)}{N_{t}}$，其中$I[]$为判别函数；</p><p>D.) 计算基分类器$h_i$，权重$a_{i}=\log \frac{\left(1-\varepsilon_{i}\right)}{\varepsilon_{i}}$；</p><p>E.) 设置下一次采样</p><p>$D_{t+1}=   \left\{\begin{array}{l} D_t(i) 或者 {D_t(i)(1-\varepsilon_t)} \over {\varepsilon_t} &amp; h_t(x_i) \neq y_i \\ \frac {D_t(i)\varepsilon_t }{ (1 - \varepsilon_t ) } &amp; h_t(x_i)=y_i \end{array}\right.$ ，并将它归一化为一个概率分布函数。</p><p>③ 合并基分类器：给定一个未知样本$z$，输出分类结果为加权投票的结果$\operatorname{sign}\left(\sum_{t=1}^{T} h_{t}(z) a_{t}\right)$</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Boosting </tag>
            
            <tag> Bagging </tag>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>范数介绍</title>
      <link href="/blog/a3b3b417.html"/>
      <url>/blog/a3b3b417.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>向量范数：</strong><br>向量范数定义了向量的距离，而距离满足正定，齐次，三角不等式。范数的使用可以帮助<strong>特征选择</strong>，使得模型更具<strong>解释性</strong>。<br><a id="more"></a><br>向量的范数一般有L0, L1, L2与L_infinity范数,</p><p><strong>L0范数：</strong><br>定义：$|x|_{0}=\sum_{i=1}^{k}\left|x_{i}\right|^{0}$<br>L0范数表示非0元素的个数。利用该特性，我们可以用来规则化机器学习中的参数w，可以使得w大部分元素为零，寻找最少最优的稀疏特征。但是，L0范数的最小化问题是NP难问题，而L1范数是L0范数的最优凸近似，L1范数比L0范数更容易求解。所以实际中会用L1范数来代替L0范数求解。</p><p><strong>L1范数：</strong><br>定义：$|x|_{1}=\sum_{i=1}^{k}\left|x_{i}\right|$<br>L1范数表示向量中各个元素绝对值的和，也被称作”Lasso regularization”(稀疏规则算子)。在机器学习中，稀疏规则化能够实现特征的自动选择，将无用的特征权重置为0来剔除。</p><p><strong>L2范数：</strong><br>定义：$|x|_{2}=\sqrt{\sum_{i=1}^{k}\left|x_{i}\right|^{2}}$<br>L2范数中的一个代表是欧式距离。L2范数被广泛应用在解决机器学习里面的过拟合问题，L2范数不会像L1范数那样将不重要的特征置为0，而是将所有参数最小化，只是接近于0。所以，L2范数下的特征重要性更均匀，但是不像L1范数突出显示最重要的特征。</p><p><strong>矩阵范数：</strong><br>矩阵范数又名为相容范数，除了要满足向量范数中的要求外，在矩阵为n阶方正的情况下，需要满足相容性，即$|A B| \leq|A| \cdot|B|$<br>矩阵范数一般有1-, 2-, infinity-, F-范数。</p><p><strong>1-范数：</strong><br>定义：$|A|_{1}=\max _{j} \sum_{i=1}^{m}\left|a_{i j}\right|$<br>1-范数又名为列和范数，即所有矩阵列向量绝对值之和的最大值。</p><p><strong>2-范数：</strong><br>定义：$|A|_{2}=\sqrt{\lambda_{1}}$<br>其中$\lambda$为$A^{T} A$的最大特征值。又名为谱范数，表示$A^{T} A$矩阵最大特征值的平方根。</p><p><strong>infinity-范数：</strong><br>定义：$|A|_{\infty}=\max _{i} \sum_{j=1}^{m}\left|a_{i j}\right|$<br>$\infty$-范数又名为行和范数，即所有矩阵行向量绝对值之和的最大值。</p><p>以上范数都是诱导范数，由向量Lp范数诱导得到。非诱导范数常见的为F-范数，即Frobenius范数以及核范数。</p><p><strong>F-范数：</strong><br>定义：$|A|_{F}=\left(\sum_{i=1}^{m} \sum_{j=1}^{n}\left|a_{i j}\right|^2\right)^{\frac{1}{2}}$<br>Frobenius范数，即矩阵元素绝对值的平方和再开平方。</p><p><strong>核范数：</strong><br>定义：$|A|_{*}=\sum_{i=1}^{n} \lambda_{i}$<br>$\lambda_i$为矩阵A的奇异。秩可以度量矩阵中数据的相关性，如果相关性很强，表示数据中含有冗余信息，则表示该数据矩阵可以降维，也可以利用冗余信息对缺失值进行填充。由于求解矩阵的秩很难，所以寻找了它的近似凸函数即核范数来求解。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 范数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>谱聚类学习</title>
      <link href="/blog/e5c13f51.html"/>
      <url>/blog/e5c13f51.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ol><li>方阵作为线性算子，它的所有征值的全体统方阵的谱。</li><li>方阵的谱半径为最大的特征值；</li><li>矩阵A的谱半径：(ATA)的最大特征值；</li><li>谱聚类：是一种基于图的聚类方法，通过对样本数据的拉普拉斯矩阵的特征向量进行聚类，从而达到对样本聚类的目的。<a id="more"></a></li></ol><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p>无向图：G=(V,E)<br>邻接矩阵：$W=(w_{ij})i,j=1,…,n$，对称阵。<br>顶点的度：对角矩阵D,$d_i=\sum^n_{j=1}w_{ij}$表示某个顶点，所有与它连接的相似度和。</p><h2 id="谱分析的整体过程"><a href="#谱分析的整体过程" class="headerlink" title="谱分析的整体过程"></a>谱分析的整体过程</h2><ol><li><p>计算数据彼此之间的相似度，构成相似度矩阵(相似度图)。（关于相似度的计算可以用欧式距离，也可以用高斯函数。）</p></li><li><p>接下来，用相似度图来解决样本数据的聚类问题。找到图的一个划分，形成若干个组（Group）,使得不同组之间有较低的权值，组内有较高的权值。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 谱聚类 </tag>
            
            <tag> 聚类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归介绍</title>
      <link href="/blog/2a97a967.html"/>
      <url>/blog/2a97a967.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><p>线性回归模型公式：$g(x)=\omega_{0}+\omega_{1} x_{1}$</p><p>逻辑回归模型公式：$f(x)=\frac{1}{1+e^{-g(x)}}$（包含了线性回归）</p><p>在$x$条件下$y=1$发生的概率为：$P(y=1 | x)=\pi(x)=\frac{1}{1+e^{-g(x)}}$</p><p>在$x$条件下$y = 1$不发生的概率为：$P(y=0 | x)=1-P(y=1 | x)=1-\frac{1}{1+e^{-g(x)}}=\frac{e^{-g(x)}}{1+e^{-g(x)}}=\frac{1}{1+e^{g(x)}}$</p><p>事件发生与不发生的概率比（事件发生比odds）为：$\frac{P(y=1 | x)}{P(y=0 | x)}=\frac{p}{1-p}=e^{g(x)}$</p><p>接下来将会对这个odds进行操作。</p><p>设非线性函数$g(x)=w_{0}+w_{1} x_{1}+\ldots+w_{n} x_{n}$</p><p>对odds取对数得到：$\ln \left(\frac{p}{1-p}\right)=g(x)=w_{0}+w_{1} x_{1}+\ldots+w_{n} x_{n}$</p><p>假设有m个相互独立的观测样本，观测值分别为$y_{1}, y_{2}, \dots, y_{m}$，设$p_{i}=P\left(y_{i}=1 | x_{i}\right)$为给定条件下得到$y_{i}=1$的概率，则$y_{i}=0$的概率为$P\left(y_{i}=0 | x_{i}\right)=1-p_{i}$，所以得到一个观测值的概率为：$P\left(y_{i}\right)=\frac{p_{i}^{y_{i}}}{\left(1-p_{i}\right)^{y_{i}-1}}=p_{i}^{y_{i}}\left(1-p_{i}\right)^{1-y_{i}}$。因为各个观测样本相互独子，那么它们的联合分布为各边缘分布的乘积。</p><p>得到似然函数为：$L(w)=\prod_{i=1}^{m}\left(\pi\left(x_{i}\right)\right)^{y_{i}}\left(1-\pi\left(x_{i}\right)\right)^{1-y_{i}}$</p><p>这里似然函数的作用就是，求在所有事件发生的odds概率乘积为最大值下的参数值$w\left(w_{0}, w_{1}, \dots, w_{n}\right)$，n+1个参数。</p><p>对函数$L(w)$取对数得到：$\ln L(w)=\sum_{i=1}^{m}\left(y_{i} \ln \left[\pi\left(x_{i}\right)\right]+\left(1-y_{i}\right) \ln \left[1-\pi\left(x_{i}\right)\right]\right)$</p><p>接下来分别对这些$w$参数求导，得到n+1个方程。接下来以对参数$w_k$求导为例：$\left(y_{i} \ln \left[\pi\left(x_{i}\right)\right]+\left(1-y_{i}\right) \ln \left[1-\pi\left(x_{i}\right)\right]\right)^{\prime}$<br>$=\frac{y_{i}}{\pi\left(x_{i}\right)} \cdot\left[\pi\left(x_{i}\right)\right]^{\prime}+\left(1-y_{i}\right) \cdot \frac{-\left[\pi\left(x_{i}\right)\right]^{\prime}}{1-\pi\left(x_{i}\right)} )^{\prime}$<br>$=\left[\frac{y_{i}}{\pi\left(x_{i}\right)}-\frac{1-y_{i}}{1-\pi\left(x_{i}\right)}\right] \cdot\left[\pi\left(x_{i}\right)\right]^{\prime}$<br>$=\left(y_{i}-\pi\left(x_{i}\right)\right) g^{\prime}(x)$<br>$=x_{i k}\left[y_{i}-\pi\left(x_{i}\right)\right]$</p><p>得出：$\frac{\partial \ln L\left(w_{k}\right)}{\partial w_{k}}=\sum_{i=1}^{m} x_{i k}\left[y_{i}-\pi\left(x_{i}\right)\right]=0$,当梯度为0时可使得函数值最大，至此求得最优$w_k$ 。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>采样的作用</title>
      <link href="/blog/c397a88b.html"/>
      <url>/blog/c397a88b.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>定义：</strong> 采样本质上是对随机现象的模拟，根据给定的概率分布，来模拟产生一个对应的随机事件。采样可以让人们对随机事件及其产生过程有更直观的认识。</p><p>实例：通过对二项分布的采样，可以模拟”抛硬币出现正面还是反面“这个随机事件，进而模拟产生一个多次抛硬币出现的序列。<br><a id="more"></a></p><p><strong>采样的作用：</strong> </p><p>1.采样也是一种信息降维，可以起到简化问题的作用。</p><p>2.采样得到的样本集可以看作是一种非参数模型，即用较少量的样本点（经验分布）来近似总体分布，并刻画分布中的不确定性。</p><p>3.采样这种信息降维的特性，可以帮助人们快速、直观地了解总体分布中数据的结构核特性。</p><p>4.利用重采样可以保持特定的信息下（目标信息不丢失），有意识地改变改变样本的分布，以更适应后续模型的训练和学习，比如用重采样来处理分类模型的训练样本不均衡的问题。</p><p>5.很多模型由于结构复杂、含有隐变量等原因，导致对应的求解公式比较复杂，没有显示解析解，难以进行精确求解或推理。这种情况下可以利用采样的方法进行随机模拟，从而对这些复杂模型进行近似求解或推理。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 采样 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>隐马尔可夫模型HMM学习笔记</title>
      <link href="/blog/34933be3.html"/>
      <url>/blog/34933be3.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>-<br><a id="more"></a></p><p><strong>一个模型</strong><br>HMM定义为$\lambda = (N,M,\pi,A,B)$</p><p><strong>N：</strong>模型中马尔可夫链的状态数目$[s_1,s_2,…,s_N]$。如果记t时刻Markov链所处的状态$q_t$，那么$q_t \in (s_1,s_2,…,s_N)$。</p><p><strong>M：</strong>每个状态可能输出的观测符号数目$[\theta_1,\theta_2,…,\theta_M]$。如果记t时刻Markov链所处的观测值维$O_t$，那么$O_t \in (\theta_1,\theta_2,…,\theta_M)$。</p><p><strong>$\pi$：</strong>初始状态概率分布矢量，$\pi = (\pi_1,\pi_2,…,\pi_N)$。某一时刻处于某一状态的概率。$\pi = P(q_t=s_i),1 \leq i \leq N $。</p><p><strong>A：</strong>状态转移概率矩阵。$A=\{ a_{ij} \}_{NN}$ 。$a_ij = P(q_{t+1}=s_j,q_t = s_i);1\leq i,j\leq N$表示两个状态之间的转移概率。</p><p><strong>B：</strong>观测符号概率分布，$B = \{ b_j(k)\}_{NM}$。其中：$b_j(k) = P(O_t=V_k \mid q_i = s_j)$。对于连续HMM，B是一组观察值概率函数，即$B = \{b_j(X),j=1,2,…,N \}$。</p><p><strong>两个假设：</strong><br>齐次Markov假设：t+1时刻的隐藏状态只与t时刻的隐藏状态有关。<br>观察独立假设：t时刻的隐藏状态只与t时刻的观测变量有关。</p><p><strong>三个问题：</strong><br>Evaluation：当已知各个参数，如何求得某个观测序列的概率。<br>Learning：参数训练，EM算法（Baum-Welch）<br>Decoding：已知观测序列，求的参数使对应隐藏序列概率最大<br><img src="images/HMMLearn_1.png" alt="forward.png"></p><p><img src="images/HMMLearn_2.png" alt="backward.png"></p><p><img src="images/HMMLearn_3.png" alt="Learning.png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 马尔可夫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马尔可夫链介绍</title>
      <link href="/blog/8edc4196.html"/>
      <url>/blog/8edc4196.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>马尔可夫链（Markov chain），又称离散时间马尔可夫链（discrete-time Markov chain）为状态空间中经过从一个状态到另一个状态的转换的随机过程。</p><p>该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作马尔可夫性质。</p><p>在马尔可夫链的每一步，系统根据概率分布，可以从一个状态变到另一个状态，也可以保持当前状态。状态的改变叫做转移，与不同的状态改变相关的概率叫做转移概率。</p><p>随机漫步就是马尔可夫链的例子。随机漫步中每一步的状态是在图形中的点，每一步可以移动到任何一个相邻的点，在这里移动到每一个点的概率都是相同的（无论之前漫步路径是如何的）。【维基百科】<br><a id="more"></a></p><p><img src="images/马尔可夫链动图.gif" alt="马尔可夫链动图.gif"></p><p>马尔可夫链的数学表示为：<br>$P\left(x_{t+1} | \cdots, x_{t-2}, x_{t-1}, x_{t}\right)=P\left(x_{t+1} | x_{t}\right)$<br>既然某一时刻状态转移的概率只依赖前一个状态，那么只要求出系统中任意两个状态之间的转移概率，这个马尔科夫链的模型就定了。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="股市应用"><a href="#股市应用" class="headerlink" title="股市应用"></a>股市应用</h3><p><img src="images/马尔可夫链股市.png" alt=""></p><p>这个马尔科夫链是用来表示股市模型，共有三种状态：牛市（Bull market）, 熊市（Bear market）和横盘（Stagnant market）。每一个状态都以一定的概率转化到下一个状态。比如，牛市以0.025的概率转化到横盘的状态。这个状态概率转化图可以以矩阵的形式表示。如果我们定义矩阵阵P某一位置P(i, j)的值为P(j|i)，即从状态i变为状态j的概率。另外定义牛市、熊市、横盘的状态分别为0、1、2，这样我们得到了马尔科夫链模型的状态转移矩阵为：<br>$P=\left(\begin{array}{ccc}{0.9} &amp; {0.075} &amp; {0.025} \\ {0.15} &amp; {0.8} &amp; {0.05} \\ {0.25} &amp; {0.25} &amp; {0.5}\end{array}\right)$<br>当这个状态转移矩阵P确定以后，整个股市模型就已经确定！</p><h3 id="PageRank算法"><a href="#PageRank算法" class="headerlink" title="PageRank算法"></a>PageRank算法</h3><p>如何使用给定集之间的现有链接对给定集的页进行排名。如果N是已知网页的数量，一个页面i有k个链接到这个页面，那么它到链接页面的转换概率为$\frac{\alpha}{k}+\frac{1-\alpha}{N}$到未链接页面的概率为$\frac{1-\alpha}{N}$，其中超参$\alpha=0.85$。</p><h2 id="马尔可夫的性质"><a href="#马尔可夫的性质" class="headerlink" title="马尔可夫的性质"></a>马尔可夫的性质</h2><h3 id="马尔可夫链的收敛性"><a href="#马尔可夫链的收敛性" class="headerlink" title="马尔可夫链的收敛性"></a>马尔可夫链的收敛性</h3><p>如果确定了马尔科夫链模型的状态转移矩阵P，假设初始状态s=[0.2,0.2,0.6]，那么在这样的初始状态下，按照P转移n次，最终都会收敛于一个特定的数，上例最终收敛于[0.624,0.312,0.064]，则第一种事件发生的可能性最大。在排名算法中，则是，该网页的权重更大排名更靠前。</p><h4 id="收敛性需要满足的条件"><a href="#收敛性需要满足的条件" class="headerlink" title="收敛性需要满足的条件"></a>收敛性需要满足的条件</h4><p>1.可能的状态数是有限的。<br>2.状态间的转移概率需要固定不变。<br>3.从任意状态能够转变到任意状态。<br>4.不能是简单的循环，例如全是从x到y再从y到x。</p><h3 id="马尔可夫链是否可约"><a href="#马尔可夫链是否可约" class="headerlink" title="马尔可夫链是否可约"></a>马尔可夫链是否可约</h3><p>如果一个马尔可夫链可以从任何其他状态到达任何状态（不一定是在一个时间步内），那么它是不可约的。如果状态空间是有限的，并且链可以用图表示，那么我们可以说不可约马尔可夫链的图是强连通的（图论）。</p><p><img src="images/Markov-03.png" alt="左：可约  |  右：不可约"></p><p>左边的链是可约的：从3到4我们不能到达1或2。右边的链（添加了一条边）是不可约的：每个状态都可以从任何其他状态到达。</p><h3 id="马尔可夫链重现性"><a href="#马尔可夫链重现性" class="headerlink" title="马尔可夫链重现性"></a>马尔可夫链重现性</h3><p>若马尔可夫链在到达一个状态后，在演变中能反复回到该状态，则该状态具有重现性或复发性，或该马尔可夫链具有（局部）重现性，反之则具有瞬变性或短暂性</p><blockquote><p>参考链接：<br><a href="https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE</a><br><a href="https://blog.csdn.net/bitcarmanlee/article/details/82819860" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/82819860</a><br><a href="https://baijiahao.baidu.com/s?id=1626496369744727412&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1626496369744727412&amp;wfr=spider&amp;for=pc</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 马尔可夫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高斯混合模型</title>
      <link href="/blog/2f062e4e.html"/>
      <url>/blog/2f062e4e.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>简述：</strong> 高斯混合模型是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代。高斯混合模型假设每个簇的数据都是符合高斯分布的，当前数据呈现的分布就是各个簇的高斯分布叠加在一起的效果，可用多个高斯分布函数的线性组合来对数据分布进行拟合。理论上，高斯混合模型可以拟合出任意类型的分布。<br><a id="more"></a></p><p><strong>公式解说：</strong><br>GMM的概率密度函数：$p(x)=\sum_{k=1}^{K} p(k) p(x | k)=\sum_{k=1}^{K} \pi_{k} N\left(x | u_{k}, \Sigma_{k}\right)$<br>其中$p(x | k)=N\left(x | u_{k}, \Sigma_{k}\right)$是第k个高斯模型的概率密度函数，指的是选定第k个模型后产生x的概率，$p(k)=\pi_{k}$是第k个高斯模型的权重，称作选择第k个模型的先验概率，且满足$\sum_{k=1}^{K} \pi_{k}=1$ 。</p><p><strong>GMM的意义：</strong><br>比如一个班级所有同学的身高可以看作一个高斯分布，但是，一个高斯分布难免会欠拟合。所以，将维度变为2，拆分为男女两部分数据，用两个高斯模型共同拟合，这样拟合出来的分布才会更符合真实的数据分布。</p><p><strong>GMM的参数求解：（EM算法）</strong><br>待求解参数：均数$\mu$,方差$\Sigma$，权重$\pi_{k}$ 。<br>步骤：<br>①确定K值，随机初始各个参数值；<br>②E步：根据当前参数，计算每个点由某个分模型生成的概率；<br>③M步：E步估计出的概率越大，则相对应的模型权重越大，用此作为权重来计算加权的均值和方差来替代其原本的均值和方差；<br>④重复E步M步直至均值、方差收敛。<br>E步中计算概率的方法是：<br>$z_{k}^{i}=\frac{g_{k}\left(\boldsymbol{x}_{i} | \boldsymbol{\mu}_{k}, \Sigma_{k}\right)}{\sum_{k=1}^{K} g_{k}\left(\boldsymbol{x}_{i} | \boldsymbol{\mu}_{k}, \Sigma_{k}\right)}(k=1,2, \cdots, K ; i=1,2, \cdots, N)$<br>其中K是单高斯分布的个数，N是观测值的数目。在确定所有单个高斯分布之后，可以计算单个高斯分布$g_{k}\left(\boldsymbol{\mu}_{k}, \Sigma_{k}\right)$下观测值$x_i$发生的概率与观测值$x_i$在整个分布上发生的概率的比值。这个歌比值$z^i_k$指的是第k个高斯分布对观测值$x_i$发生概率的贡献。单个高斯分布对整个GMM的贡献可以表示为：$z_{k}=\sum_{i=1}^{N} z_{k}^{i}$</p><p><strong>高斯混合模型与K均值算法：</strong><br>1.共同点:<br>①可用于聚类的算法；<br>②都需要指定K值；<br>③都是需要使用EM算法来求解；<br>④都往往只能收敛于局部最优。<br>2.GMM相比于K均值算法的优点是:<br>①可以给出一个样本属于某一类的概率是多少，而不是绝对的属于哪一类；<br>②不仅仅可以用于聚类，还可以用于概率密度的估计；<br>③可以用于生成新的样本点。<br>④多维的时候，高斯混合模型需要计算协方差，考察不同维度之间的相互约束关系。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高斯混合模型 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
